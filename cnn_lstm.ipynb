{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8262a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, BinaryAccuracy\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1db65",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f3795f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_raw</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>digust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>1, 4, 7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... And I don't think we need to discuss the T...</td>\n",
       "      <td>8, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* So get up out of your bed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A confession that you hired [PERSON] ... and a...</td>\n",
       "      <td>1, 6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence label_raw  anger  \\\n",
       "0                                              , ...         1      1   \n",
       "1                                                  !   1, 4, 7      1   \n",
       "2  ... And I don't think we need to discuss the T...      8, 1      1   \n",
       "3                        * So get up out of your bed         1      1   \n",
       "4  A confession that you hired [PERSON] ... and a...      1, 6      1   \n",
       "\n",
       "   anticipation  digust  fear  joy  sadness  surprise  trust  \\\n",
       "0             0       0     0    0        0         0      0   \n",
       "1             0       0     1    0        0         1      0   \n",
       "2             0       0     0    0        0         0      1   \n",
       "3             0       0     0    0        0         0      0   \n",
       "4             0       0     0    0        1         0      0   \n",
       "\n",
       "                                      label  \n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "url = 'https://raw.githubusercontent.com/ziwei-z/w266-project/main/data/en-annotated.tsv'\n",
    "data = pd.read_csv(url, sep='\\t', header=None, names=['sentence', 'label_raw'])\n",
    "\n",
    "# make flag for each emotion\n",
    "emotions = ['anger', 'anticipation', 'digust', 'fear', 'joy', 'sadness', 'surprise', 'trust']\n",
    "i = 1\n",
    "for emo in emotions:\n",
    "    data[emo] = data.label_raw.str.contains(str(i))*1\n",
    "    i += 1\n",
    "\n",
    "data['label'] = [y[2:].astype('float32') for (x, y) in enumerate(data.values)]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d4174f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape:  (14022,)\n",
      "Test dataset shape:  (3506,)\n"
     ]
    }
   ],
   "source": [
    "# split test & train\n",
    "train_in, test_in, train_labels, test_labels = train_test_split(data['sentence'], data['label'], test_size = 0.2, random_state=13)\n",
    "print('Train dataset shape: ', train_in.shape)\n",
    "print('Test dataset shape: ', test_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da5f7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape:  (10516,)\n",
      "Dev dataset shape:  (3506,)\n"
     ]
    }
   ],
   "source": [
    "# Split to create Dev set\n",
    "train_in, dev_in, train_labels, dev_labels = train_test_split(train_in, train_labels,\n",
    "                                                              test_size = 0.25, random_state=13)\n",
    "print('Train dataset shape: ', train_in.shape)\n",
    "print('Dev dataset shape: ', dev_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6a46587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.concatenate([[train_labels.iloc[x] for x in list(range(len(train_labels)))]])\n",
    "test_labels = np.concatenate([[test_labels.iloc[x] for x in list(range(len(test_labels)))]])\n",
    "dev_labels = np.concatenate([[dev_labels.iloc[x] for x in list(range(len(dev_labels)))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00750d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12272                                What about us ?\n",
       "14401    I mean that all my life I've been nothing .\n",
       "16685                  I'll break it to her gently .\n",
       "17396              You know what I'm talking about .\n",
       "5364                          Look , it's [PERSON] !\n",
       "                            ...                     \n",
       "9360                             In here ! Quickly !\n",
       "7684                               Who dares to ....\n",
       "8597       First , I would like to take off my hat .\n",
       "3834               Get going , [PERSON] ! [PERSON] !\n",
       "8503                                       Correct ?\n",
       "Name: sentence, Length: 3506, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620b398",
   "metadata": {},
   "source": [
    "### Baseline model - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa354bf",
   "metadata": {},
   "source": [
    "#### tokenize and embed sentences\n",
    "- Using Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f2b7d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length in train and test = 299\n"
     ]
    }
   ],
   "source": [
    "# Process sentences \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# tun into tokens\n",
    "# max len \n",
    "max_len = train_in.str.len().max()\n",
    "if test_in.str.len().max() > max_len: max_len = test_in.str.len().max()\n",
    "print('max sentence length in train and test =', max_len)\n",
    "\n",
    "# initialize tokenizer \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_in)\n",
    "\n",
    "# convert to sequences and pad\n",
    "train_sequences = tokenizer.texts_to_sequences(train_in)\n",
    "dev_sequences = tokenizer.texts_to_sequences(dev_in)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_in)\n",
    "padding_type = \"post\"\n",
    "truncate_type = \"pre\"\n",
    "# use 100 for now\n",
    "max_len_touse = 100\n",
    "train_padded = pad_sequences(train_sequences,maxlen=max_len_touse, padding=padding_type, truncating=truncate_type)\n",
    "dev_padded = pad_sequences(dev_sequences,maxlen=max_len_touse, padding=padding_type, truncating=truncate_type)\n",
    "test_padded = pad_sequences(test_sequences,maxlen=max_len_touse, padding=padding_type, truncating=truncate_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ad97a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18c6b8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/glove.6B (1).zip'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download Glove model\n",
    "# based on https://cnvrg.io/cnn-sentence-classification/\n",
    "import wget\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "wget.download(url, out=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1d349c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/glove.6B.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d8cf8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('data/glove/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a1d82cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, max_len_touse))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546fc4d6",
   "metadata": {},
   "source": [
    "# Train model\n",
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939dd14",
   "metadata": {},
   "source": [
    "- First attempt: based on  https://cnvrg.io/cnn-sentence-classification/\n",
    "        Did not perform better than most common class (label 0 at 21.2%)... :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee0d9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kera embedding layer\n",
    "embedding_layer = keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "                            output_dim=max_len_touse,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len_touse,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc16e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model - option 1 \n",
    "model_test = keras.models.Sequential([\n",
    "    embedding_layer,\n",
    "  keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "  keras.layers.Dense(10, activation='relu'),\n",
    "  keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "093497fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 3.7166e-07 - accuracy: 0.1555\n"
     ]
    }
   ],
   "source": [
    "# train model \n",
    "model_test.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = model_test.fit(train_padded, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b43a4",
   "metadata": {},
   "source": [
    "## CNN from A4 & Random Search\n",
    "- Second attempt: based on CCN notebook from assignment 4\n",
    "        A little bit better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "823f8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model - taken from CNN in A4\n",
    "epochs = 10\n",
    "embed_dim = 100\n",
    "num_filters = [2, 2, 2]\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dense_layer_dims = [10, 4]\n",
    "dropout_rate = 0.7\n",
    "num_classes = 8\n",
    "\n",
    "wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "conv_layers_for_all_kernel_sizes = []\n",
    "for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
    "    conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
    "    conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "    conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
    "\n",
    "h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
    "h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "dense_layers = []\n",
    "for dense_dim in dense_layer_dims:\n",
    "    dense_layer = keras.layers.Dense(dense_dim, activation='relu')(h)\n",
    "    dense_layers.append(dense_layer)\n",
    "    \n",
    "h = keras.layers.concatenate(dense_layers, axis=1)\n",
    "\n",
    "prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])        # What metric to output as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efe85af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.5153 - accuracy: 0.1535 - val_loss: 0.4582 - val_accuracy: 0.2133\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4481 - accuracy: 0.2045 - val_loss: 0.4401 - val_accuracy: 0.2128\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4373 - accuracy: 0.2260 - val_loss: 0.4350 - val_accuracy: 0.2228\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4348 - accuracy: 0.2288 - val_loss: 0.4336 - val_accuracy: 0.2316\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4326 - accuracy: 0.2360 - val_loss: 0.4316 - val_accuracy: 0.2681\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4299 - accuracy: 0.2517 - val_loss: 0.4264 - val_accuracy: 0.3012\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4272 - accuracy: 0.2615 - val_loss: 0.4222 - val_accuracy: 0.3157\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4226 - accuracy: 0.2766 - val_loss: 0.4187 - val_accuracy: 0.3135\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4193 - accuracy: 0.2851 - val_loss: 0.4165 - val_accuracy: 0.3109\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4161 - accuracy: 0.2934 - val_loss: 0.4169 - val_accuracy: 0.3118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1446411c0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical(\n",
    "    train_labels, num_classes=None, dtype='float32'\n",
    ")\n",
    "model.fit(train_padded, train_labels, epochs=10, validation_data=(dev_padded, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "77fb4d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.3163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41849982738494873, 0.3163148760795593]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_padded, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "940e01ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 100, 100)     661800      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 99, 2)        402         embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 98, 2)        602         embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 97, 2)        802         embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 2)            0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 2)            0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 2)            0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 6)            0           global_max_pooling1d_23[0][0]    \n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 6)            0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 10)           70          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 4)            28          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 14)           0           dense_25[0][0]                   \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 8)            120         concatenate_15[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 663,824\n",
      "Trainable params: 663,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90205efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bf67d48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger      0.933     0.018     0.035       775\n",
      "anticipation      1.000     0.003     0.006       633\n",
      "     disgust      0.000     0.000     0.000       460\n",
      "        fear      0.000     0.000     0.000       500\n",
      "         joy      0.742     0.243     0.366       592\n",
      "     sadness      0.000     0.000     0.000       464\n",
      "    surprise      0.000     0.000     0.000       505\n",
      "       trust      0.000     0.000     0.000       564\n",
      "\n",
      "   micro avg      0.758     0.036     0.068      4493\n",
      "   macro avg      0.334     0.033     0.051      4493\n",
      "weighted avg      0.400     0.036     0.055      4493\n",
      " samples avg      0.046     0.040     0.042      4493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charagon/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/charagon/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "emotions = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust']\n",
    "print(classification_report(test_labels, y_pred_bool, digits = 3, target_names = emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79606507",
   "metadata": {},
   "source": [
    "### Training with Random Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee599a96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_sizes:  [6, 4, 14]\n",
      "num_filters:  [36, 49, 44]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 10s 30ms/step - loss: 0.4742 - accuracy: 0.1409 - val_loss: 0.4365 - val_accuracy: 0.2108\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.4323 - accuracy: 0.2585 - val_loss: 0.4154 - val_accuracy: 0.3169\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.4071 - accuracy: 0.3387 - val_loss: 0.3998 - val_accuracy: 0.3545\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.3783 - accuracy: 0.3997 - val_loss: 0.3957 - val_accuracy: 0.3634\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.3508 - accuracy: 0.4604 - val_loss: 0.4010 - val_accuracy: 0.3637\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.3286 - accuracy: 0.5046 - val_loss: 0.4115 - val_accuracy: 0.3600\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.3067 - accuracy: 0.5495 - val_loss: 0.4254 - val_accuracy: 0.3571\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 27s 83ms/step - loss: 0.2856 - accuracy: 0.5857 - val_loss: 0.4392 - val_accuracy: 0.3542\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 22s 67ms/step - loss: 0.2684 - accuracy: 0.6107 - val_loss: 0.4592 - val_accuracy: 0.3454\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.2540 - accuracy: 0.6346 - val_loss: 0.4862 - val_accuracy: 0.3394\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.3394\n",
      "F1 score:  0.29175540006084577\n",
      "kernel_sizes:  [17, 14, 11]\n",
      "num_filters:  [17, 42, 17]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.4630 - accuracy: 0.1647 - val_loss: 0.4359 - val_accuracy: 0.2102\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.4414 - accuracy: 0.2144 - val_loss: 0.4321 - val_accuracy: 0.2322\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.4252 - accuracy: 0.2852 - val_loss: 0.4113 - val_accuracy: 0.3212\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.3952 - accuracy: 0.3642 - val_loss: 0.3987 - val_accuracy: 0.3471\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 19s 56ms/step - loss: 0.3657 - accuracy: 0.4324 - val_loss: 0.3982 - val_accuracy: 0.3577\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.3391 - accuracy: 0.4789 - val_loss: 0.4034 - val_accuracy: 0.3588\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.3153 - accuracy: 0.5364 - val_loss: 0.4131 - val_accuracy: 0.3580\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.2950 - accuracy: 0.5694 - val_loss: 0.4204 - val_accuracy: 0.3614\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.2778 - accuracy: 0.5987 - val_loss: 0.4306 - val_accuracy: 0.3488\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 15s 44ms/step - loss: 0.2620 - accuracy: 0.6298 - val_loss: 0.4455 - val_accuracy: 0.3443\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.3540\n",
      "F1 score:  0.27360308285163776\n",
      "kernel_sizes:  [9, 17, 13]\n",
      "num_filters:  [15, 9, 12]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 13s 38ms/step - loss: 0.5016 - accuracy: 0.1526 - val_loss: 0.4400 - val_accuracy: 0.2102\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.4523 - accuracy: 0.1994 - val_loss: 0.4424 - val_accuracy: 0.2102\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 13s 41ms/step - loss: 0.4389 - accuracy: 0.2221 - val_loss: 0.4281 - val_accuracy: 0.2701\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 14s 41ms/step - loss: 0.4214 - accuracy: 0.2805 - val_loss: 0.4128 - val_accuracy: 0.2992\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 14s 41ms/step - loss: 0.4004 - accuracy: 0.3270 - val_loss: 0.4048 - val_accuracy: 0.3394\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.3825 - accuracy: 0.3729 - val_loss: 0.4014 - val_accuracy: 0.3488\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.3669 - accuracy: 0.4057 - val_loss: 0.4017 - val_accuracy: 0.3446\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.3538 - accuracy: 0.4217 - val_loss: 0.4056 - val_accuracy: 0.3388\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.3420 - accuracy: 0.4450 - val_loss: 0.4086 - val_accuracy: 0.3280\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.3302 - accuracy: 0.4590 - val_loss: 0.4165 - val_accuracy: 0.3320\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.3311\n",
      "F1 score:  0.201530612244898\n",
      "kernel_sizes:  [8, 11, 11]\n",
      "num_filters:  [16, 21, 46]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.4643 - accuracy: 0.1737 - val_loss: 0.4368 - val_accuracy: 0.2102\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4383 - accuracy: 0.2388 - val_loss: 0.4227 - val_accuracy: 0.3086\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4162 - accuracy: 0.3209 - val_loss: 0.4066 - val_accuracy: 0.3437\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.3883 - accuracy: 0.3863 - val_loss: 0.3983 - val_accuracy: 0.3585\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.3599 - accuracy: 0.4464 - val_loss: 0.3977 - val_accuracy: 0.3597\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 13s 38ms/step - loss: 0.3316 - accuracy: 0.5056 - val_loss: 0.4086 - val_accuracy: 0.3500\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.3081 - accuracy: 0.5489 - val_loss: 0.4149 - val_accuracy: 0.3503\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.2875 - accuracy: 0.5825 - val_loss: 0.4277 - val_accuracy: 0.3537\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.2707 - accuracy: 0.6118 - val_loss: 0.4379 - val_accuracy: 0.3460\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.2546 - accuracy: 0.6340 - val_loss: 0.4588 - val_accuracy: 0.3377\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.3443\n",
      "F1 score:  0.2926829268292683\n",
      "kernel_sizes:  [7, 5, 19]\n",
      "num_filters:  [24, 9, 31]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.5022 - accuracy: 0.1679 - val_loss: 0.4361 - val_accuracy: 0.2347\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4449 - accuracy: 0.2297 - val_loss: 0.4273 - val_accuracy: 0.2838\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.4273 - accuracy: 0.2865 - val_loss: 0.4132 - val_accuracy: 0.3175\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.4061 - accuracy: 0.3529 - val_loss: 0.3996 - val_accuracy: 0.3505\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.3813 - accuracy: 0.3995 - val_loss: 0.3948 - val_accuracy: 0.3560\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.3583 - accuracy: 0.4501 - val_loss: 0.3955 - val_accuracy: 0.3617\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.3349 - accuracy: 0.4896 - val_loss: 0.4016 - val_accuracy: 0.3577\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.3186 - accuracy: 0.5202 - val_loss: 0.4102 - val_accuracy: 0.3537\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.3014 - accuracy: 0.5542 - val_loss: 0.4181 - val_accuracy: 0.3485\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.2872 - accuracy: 0.5807 - val_loss: 0.4305 - val_accuracy: 0.3485\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.3465\n",
      "F1 score:  0.27073954983922827\n",
      "kernel_sizes:  [7, 9, 7]\n",
      "num_filters:  [12, 40, 37]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 10s 31ms/step - loss: 0.4610 - accuracy: 0.1757 - val_loss: 0.4341 - val_accuracy: 0.2108\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 10s 29ms/step - loss: 0.4344 - accuracy: 0.2526 - val_loss: 0.4151 - val_accuracy: 0.3183\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.4053 - accuracy: 0.3434 - val_loss: 0.3956 - val_accuracy: 0.3557\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.3729 - accuracy: 0.4225 - val_loss: 0.3920 - val_accuracy: 0.3645\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.3459 - accuracy: 0.4726 - val_loss: 0.3987 - val_accuracy: 0.3648\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.3222 - accuracy: 0.5317 - val_loss: 0.4072 - val_accuracy: 0.3611\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 10s 30ms/step - loss: 0.2984 - accuracy: 0.5668 - val_loss: 0.4224 - val_accuracy: 0.3605\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.2781 - accuracy: 0.5959 - val_loss: 0.4383 - val_accuracy: 0.3531\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 10s 32ms/step - loss: 0.2625 - accuracy: 0.6241 - val_loss: 0.4560 - val_accuracy: 0.3477\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.2479 - accuracy: 0.6510 - val_loss: 0.4683 - val_accuracy: 0.3423\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.3542\n",
      "F1 score:  0.3042808746535263\n",
      "kernel_sizes:  [4, 18, 18]\n",
      "num_filters:  [15, 22, 19]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.4846 - accuracy: 0.1667 - val_loss: 0.4353 - val_accuracy: 0.2128\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.4437 - accuracy: 0.2150 - val_loss: 0.4298 - val_accuracy: 0.2790\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.4260 - accuracy: 0.2847 - val_loss: 0.4112 - val_accuracy: 0.3263\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.3993 - accuracy: 0.3585 - val_loss: 0.3994 - val_accuracy: 0.3523\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.3750 - accuracy: 0.4057 - val_loss: 0.3988 - val_accuracy: 0.3494\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.3538 - accuracy: 0.4513 - val_loss: 0.4039 - val_accuracy: 0.3468\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.3358 - accuracy: 0.4838 - val_loss: 0.4093 - val_accuracy: 0.3443\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.3186 - accuracy: 0.5126 - val_loss: 0.4146 - val_accuracy: 0.3494\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.3054 - accuracy: 0.5393 - val_loss: 0.4280 - val_accuracy: 0.3460\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2915 - accuracy: 0.5655 - val_loss: 0.4394 - val_accuracy: 0.3520\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.3426\n",
      "F1 score:  0.2763496143958869\n",
      "kernel_sizes:  [6, 20, 14]\n",
      "num_filters:  [28, 24, 44]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.5047 - accuracy: 0.1364 - val_loss: 0.4354 - val_accuracy: 0.2102\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.4426 - accuracy: 0.2071 - val_loss: 0.4285 - val_accuracy: 0.2282\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.4222 - accuracy: 0.2593 - val_loss: 0.4105 - val_accuracy: 0.3175\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.3906 - accuracy: 0.3459 - val_loss: 0.4015 - val_accuracy: 0.3391\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.3580 - accuracy: 0.4154 - val_loss: 0.4040 - val_accuracy: 0.3366\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.3339 - accuracy: 0.4644 - val_loss: 0.4109 - val_accuracy: 0.3465\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.3096 - accuracy: 0.5171 - val_loss: 0.4231 - val_accuracy: 0.3451\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.2925 - accuracy: 0.5567 - val_loss: 0.4343 - val_accuracy: 0.3474\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.2755 - accuracy: 0.5813 - val_loss: 0.4499 - val_accuracy: 0.3406\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.2580 - accuracy: 0.6192 - val_loss: 0.4649 - val_accuracy: 0.3440\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.3388\n",
      "F1 score:  0.28167687235044747\n",
      "kernel_sizes:  [17, 5, 2]\n",
      "num_filters:  [27, 27, 50]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.4745 - accuracy: 0.1841 - val_loss: 0.4334 - val_accuracy: 0.2573\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.4340 - accuracy: 0.2557 - val_loss: 0.4184 - val_accuracy: 0.3083\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.4137 - accuracy: 0.3242 - val_loss: 0.4056 - val_accuracy: 0.3300\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.3923 - accuracy: 0.3714 - val_loss: 0.3971 - val_accuracy: 0.3503\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.3670 - accuracy: 0.4312 - val_loss: 0.3957 - val_accuracy: 0.3585\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.3440 - accuracy: 0.4764 - val_loss: 0.3995 - val_accuracy: 0.3634\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.3211 - accuracy: 0.5169 - val_loss: 0.4085 - val_accuracy: 0.3560\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.3039 - accuracy: 0.5569 - val_loss: 0.4208 - val_accuracy: 0.3582\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.2872 - accuracy: 0.5799 - val_loss: 0.4265 - val_accuracy: 0.3597\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.2706 - accuracy: 0.6052 - val_loss: 0.4513 - val_accuracy: 0.3560\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.3534\n",
      "F1 score:  0.2999379652605459\n",
      "kernel_sizes:  [8, 20, 19]\n",
      "num_filters:  [11, 4, 46]\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 15s 46ms/step - loss: 0.4748 - accuracy: 0.1618 - val_loss: 0.4365 - val_accuracy: 0.2102\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 15s 46ms/step - loss: 0.4463 - accuracy: 0.1973 - val_loss: 0.4338 - val_accuracy: 0.2210\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.4341 - accuracy: 0.2492 - val_loss: 0.4248 - val_accuracy: 0.2849\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.4155 - accuracy: 0.3100 - val_loss: 0.4148 - val_accuracy: 0.3132\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.3924 - accuracy: 0.3636 - val_loss: 0.4115 - val_accuracy: 0.3106\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.3702 - accuracy: 0.4021 - val_loss: 0.4122 - val_accuracy: 0.3243\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 15s 47ms/step - loss: 0.3492 - accuracy: 0.4465 - val_loss: 0.4122 - val_accuracy: 0.3360\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.3320 - accuracy: 0.4844 - val_loss: 0.4186 - val_accuracy: 0.3411\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.3137 - accuracy: 0.5193 - val_loss: 0.4232 - val_accuracy: 0.3440\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.2967 - accuracy: 0.5411 - val_loss: 0.4304 - val_accuracy: 0.3443\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.3440\n",
      "F1 score:  0.25658992325658997\n"
     ]
    }
   ],
   "source": [
    "# Implement Random Search for parameters: num_filters, kernel_sizes\n",
    "import random as rn\n",
    "for _ in range(10):\n",
    "    # Specify model hyperparameters.\n",
    "    epochs = 10\n",
    "    embed_dim = 100\n",
    "    num_filters = [rn.randint(1, 50), rn.randint(1, 50), rn.randint(1, 50)]\n",
    "    kernel_sizes = [rn.randint(1, 20), rn.randint(1, 20), rn.randint(1, 20)]\n",
    "    dense_layer_dims = [10, 4]\n",
    "    dropout_rate = 0.7\n",
    "    num_classes = 8\n",
    "    print('kernel_sizes: ', kernel_sizes)\n",
    "    print('num_filters: ', num_filters)\n",
    "    # Construct the convolutional neural network.\n",
    "\n",
    "    wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "    h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "    conv_layers_for_all_kernel_sizes = []\n",
    "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
    "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
    "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
    "\n",
    "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
    "    h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "    dense_layers = []\n",
    "    for dense_dim in dense_layer_dims:\n",
    "        dense_layer = keras.layers.Dense(dense_dim, activation='relu')(h)\n",
    "        dense_layers.append(dense_layer)\n",
    "\n",
    "    h = keras.layers.concatenate(dense_layers, axis=1)\n",
    "\n",
    "    prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "    model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])        # What metric to output as we train.\n",
    "    tf.keras.utils.to_categorical(\n",
    "        train_labels, num_classes=None, dtype='float32'\n",
    "    )\n",
    "    model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "    model.evaluate(test_padded, test_labels)\n",
    "    \n",
    "    # Get F1 score\n",
    "    y_pred = model.predict(test_padded)\n",
    "    y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "    print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b7fffad7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  21\n",
      "Epoch 1/21\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.4845 - accuracy: 0.1633 - val_loss: 0.4347 - val_accuracy: 0.2102\n",
      "Epoch 2/21\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.4400 - accuracy: 0.2310 - val_loss: 0.4226 - val_accuracy: 0.3038\n",
      "Epoch 3/21\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.4142 - accuracy: 0.3168 - val_loss: 0.4023 - val_accuracy: 0.3477\n",
      "Epoch 4/21\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.3844 - accuracy: 0.3943 - val_loss: 0.3979 - val_accuracy: 0.3597\n",
      "Epoch 5/21\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.3563 - accuracy: 0.4463 - val_loss: 0.4032 - val_accuracy: 0.3514\n",
      "Epoch 6/21\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.3307 - accuracy: 0.5038 - val_loss: 0.4116 - val_accuracy: 0.3523\n",
      "Epoch 7/21\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.3096 - accuracy: 0.5504 - val_loss: 0.4223 - val_accuracy: 0.3423\n",
      "Epoch 8/21\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2879 - accuracy: 0.5798 - val_loss: 0.4395 - val_accuracy: 0.3505\n",
      "Epoch 9/21\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.2712 - accuracy: 0.6047 - val_loss: 0.4551 - val_accuracy: 0.3406\n",
      "Epoch 10/21\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.2560 - accuracy: 0.6322 - val_loss: 0.4804 - val_accuracy: 0.3423\n",
      "Epoch 11/21\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.2430 - accuracy: 0.6508 - val_loss: 0.4957 - val_accuracy: 0.3383\n",
      "Epoch 12/21\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.2327 - accuracy: 0.6618 - val_loss: 0.5238 - val_accuracy: 0.3397\n",
      "Epoch 13/21\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.2246 - accuracy: 0.6732 - val_loss: 0.5457 - val_accuracy: 0.3437\n",
      "Epoch 14/21\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.2145 - accuracy: 0.6882 - val_loss: 0.5577 - val_accuracy: 0.3326\n",
      "Epoch 15/21\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.2076 - accuracy: 0.6988 - val_loss: 0.5811 - val_accuracy: 0.3331\n",
      "Epoch 16/21\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.2035 - accuracy: 0.7046 - val_loss: 0.6009 - val_accuracy: 0.3386\n",
      "Epoch 17/21\n",
      "329/329 [==============================] - 14s 41ms/step - loss: 0.1969 - accuracy: 0.7174 - val_loss: 0.6278 - val_accuracy: 0.3311\n",
      "Epoch 18/21\n",
      "329/329 [==============================] - 20s 62ms/step - loss: 0.1918 - accuracy: 0.7167 - val_loss: 0.6425 - val_accuracy: 0.3300\n",
      "Epoch 19/21\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.1862 - accuracy: 0.7216 - val_loss: 0.6576 - val_accuracy: 0.3297\n",
      "Epoch 20/21\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.1823 - accuracy: 0.7351 - val_loss: 0.6589 - val_accuracy: 0.3380\n",
      "Epoch 21/21\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.1790 - accuracy: 0.7366 - val_loss: 0.7071 - val_accuracy: 0.3283\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.3360\n",
      "F1 score:  0.3181197048373872\n",
      "epochs:  19\n",
      "Epoch 1/19\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.4618 - accuracy: 0.1857 - val_loss: 0.4352 - val_accuracy: 0.2128\n",
      "Epoch 2/19\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.4396 - accuracy: 0.2391 - val_loss: 0.4277 - val_accuracy: 0.2752\n",
      "Epoch 3/19\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.4177 - accuracy: 0.3215 - val_loss: 0.4086 - val_accuracy: 0.3203\n",
      "Epoch 4/19\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.3883 - accuracy: 0.3820 - val_loss: 0.4032 - val_accuracy: 0.3369\n",
      "Epoch 5/19\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.3621 - accuracy: 0.4438 - val_loss: 0.4041 - val_accuracy: 0.3423\n",
      "Epoch 6/19\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.3368 - accuracy: 0.4930 - val_loss: 0.4121 - val_accuracy: 0.3388\n",
      "Epoch 7/19\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.3124 - accuracy: 0.5381 - val_loss: 0.4224 - val_accuracy: 0.3426\n",
      "Epoch 8/19\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2930 - accuracy: 0.5779 - val_loss: 0.4401 - val_accuracy: 0.3400\n",
      "Epoch 9/19\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.2764 - accuracy: 0.6011 - val_loss: 0.4450 - val_accuracy: 0.3420\n",
      "Epoch 10/19\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.2619 - accuracy: 0.6222 - val_loss: 0.4698 - val_accuracy: 0.3431\n",
      "Epoch 11/19\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.2462 - accuracy: 0.6476 - val_loss: 0.4729 - val_accuracy: 0.3357\n",
      "Epoch 12/19\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2374 - accuracy: 0.6671 - val_loss: 0.4956 - val_accuracy: 0.3320\n",
      "Epoch 13/19\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2263 - accuracy: 0.6758 - val_loss: 0.5028 - val_accuracy: 0.3306\n",
      "Epoch 14/19\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2184 - accuracy: 0.6854 - val_loss: 0.5316 - val_accuracy: 0.3388\n",
      "Epoch 15/19\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.2089 - accuracy: 0.7002 - val_loss: 0.5515 - val_accuracy: 0.3426\n",
      "Epoch 16/19\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.2037 - accuracy: 0.6990 - val_loss: 0.5654 - val_accuracy: 0.3366\n",
      "Epoch 17/19\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.2008 - accuracy: 0.7075 - val_loss: 0.5771 - val_accuracy: 0.3406\n",
      "Epoch 18/19\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.1932 - accuracy: 0.7170 - val_loss: 0.5925 - val_accuracy: 0.3351\n",
      "Epoch 19/19\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.1875 - accuracy: 0.7205 - val_loss: 0.6029 - val_accuracy: 0.3414\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.3377\n",
      "F1 score:  0.31876317638791285\n",
      "epochs:  17\n",
      "Epoch 1/17\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.4810 - accuracy: 0.1612 - val_loss: 0.4351 - val_accuracy: 0.2216\n",
      "Epoch 2/17\n",
      "329/329 [==============================] - 13s 38ms/step - loss: 0.4351 - accuracy: 0.2436 - val_loss: 0.4128 - val_accuracy: 0.3263\n",
      "Epoch 3/17\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.4071 - accuracy: 0.3363 - val_loss: 0.4005 - val_accuracy: 0.3414\n",
      "Epoch 4/17\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.3825 - accuracy: 0.3926 - val_loss: 0.3992 - val_accuracy: 0.3523\n",
      "Epoch 5/17\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.3586 - accuracy: 0.4443 - val_loss: 0.4007 - val_accuracy: 0.3525\n",
      "Epoch 6/17\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.3374 - accuracy: 0.4782 - val_loss: 0.4075 - val_accuracy: 0.3574\n",
      "Epoch 7/17\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.3162 - accuracy: 0.5212 - val_loss: 0.4163 - val_accuracy: 0.3471\n",
      "Epoch 8/17\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.2976 - accuracy: 0.5564 - val_loss: 0.4299 - val_accuracy: 0.3531\n",
      "Epoch 9/17\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.2815 - accuracy: 0.5882 - val_loss: 0.4479 - val_accuracy: 0.3485\n",
      "Epoch 10/17\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2656 - accuracy: 0.6123 - val_loss: 0.4622 - val_accuracy: 0.3531\n",
      "Epoch 11/17\n",
      "329/329 [==============================] - 13s 38ms/step - loss: 0.2509 - accuracy: 0.6436 - val_loss: 0.4780 - val_accuracy: 0.3477\n",
      "Epoch 12/17\n",
      "329/329 [==============================] - 13s 38ms/step - loss: 0.2408 - accuracy: 0.6539 - val_loss: 0.4960 - val_accuracy: 0.3460\n",
      "Epoch 13/17\n",
      "329/329 [==============================] - 13s 38ms/step - loss: 0.2282 - accuracy: 0.6773 - val_loss: 0.5207 - val_accuracy: 0.3488\n",
      "Epoch 14/17\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.2194 - accuracy: 0.6888 - val_loss: 0.5387 - val_accuracy: 0.3528\n",
      "Epoch 15/17\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.2126 - accuracy: 0.6987 - val_loss: 0.5641 - val_accuracy: 0.3423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/17\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2071 - accuracy: 0.6988 - val_loss: 0.5786 - val_accuracy: 0.3408\n",
      "Epoch 17/17\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.1998 - accuracy: 0.7111 - val_loss: 0.5938 - val_accuracy: 0.3463\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.3391\n",
      "F1 score:  0.3183046508320296\n",
      "epochs:  8\n",
      "Epoch 1/8\n",
      "329/329 [==============================] - 13s 38ms/step - loss: 0.4771 - accuracy: 0.1487 - val_loss: 0.4372 - val_accuracy: 0.2142\n",
      "Epoch 2/8\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.4416 - accuracy: 0.2220 - val_loss: 0.4286 - val_accuracy: 0.2470\n",
      "Epoch 3/8\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.4237 - accuracy: 0.2944 - val_loss: 0.4167 - val_accuracy: 0.3120\n",
      "Epoch 4/8\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.3966 - accuracy: 0.3635 - val_loss: 0.4047 - val_accuracy: 0.3477\n",
      "Epoch 5/8\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.3680 - accuracy: 0.4312 - val_loss: 0.4003 - val_accuracy: 0.3534\n",
      "Epoch 6/8\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.3417 - accuracy: 0.4836 - val_loss: 0.4042 - val_accuracy: 0.3565\n",
      "Epoch 7/8\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.3180 - accuracy: 0.5145 - val_loss: 0.4144 - val_accuracy: 0.3508\n",
      "Epoch 8/8\n",
      "329/329 [==============================] - 13s 38ms/step - loss: 0.2979 - accuracy: 0.5558 - val_loss: 0.4261 - val_accuracy: 0.3417\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.3428\n",
      "F1 score:  0.24590993422162252\n",
      "epochs:  8\n",
      "Epoch 1/8\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4847 - accuracy: 0.2018 - val_loss: 0.4345 - val_accuracy: 0.2202\n",
      "Epoch 2/8\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.4375 - accuracy: 0.2375 - val_loss: 0.4200 - val_accuracy: 0.2772\n",
      "Epoch 3/8\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.4157 - accuracy: 0.2858 - val_loss: 0.4092 - val_accuracy: 0.2958\n",
      "Epoch 4/8\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.3888 - accuracy: 0.3606 - val_loss: 0.4021 - val_accuracy: 0.3377\n",
      "Epoch 5/8\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.3587 - accuracy: 0.4321 - val_loss: 0.3980 - val_accuracy: 0.3588\n",
      "Epoch 6/8\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.3327 - accuracy: 0.4959 - val_loss: 0.4038 - val_accuracy: 0.3560\n",
      "Epoch 7/8\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.3087 - accuracy: 0.5471 - val_loss: 0.4168 - val_accuracy: 0.3514\n",
      "Epoch 8/8\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.2874 - accuracy: 0.5816 - val_loss: 0.4276 - val_accuracy: 0.3557\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.3474\n",
      "F1 score:  0.2829766847652507\n"
     ]
    }
   ],
   "source": [
    "# Implement Random Search for parameters: epochs\n",
    "for _ in range(5):\n",
    "    # Specify model hyperparameters\n",
    "    epochs = rn.randint(5, 25)\n",
    "    embed_dim = 100\n",
    "    num_filters = [12, 40, 37]\n",
    "    kernel_sizes = [7, 9, 7]\n",
    "    dense_layer_dims = [10, 4]\n",
    "    dropout_rate = 0.7\n",
    "    num_classes = 8\n",
    "    print('epochs: ', epochs)\n",
    "    # Construct the convolutional neural network.\n",
    "\n",
    "    wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "    h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "    conv_layers_for_all_kernel_sizes = []\n",
    "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
    "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
    "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
    "\n",
    "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
    "    h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "    dense_layers = []\n",
    "    for dense_dim in dense_layer_dims:\n",
    "        dense_layer = keras.layers.Dense(dense_dim, activation='relu')(h)\n",
    "        dense_layers.append(dense_layer)\n",
    "\n",
    "    h = keras.layers.concatenate(dense_layers, axis=1)\n",
    "\n",
    "    prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "    model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])        # What metric to output as we train.\n",
    "    tf.keras.utils.to_categorical(\n",
    "        train_labels, num_classes=None, dtype='float32'\n",
    "    )\n",
    "    model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "    model.evaluate(test_padded, test_labels)\n",
    "\n",
    "    # Get F1 score\n",
    "    y_pred = model.predict(test_padded)\n",
    "    y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "    print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f9a84d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "329/329 [==============================] - 10s 30ms/step - loss: 0.4935 - accuracy: 0.1579 - val_loss: 0.4337 - val_accuracy: 0.2250\n",
      "Epoch 2/11\n",
      "329/329 [==============================] - 10s 30ms/step - loss: 0.4365 - accuracy: 0.2385 - val_loss: 0.4215 - val_accuracy: 0.2949\n",
      "Epoch 3/11\n",
      "329/329 [==============================] - 10s 30ms/step - loss: 0.4124 - accuracy: 0.3226 - val_loss: 0.4060 - val_accuracy: 0.3314\n",
      "Epoch 4/11\n",
      "329/329 [==============================] - 10s 30ms/step - loss: 0.3861 - accuracy: 0.3805 - val_loss: 0.4029 - val_accuracy: 0.3406\n",
      "Epoch 5/11\n",
      "329/329 [==============================] - 10s 29ms/step - loss: 0.3596 - accuracy: 0.4269 - val_loss: 0.4052 - val_accuracy: 0.3437\n",
      "Epoch 6/11\n",
      "329/329 [==============================] - 10s 31ms/step - loss: 0.3365 - accuracy: 0.4758 - val_loss: 0.4110 - val_accuracy: 0.3460\n",
      "Epoch 7/11\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.3106 - accuracy: 0.5208 - val_loss: 0.4257 - val_accuracy: 0.3434\n",
      "Epoch 8/11\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.2909 - accuracy: 0.5614 - val_loss: 0.4375 - val_accuracy: 0.3457\n",
      "Epoch 9/11\n",
      "329/329 [==============================] - 11s 35ms/step - loss: 0.2724 - accuracy: 0.5953 - val_loss: 0.4510 - val_accuracy: 0.3431\n",
      "Epoch 10/11\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.2573 - accuracy: 0.6181 - val_loss: 0.4747 - val_accuracy: 0.3383\n",
      "Epoch 11/11\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.2421 - accuracy: 0.6429 - val_loss: 0.4951 - val_accuracy: 0.3411\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.3426\n",
      "F1 score:  0.2976280404894999\n"
     ]
    }
   ],
   "source": [
    "# Specify model hyperparameters.\n",
    "epochs = 11\n",
    "embed_dim = 100\n",
    "num_filters = [12, 40, 37]\n",
    "kernel_sizes = [7, 9, 7]\n",
    "dense_layer_dims = [10, 4]\n",
    "dropout_rate = 0.7\n",
    "num_classes = 8\n",
    "# Construct the convolutional neural network.\n",
    "\n",
    "wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "conv_layers_for_all_kernel_sizes = []\n",
    "for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
    "    conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
    "    conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "    conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
    "\n",
    "h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
    "h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "dense_layers = []\n",
    "for dense_dim in dense_layer_dims:\n",
    "    dense_layer = keras.layers.Dense(dense_dim, activation='relu')(h)\n",
    "    dense_layers.append(dense_layer)\n",
    "\n",
    "h = keras.layers.concatenate(dense_layers, axis=1)\n",
    "\n",
    "prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])        # What metric to output as we train.\n",
    "tf.keras.utils.to_categorical(\n",
    "    train_labels, num_classes=None, dtype='float32'\n",
    ")\n",
    "model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "model.evaluate(test_padded, test_labels)\n",
    "\n",
    "# Get F1 score\n",
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0fef0f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABOMAAANHCAYAAAB0MpmrAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVxV9b7/8fdmVEHUyjGnSM0hSSHMqVJT0dwbrUBySM3xlL+sTubJ5uvtnHO9XbNTNtpwT900wRzYHMRZTNHsYGk5NZgKoQlOgCIgfH9/+HDnTkBA2Jvh9Xw8euT+runDWvB1+eb7XctijDECAAAAAAAAUNliPNxdAQAAAAAAAFBbEMYBAAAAAAAALkIYBwAAAAAAALgIYRwAAAAAAADgIl7uLgAAANQ827Zt02uvvebuMoBrEhMT4+4SAABADcTIOAAAUOFSUlK0dOlSd5cBlEtqairfvwAAoNIwMg4AAFQaRhahOoqOjlZUVJS7ywAAADUUI+MAAAAAAAAAFyGMAwAAAAAAAFyEMA4AAAAAAABwEcI4AAAAAAAAwEUI4wAAAAAAAAAXIYwDAAAAAAAAXIQwDgAAAAAAAHARwjgAAAAAAADARQjjAAAAAAAAABchjAMAAAAAAABchDAOAAAAAAAAcBHCOAAAAAAAAMBFCOMAAAAAAAAAFyGMAwAAAAAAAFzEy90FAAAASNLBgwf1yiuvaM6cOWrZsqW7yym3Xbt2afPmzfLx8dGwYcOu+FqOHTum/fv3q1+/fmXe9+bNm/Xrr786tTVs2FBDhw69lpKv2Zo1a3TixAmntqCgIHXp0sVNFQEAAFRdjIwDAABVws6dO/Xxxx/ru+++c3cp5ZKRkaHJkydr9uzZGj58uKZNm+YUxKWnp2vmzJkKDAzU8uXLy3WMnj17qm7duho9erRGjx6tjIyMcoV6Fa179+7avn27Ro8erYceekjNmjVT+/bt3V0WAABAlUQYBwAAqoSIiAilp6e7dZTXJ598Uq7tDh06pE6dOik3N1fx8fFq3bp1keuMGzdOOTk55a7Px8dHw4cPV8OGDSVJY8eOVd26dcu9v2tx+blq3Lixxo0bJ0nq1q2b+vfvLx8fH7fUBQAAUNURxgEAgCrjhhtucNuxN2zYoNmzZ5d5u7y8PI0cOVLXXXed3n333WLXCw0NVceOHa+lREmSxWJR/fr1JUkNGjS45v2VR1Hn6lJNfn5+7igJAACg2uCZcQAAoEooLCxUYmKi/P39FRoaKklKSUnRsmXL9Nhjj2nv3r1auXKlWrdurTFjxsjD4+LvFFNTUxUbG6tHHnlEiYmJWr16tW688UZNmjRJdevWld1u188//yx/f39NnjxZWVlZ+uSTT5Sfn6/mzZsrKipKGzdu1IgRI2SxWPTee++pRYsWstlspar7ueee09dff60PPvjgmoKojIwMLVy4UBMnTlTTpk3LvH11OFeX++GHH7R9+3bt3r1bffr00X333SdJWr9+vVJSUiRJvr6+uv/+++Xr66sdO3Zo7969atSokYYPHy5JSktLU0JCglJTU9WnTx/dc889jv2fOnVKixcv1qOPPqpVq1Zp9+7deuqpp+Tlxe0vAABwL+5GAACA2+3du1cvvfSSli5dqnfeeUehoaGy2+2aNGmS0tPTZYzR7t27lZ6erueff16pqamaPXu2PvvsMz322GM6f/68vvvuO+Xl5enYsWP6r//6L33yySfaunWrbDabbr31Vp05c0aTJ09W/fr1NW7cOLVs2VJdunRRVFSUGjVqpKCgIP3www+65ZZbHNNAS2Px4sXy8vLSd999pwEDBmjHjh0KDg7W66+/ruDg4FLvZ8WKFXr22Wfl7++vxx57rEznr7qcq0tef/11rVy5Uhs2bNDhw4fVv39/HTt2TI888oh69eqlxx9/XHv27NHPP/8sX19fSVKPHj00fvx4rVy5UpK0ceNGLV68WI888ojq16+vESNGaNy4cXrrrbf0z3/+U48++qjy8vJUWFioDz74QLt27dLQoUMVFBRU5noBAAAqlAEAAKhgS5YsMWW9zdi9e7eRZN555x1H2zPPPGMkmXXr1jnagoODTUhIiOPz2LFjjcViMd9//72j7YUXXjCSzLvvvmuMMSYiIsK0bNnS6XjBwcGmV69ejs8jRowwrVq1KlPNqampRpLp1q2bOXHihDHGmAMHDpjmzZsbf39/k5qa6rR+bm6ukWRmzJhxxb6ys7PNokWLTGZm5lWP26pVKyPJFBQUONrcfa4OHDhgJJm77rrrqvW3a9fOTJ8+3Wl/9957r+NzbGyskWQWLlzoaEtLSzMRERHGGGOysrJMYGCgyc7OdiyfNGmSkWS2bdtmjDFmzJgxRpJZtmyZMcaYffv2XbWuS8rz/QsAAFBK0TwzDgAAVAmXRkBd7tLLCS5/1lrnzp115MgRx2c/Pz95eXmpS5cujrZnnnlGXl5e2rx5c5lqsFgsZVp/586dkqQRI0bouuuukyR16NBBr732mrKzs/X222+Xel9+fn4aNWqU49lrZVXVz9XlNm3apFdeeUXSxVGRKSkp+vHHHx3LrVarOnXqpNdee03GGEnSokWLHC+JWLx4sXJycjRr1ixNnz5d06dP19GjR3XzzTfrp59+kiS1aNFCkhxTWivieX0AAAAVgWmqAACgWvH09HQENMWpV6+eWrZsqfT09DLtu6wB06UXKPzxxRO9evWSJB04cKBM+6toVelcXe7GG2/UmjVrFBcXp7vvvls333yzkpOTnfb99NNPa+LEiYqPj9ewYcO0bt06Pf7445KkPXv2qHnz5nrrrbeKPcal5+Rd+j8AAEBVwd0JAACocXJzc3Xs2DEFBgaWabuyBkwdOnSQJKcgSZJat24tb2/vco9ycyVXnStJOn78uHJzc/XCCy/olVde0dy5c/XAAw/I09PzinXHjBmjG2+8UfPmzdOePXvUpUsXx8sXPD09deDAAeXn55e5BgAAAHcjjAMAADXO9u3bdf78eVmtVkmSl5eXzp8/X+I2FotFBQUFZTpOs2bNFBYWpu3btzu1//jjj8rPz1efPn3KVrgbuOpcSdKUKVN05MgRvfLKKxo7dqxjam1hYeEV6/r4+OiJJ57Qxo0b9fTTT+vhhx92LLvtttt09uxZvfvuu07bnD59ukxTgwEAANyBMA4AAFQJubm5kqSMjAxHW2ZmpiQpLy/P0ZaRkaHc3Fyn6ZcXLlzQvn37HJ+XLl2qu+++2xEwDR48WBkZGfr444919uxZffzxxzpx4oQOHjyoU6dOSZKaN2+uY8eO6eDBg/r555919uzZUtU9b948paSkKCkpydG2ceNGderUSRMmTHBa99Kxigq7kpOT1aNHD23atOmqx7x0Xi79//I/u+tcHT58+IrjX3Lu3DnNmDHDKehbvHixMjMz9eWXX2rz5s06deqUsrOzlZWV5dhu2rRpatCggTIyMpyecxcVFaVWrVpp5syZevXVV7Vv3z5FR0dr6tSpeuihhyTJcf1OnDhx1fMJAADgSoRxAADA7b766ivNmTNHkrRkyRL961//UmJiopYvXy5J+tvf/qZjx47p888/15dffqmsrCzNmTNHFy5ckHTxuWBvv/22Zs2apVGjRunw4cOy2+2O/UdGRqpnz56aOHGiQkND1bBhQ4WEhKhbt2764osvHOsYYxQSEqL4+Hj5+fmVqvYuXbpo69atevHFF/XSSy/pb3/7m+Li4rR+/XrHtEpJWrVqleOZZytWrNAHH3ygY8eOOZYfPnxY//73vx0vICjKunXrNGXKFJ05c0aSNGnSJC1btszt52rlypV6/vnnHdeyZ8+eGjhwoPr06aNbb71VDRs21JtvvqkhQ4aoa9eumjhxorZs2aKQkBDt3btXb775prKzszV8+HCnqaf169fXqFGjrgg1fX19tXr1arVt21azZs1S586dNWfOHM2ePVv169fXhx9+6Dgfjz76qHbs2FGqawkAAOAKFnO1p/oCAACUUXR0tKKioq768oCK8Kc//UkfffSR8vLylJKSogYNGiggIKDIddPT09W4cWNJF0en1alTx2n5mTNn5OHhUe5nvaWlpalu3bpq1KhRubbPzMwstvaKUJXOVVZWltO2ubm5Rb5Rd/DgwYqOjlbDhg2L3M/hw4dlsVjUunXrctVRFFd+/wIAgFonhrepAgCAGqNVq1YlLr8ULkm6IlySfn87qnRxRNXVTJ06Vd26dXN8btGiRWnKLFZlBnF/VJHnqjz+GOIVFcTt2rVLgYGBxQZxktSmTZtrqgMAAMDVCOMAAEC1du7cOV24cEHZ2dny9/evsP3279//qutcHlhVB5V1ripScnKyZs2apa5du2rTpk1asWKFu0sCAACoUIRxAACg2vrss8+0Zs0aGWP0l7/8RVOmTHEaqXYtIiMjK2Q/VUVlnquKVFhYqK+//lrJyclauHCh2rZt6+6SAAAAKhRhHAAAqLasVquGDRvm+FzUVEdcVF3OVWhoqE6ePCkPDw95ePCuMQAAUPMQxgEAgGrrWp9bVptUp3N1+VtoAQAAahp+3QgAAAAAAAC4CGEcAAAAAAAA4CKEcQAAAAAAAICLEMYBAAAAAAAALkIYBwAAAAAAALgIYRwAAAAAAADgIoRxAAAAAAAAgIsQxgEAAAAAAAAuQhgHAAAAAAAAuAhhHAAAAAAAAOAihHEAAAAAAACAixDGAQAAAAAAAC7i5e4CAABAzRUZGenuEoAyS01NdXcJAACgBmNkHAAAqHCtWrVSRESEu8uosdLT07V582Z3l1FjtWzZku9fAABQaSzGGOPuIgAAAFB60dHRioqKErdxAAAA1U4MI+MAAAAAAAAAFyGMAwAAAAAAAFyEMA4AAAAAAABwEcI4AAAAAAAAwEUI4wAAAAAAAAAXIYwDAAAAAAAAXIQwDgAAAAAAAHARwjgAAAAAAADARQjjAAAAAAAAABchjAMAAAAAAABchDAOAAAAAAAAcBHCOAAAAAAAAMBFCOMAAAAAAAAAFyGMAwAAAAAAAFyEMA4AAAAAAABwEcI4AAAAAAAAwEUI4wAAAAAAAAAXIYwDAAAAAAAAXIQwDgAAAAAAAHARwjgAAAAAAADARQjjAAAAAAAAABchjAMAAAAAAABchDAOAAAAAAAAcBHCOAAAAAAAAMBFCOMAAAAAAAAAFyGMAwAAAAAAAFyEMA4AAAAAAABwEcI4AAAAAAAAwEUI4wAAAAAAAAAXIYwDAAAAAAAAXIQwDgAAAAAAAHARwjgAAAAAAADARQjjAAAAAAAAABfxcncBAAAAKF5qaqrGjx+vgoICR1tGRoa8vLzUr18/p3VvueUWvffeey6uEAAAAGVBGAcAAFCFtWzZUocOHdLBgwevWJaYmOj0+c4773RVWQAAACgnpqkCAABUcePGjZO3t/dV13vwwQddUA0AAACuBWEcAABAFTdmzBjl5+eXuE7nzp3VpUsXF1UEAACA8iKMAwAAqOLatWunoKAgWSyWIpd7e3tr/PjxLq4KAAAA5UEYBwAAUA2MGzdOnp6eRS67cOGCRo4c6eKKAAAAUB6EcQAAANXAqFGjVFhYeEW7xWLRHXfcobZt27q+KAAAAJQZYRwAAEA10KJFC/Xu3VseHs63b56enho3bpybqgIAAEBZEcYBAABUEw899NAVbcYYPfDAA26oBgAAAOVBGAcAAFBNREZGOo2M8/T01MCBA9WkSRM3VgUAAICyIIwDAACoJho1aqTBgwc7XuRgjNHYsWPdXBUAAADKgjAOAACgGhk7dqzjRQ5eXl4KDw93c0UAAAAoC8I4AACAaiQ8PFy+vr6OPwcEBLi5IgAAAJSFl7sLAAAArpeamqqkpCR3l4FyCg4OVlJSkm666SZFR0e7uxyU08iRI91dAgAAcAOLMca4uwgAAOBa0dHRioqKcncZQK3GbTgAALVSDCPjAACoxQgDqqf8/Hw9//zzmjt3rrtLQTkQhgMAULvxzDgAAIBqxtvbWy+//LK7ywAAAEA5EMYBAABUQ3Xr1nV3CQAAACgHwjgAAAAAAADARQjjAAAAAAAAABchjAMAAAAAAABchDAOAAAAAAAAcBHCOAAAAAAAAMBFCOMAAAAAAAAAFyGMAwAAAAAAAFyEMA4AAAAAAABwEcI4AAAAAAAAwEUI4wAAAAAAAAAXIYwDAAAAAAAAXIQwDgAAAAAAAHARL3cXAAAAarfs7GytX79e3377rV566aUK3e/GjRu1ZcsWzZ07t9TrHDx4UK+88ormzJmjli1bVlg95bVr1y5t3rxZPj4+GjZsmKOmrKwsLVq0SL/88ovatWun0aNHq169emXa95o1a3TixImrrhceHi4/P79y1S9xjQEAAC7HyDgAAOBWS5cu1eTJk7V48eIK3W9CQoJmzJihzz//vEzr7Ny5Ux9//LG+++67Cq2nrDIyMjR58mTNnj1bw4cP17Rp0xzB0YEDB9ShQwfNmzdP8+fP15QpUxQUFKRjx46V6Rjdu3fX9u3bNXr0aM2cOVO5ubkqKChQQUGBsrKy9O9//1sPP/yw0tLSrulr4RoDAAD8jjAOAAC41YQJE3T77bdX+H4jIiLUo0cPeXkVPxGgqHUiIiKUnp6uoUOHVnhNpXXo0CF16tRJubm5io+PV+vWrZ2WP/nkk1q9erV++OEHpaamavLkyfr555/13HPPlek4jRs31rhx4yRJ7dq104QJEzR27FiNHTtWU6dO1bx58/TYY48pLy/vmr4erjEAAMDvCOMAAIDbeXp6ymKxVPh+PTw85OFR8u1OUevccMMNFV5LaeXl5WnkyJG67rrr9O67716xPDk5WWPGjFFQUJCki4HanDlz5OHhoaSkpDIfr379+iUuf+KJJypkKifXGAAA4CKeGQcAAEotLS1NCQkJSk1NVZ8+fXTPPfc4luXk5GjlypUKDw/X8ePHFR8frxYtWshms8nT01O//fabYmNj5eHhocjISAUEBBR5jKSkJK1evVpBQUF64IEHSn18STp58qSWLl2qQ4cO6fbbb5cx5ooA6GrrFBYWKjExUf7+/goNDZUkpaSkaNmyZXrssce0d+9erVy5Uq1bt9aYMWOcQp7s7Gx9+umnOnLkiNq3b68ePXqoU6dO8vT0LPU5fu655/T111/rgw8+KPI5bW3btlVwcLBTW/PmzRUSEuI0+isjI0MLFy7UxIkT1bRp01If/3IJCQnq0aOHGjRoIIlrLFXMNQYAALWcAQAAtc6SJUtMWW8DNmzYYKZMmWJ27txpoqOjjb+/v3n00UeNMcZs2rTJtG/f3kgy8+bNM1OnTjWzZs0y9erVMw888IBZuHChGTNmjHnwwQeNxWIxNpvNad/Dhg0zN910k7FarWbYsGGmU6dORpIZO3ZsqY5vjDH79+83oaGhJikpyeTn55v33nvP+Pr6mg4dOpR6nT179piIiAgjybzzzjvGGGNiY2NN48aNjSQzf/588/DDDxur1Wokmb/97W+OfZ88edJ06NDBbN682WRnZ5v77rvPSDKhoaHmiSeeKPV5vvHGG42Xl5d5/PHHTf/+/Y2fn5+58847TXJyconbNWvWzMyZM8fxeeHChUaSeeONN0rc7sCBA0aSueuuu5za8/PzzZ133mmOHDlijOEaG1Nx17g8P38AAKDGiOYuAACAWqisYUBWVpYJDAw02dnZjrZJkyYZSWbbtm3GGGNee+01I8nExMQ41nnmmWeMJPPFF1842p577jnj6+trCgoKHG3Dhg0zPj4+Zv/+/cYYYwoLC83w4cONJBMfH1+q499xxx3m6aefdiwvLCw0gYGBTkFNadbZvXu3U1Bz+dexbt06R1twcLAJCQlxfJ49e7Zp06aN43NycrIj3Cmt1NRUI8l069bNnDhxwhhzMSxr3ry58ff3N6mpqUVul5iYaFq2bGmysrIcbdnZ2WbRokUmMzOzxGNeCuMaNmxoBgwYYAYMGGDuvvtu06RJEyPJEcYZwzWuiGtsDGEcAAC1XDTTVAEAwFUtXrxYOTk5mjVrlqPt6NGjuvnmm/XTTz+pZ8+ejqmMXbt2daxzyy23SJJuu+02R1vHjh2Vm5urtLQ0p2eRdenSxbG+xWLRI488opUrV+pf//qXUlNTSzz+uXPn9NVXX+mll15yLLdYLAoNDdW3334rSdqwYcNV15EkX1/fK77+unXrOmq/pHPnzlq9erXj888//6z09HTl5eXJx8dHt912m/z8/JSSklLyyb3Mzp07JUkjRozQddddJ0nq0KGDXnvtNY0aNUpvv/22/vrXvzptU1BQoBdffFGxsbHy9/d3tPv5+WnUqFGlPnZQUJDWr1/v+Hz+/Hn169fPaR2u8bVfYwAAAMI4AABwVXv27FHz5s311ltvlWm7OnXqXNHm7e0tSTp79myJ2/bs2VMeHh5KS0uTl5dXicefP3++JOnWW291ar/8OWG7du266jpl4enpKWOM43P//v0VHR2tLVu2aMCAATp16pTy8vI0aNCgUu/zUtj1x5cL9OrVS5J04MCBK7aZOXOm/vznP6t79+7l+TKKVadOHT377LOOkKqk9f6IawwAAFA8wjgAAHBVnp6eOnDggPLz8x1BS2ULCAiQv7+/AgMDZYwp8fiZmZmSpK+++kqtWrVyWnYpiCnNOtdi8uTJ+umnn/SnP/1Jf/3rX7Vx40b9/e9/15AhQ0q9jw4dOki6+MbUy7Vu3Vre3t5XvPn0/fffV/fu3RUeHn7N9Rfl0n5Pnz7tNOquotTGawwAAFDye+ABAAB0cQri2bNn9e677zq1nz59Wm+//XalHPObb75RZmamhg4detXjX5o2uWHDhmL3V5p1rsWlkV0ff/yxgoKCNH/+fD311FNl2kezZs0UFham7du3O7X/+OOPys/PV58+fRxty5cvlzFG48aNc1o3MTGx/F9EMcaOHes0Qqyi1MZrDAAAQBgHAACuKioqSq1atdLMmTP16quvat++fYqOjtbUqVP10EMPSZKysrIkSbm5uY7tsrOzJUknT550tF2aunj5epfWLSwsdHyOiYlRVFSU7rnnnqsePzw8XB07dtSnn36qzZs3S5LS0tKUmJio1NRU7d69W/fee+9V17lw4YKjroyMDEctl0Zc5eXlOdoyMjKUm5vrCKneeecdLV26VPn5+crLy9ORI0cc56Qs5s2bp5SUFCUlJTnaNm7cqE6dOmnChAmSpHXr1mnu3LnKz8/XggULtGDBAv3jH//QtGnTtHv3bkkXR9f16NFDmzZtKvF4hw8flnQx9PqjnJwcPfnkk7JYLPL29uYaV9A1BgAAtZz7Xh4BAADcpTxvc9y7d6/p0KGDkWQkmS5dupidO3caY4xJSkoyt912m5Fkxo8fbw4ePGg2btxogoODjSQzbNgws2fPHpOUlGR69uxpJJmRI0eaH374wRhjzJo1a0z37t3NwIEDzcsvv2ymTZtmnn/+eZOfn1+q4xtjzC+//GJCQ0ONJBMYGGhGjx5tbDab6du3r3nnnXdMTk7OVdfZvHmziYiIMJLMrbfeauLi4symTZtMYGCgkWQmT55sjh49ahYvXmwCAgKMJPPyyy+b/Px8s3z5cuPn5+eo79J/AwcONEePHi3Tud61a5e55557zIsvvmj++te/GqvVatLS0owxF9/gWdRxJJk6deo43sL6xRdfGIvFYhYuXFjscT777DPTo0cPx/YhISFmwIABpl+/fua2224zvr6+RpJ5/fXXucYVeI15myoAALVatMWYSphzAAAAqrTo6GhFRUWVa+rh4cOHZbFY1Lp16wqvKycnRxkZGVc876ssx09PT1e9evXk5+en7OzsIp91Vpp1ymrt2rX69ddf1bdvXx07dkznzp3T2bNntXTpUnXt2lXPPPNMmfeZlpamunXrqlGjRuWqKTMzUwEBAeXatrJwja/t5w8AAFR7MYRxAADUQoQBFSs5OVnh4eE6cuSIPD09nZadPn1a0dHR+vbbb6+6n6lTp6pbt26VVSauQWmu8dSpU0u1L37+AACo1WJ4myoAAMA12r17t44ePaoPPvhAAwcOVJs2bXTo0CHt2LFDu3fv1uzZs0s1uq1x48YuqBblUZprDAAAUBqEcQAAANdowoQJOnXqlD7//HM9/vjj8vLyUteuXfXwww9rzpw58vHxUWRkpLvLxDUozTUGAAAoDaapAgBQCzFNrvLk5+fL29vb3WWgEl3rNebnDwCAWi3Gw90VAAAA1CQEcTUf1xgAAFwLwjgAAAAAAADARQjjAAAAAAAAABchjAMAAAAAAABchDAOAAAAAAAAcBHCOAAAAAAAAMBFCOMAAAAAAAAAFyGMAwAAAAAAAFyEMA4AAAAAAABwEcI4AAAAAAAAwEUI4wAAAAAAAAAXIYwDAAAAAAAAXIQwDgAAAAAAAHARL3cXAAAA3Cc6OtrdJUiSjDE6evSoWrRo4e5SUAOdOHFC/v7+8vX1dXcpkqRt27a5uwQAAOBGhHEAANRiUVFR7i4BAAAAqFUsxhjj7iIAAEDtcPz4cSUkJCguLk6rVq3SuXPn1L17d1mtVtlsNgUHB8tisbi7zCovOjpaUVFR4jaudE6cOKENGzbIbrcrNjZWZ86cUefOnWWz2WS1WtWnTx++7wAAgKvEEMYBAIBKtWfPHsXFxclutyspKUl169bVgAEDHEEIU1PLjjCu/C5cuKDt27crLi5Oy5cv1w8//KDGjRtryJAhstlsGjp0qPz9/d1dJgAAqLkI4wAAQMXKycnR1q1bZbfb9cUXX+jXX39VmzZtFBYWJqvVqsGDB1eZZ3dVV4RxFefysHjbtm3y9fVVnz59ZLVaFRERoRtvvNHdJQIAgJqFMA4AAFy79PR0rVq1yjH9NDs7W507d1ZkZCTTTysBYVzluPz7OCEhQVlZWUxnBQAAFY0wDgAAlM8fp5/WqVPHMaIoMjKS6aeViDCu8p0/f15btmyR3W7XsmXLlJqaqtatW2vIkCGM8AQAANeCMA4AAJTO5eHE8uXLlZKSoiZNmigsLIxnbbkYYZzrlfTsQ5vNpubNm7u7RAAAUD0QxgEAgOIxba9qIoxzr0tvBY6JidHatWuVnxrz9NQAACAASURBVJ/v9FbgkJAQd5cIAACqLsI4AADgjAfaV32EcVXHuXPntH79esfPzNGjR3XTTTdp0KBBslqtCgsLk4+Pj7vLBAAAVQdhHAAAtV1R008bN26sIUOGMP20iiKMq5oKCwv1zTffyG63Ky4uTsnJyfLz81P//v0dLzNp1KiRu8sEAADuRRgHAEBtlJGRofj4eMXFxWn16tXKzMxk+mk1QhhXPRw6dEhr1qyR3W7XmjVrVFBQoJ49e8pmsyk8PFydOnVyd4kAAMD1COMAAKgtDh48KLvdrpiYGG3btk0+Pj7q27evrFarHnjgAbVs2dLdJaKUCOOqn7Nnz2rDhg2Ki4vTypUr9dtvvykwMNDxnLm7775b3t7e7i4TAABUPsI4AABqqgsXLmj79u2Ki4vT8uXL9cMPPzhNPx0yZIjq16/v7jJRDoRx1VtBQYG+/fZbRzi+d+9eXX/99RowYICsVquGDx+uBg0auLtMAABQOQjjAACoSU6cOKENGzbIbrcrNjZWZ86ccZp+2rt3b3l4eLi7TFwjwria5dKo1bi4OCUmJsoYozvuuEM2m0333XefOnTo4O4SAQBAxSGMAwCgurv8H/KbNm2Sl5eXY/rp/fffr1atWrm7RFQwwria6+TJk1q/fj2BOgAANRdhHAAA1U1BQYG2bdumuLg4rVixQgcOHNANN9ygoUOHymazKSwsTAEBAe4uE5WIMK52uNrPOlPNAQColgjjAACoDooaLXPp4e+RkZGMlqllCONqp5JGwfISFgAAqg3COAAAqiqeI4XiEMYhIyND8fHxiouL0+rVq5WZmek0nbVPnz6yWCzuLhMAAFyJMA4AgKri8ilpsbGx2rdvn9MbFkeMGMH0U0gijIOz8+fPa8uWLbLb7Vq+fLlSUlLUpEkThYWFyWaz6d5775Wfn5+7ywQAABcRxgEA4E6XTz+12+06ffq0Y/qpzWZTv3795OXl5e4yUcUQxqEke/bsUVxcnOx2u5KSklSnTh3dc889jlFzLVq0cHeJAADUZoRxAAC42h+nnxYWFqpnz56y2WwaMWKEbrnlFneXiCqOMA6ldfz4cSUkJCguLk6rVq3SuXPn1L17d0fgHxwczHRWAABcizAOAIDKdvn0U7vdrr179zpNPx0+fLgaNGjg7jJRjRDGoTxycnK0detW2e12LV26VGlpaWrbtq0GDx4sq9WqsLAw+fj4uLtMAABqOsI4AAAqw6lTp7Ru3TrHCLhTp045TT+9++675e3t7e4yUU0RxuFaFRYW6ptvvnH0UTt37lS9evXUv39/2Ww2DR8+XE2bNnV3mQAA1ESEcQAAVJSDBw86Arg1a9aooKDAMf10+PDh6tixo7tLRA1BGIeKdvjwYa1evVp2u11r167VhQsX1K1bN1mtVo0cOVKdO3d2d4kAANQUhHEAAJRXQUGBvv32W8fIkuTkZF133XW65557ZLVaFR4eroYNG7q7TNRAhHGoTOfOndP69esdb3Y+duwYI3sBAKg4hHEAAJTF2bNntWHDBsXFxWnlypX67bff+EcqXI4wDq7CLx0AAKhwhHEAAFzNL7/8orVr1xY5/dRmszF9Cy5HGAd3KWk6Pm+DBgCgVAjjAAD4oz8+2Dw5OVmNGjXSwIEDHSPgGjVq5O4yUYsRxqEquPxFNXa7XadPn3YaKdyvXz95eXm5u0wAAKoawjgAAKTin5F0KYALCwuTj4+Pu8sEJBHGoeopKCjQtm3bHFP49+/frxtuuEFDhw6VzWZTWFiYAgIC3F0mAABVAWEcAKD2OnTokNasWVPk2wNtNptCQkLcXSJQJMI4VHUHDx50jC7etGmTvLy81LdvX1mtVt1///1q1aqVu0sEAMBdCOMAALXHH6ef7ty5U/Xq1VP//v1ls9k0fPhwNW3a1N1lAldFGIfq5MSJE9qwYYPsdrtWrlypzMxMde7cWTabTVarVX369JHFYnF3mQAAuAphHACgZrt8+qndbtfRo0d10003adCgQUw/RbVFGIfq6sKFC9q+fbtiYmK0YsUKHTlyRI0bN9aQIUNks9k0dOhQ+fv7u7tMAAAqE2EcAKDmOXz4sFavXu2Yfpqfn6/u3bsz/RQ1BmEcaoo9e/Y4flmybds2+fr6qk+fPrJarYqMjFSLFi3cXSIAABWNMA4AUP0VNf20bt26GjBggGw2m8LDw9WsWTN3lwlUGMI41ETp6elatWqV4uLilJCQoKysLHXu3FmRkZGy2WwKDg5mOisAoCYgjAMAVE85OTnaunWr7Ha7li5dqrS0NLVt21aDBw+W1WrV4MGD5evr6+4ygUpBGIea7vI+/osvvtCvv/6qNm3aKCwsjD4eAFDdEcYBAKqP48ePKyEhQXFxcYqPj1dOTo7T9FNGTaAmSk9P1/Lly53a/v3vf2vhwoV67733nNr9/f01evRoV5YHuMTl01mTkpIY/QwAqM4I4wAAVVtJ/wCz2Wxq3ry5u0sEKlVubq4aN26ss2fPytPTU5JkjJExRh4eHo718vPzNW7cOP3zn/90V6mASxw5ckQJCQk8FxQAUF0RxgEAqhamJgFXmjRpkv7v//5PeXl5Ja6XkJCgsLAwF1UFuB9vzAYAVEOEcQAA97t8+umqVat07tw5pp8Cl1m/fr0GDhxY4joNGzZUenq6vLy8XFQVULX88WU+ycnJatSokQYOHCir1arw8HA1bNjQ3WUCAEAYBwBwjz9OP61Tp47uuece2Ww2Wa1WtWjRwt0lAlVGYWGhmjVrpvT09CKXe3t7a9q0aXrzzTddXBlQdf3yyy9au3at7Ha71qxZo4KCAvXs2VM2m03Dhw9Xx44d3V0iAKB2IowDAJSe3W5XVlZWuR4Qf/78eW3ZskV2u13Lli1TamqqmjRporCwMNlsNt17773y8/OrhKqBmuGJJ57QO++8U+xU1a1bt6p3794urgqoHs6ePasNGzYoJiZGcXFxOnXqlAIDAx0jsPv161euUaUzZ87U9OnTddNNN1VC1QCAGoowDgBwdefPn9esWbO0YMECDRgwQOvWrSvVdunp6Vq1apXi4uKUkJCgrKwsde7c2TH6rU+fPkw/BUrpq6++Us+ePYtc1rx5c/3666/8PAGlUFBQoG3btikuLk6xsbHat2+frr/+eg0YMEBWq1UjRoxQQEDAVfdz4sQJNWnSRHXr1tUHH3ygBx980AXVAwBqAMI4AEDJ9u/fr4iICB04cEAXLlyQt7e3Tp48KX9//yLXv3z66bZt2+Tr66s+ffrIarUqIiJCN954o4u/AqDmaNu2rQ4fPuzU5u3traeeekp///vf3VQVUL0dPHjQ8Zy5xMREGWN0xx13KDIyUvfdd59at25d5HaffvqpJkyYoMLCQknShAkTtGDBAkZ5AwCuhjAOAFC8Tz75RNOmTVNBQYHy8/MlSRaLRUuXLtX9998vyXn66fLly5WSkuI0/XTo0KHFBncAyuaFF17Q3LlzHT+Pl+zatUtBQUFuqgqoOU6ePKn169fLbrcrNjZWZ86ccRrR3bt3b3l4eEiSHnjgAcXGxurChQuSJC8vL7Vu3VpLly5V9+7d3fllAACqNsI4AMCVMjMzNW3aNH3++eeyWCy6/K8Kb29v3X///Ro0aJDi4uK0du1anTt3TiEhIY5n73Tv3p3pckAl2L9/vzp16uTU1q5dO/34449uqgioufLy8rRp0ybZ7XbZ7XYdPnxYzZs3l9Vq1dChQzV27FidO3fOaRtPT095eHjo1Vdf1YwZM/i7EABQFMI4AICzHTt2KDIyUmlpaY7f9v9R3bp1ZYxR3759ZbVa9cADD6hly5YurhSonbp06aJ9+/bJGCNvb2+9/PLLevbZZ91dFlDjXZrOGhMTo6SkJJX0zygPDw/1799fn332mZo2berCKgEA1QBhHADgImOM3njjDT311FOSLj7guiQbNmxQ//79XVEagMvMnTtXzz//vCMs//HHH9WuXTs3VwXULpMnT9ann35a7NuNpYsjyQMCArRo0SINHjzYhdUBAKq4GA93VwAAcL/ffvtNgwYN0p///GcVFBRcNYjz8fHR2rVrXVQdgMs9+OCDjp/RkJAQgjjADRISEkoM4iQpPz9fp0+f1pAhQ/T4449f8axHAEDtRRgHALWc3W5Xx44dlZiY6Hgj3NXk5eVp2bJllVwZgKK0adNGoaGhkqRx48a5uRqg9vnuu+/066+/lmrdgoICGWP05ptv6q677tKRI0cquToAQHXANFXABaKjoxUVFeXuMoBKERERoZiYGHeXgSogMjJSS5cudXcZQKVYsmSJRo4c6e4y4Ebcz6Em434OcKkYL3dXANQmS5YscXcJgENubq5Onz6t8+fPKy8vT+fPn1dOTs4Vf87NzXVqz87OVm5urvLy8uTj4+PuLwNVTM+ePfXkk0+6u4waLzMzU2+//baeeeYZd5dSKxDA4HIDBw7UwYMHVadOHfn7+8vHx0d16tRRnTp15O3trbp168rX11fe3t7y8/OTj4+P48/e3t7y8fFRkyZNeNMqqoz58+e7uwSg1iGMA1yI36ijpomMjHR3CahiWrZsSV/nInfffbfat2/v7jJqBcI4XI5npqKmYUQc4Ho8Mw4AAKAaIogDAACongjjAAAAAAAAABchjAMAAAAAAABchDAOAAAAAAAAcBHCOAAAAAAAAMBFCOMAAAAAAAAAFyGMAwAAAAAAAFyEMA4AAAAAAABwEcI4AAAAAAAAwEUI4wAAAAAAAAAXIYwDAAAAAAAAXIQwDgAAAAAAAHARwjgAAAAAAADARQjjAAAAAAAAABfxcncBAKqXY8eOaf/+/erXr1+J62VnZ2vjxo3asmWL5s6dW6nHOnHihN5//33Nnj3bqT03N1eJiYn69ttv1bdvX91xxx3y9PQsVy2XpKSkaOfOndq9e7c8PDzUvn17hYaGymKxKDU1VX379r2m/V+Los7X5s2b9euvvzqt5+3trcaNG6tFixZq3769i6sEqofq1NeVdT+lQV8H1GzVqY/LysrSokWL9Msvv6hdu3YaPXq06tWrV65aLqGPA+BujIwDUCrp6emaOXOmAgMDtXz58quun5CQoBkzZujzzz+v9GNNnjxZ//jHP5zajh8/rk6dOunIkSOaOHGiVqxYoeHDh6ugoKDM9UhSXl6enn76aXXo0EFbt25VcHCwevfurYMHDyokJESBgYHasWNHufZ9rUo6X0FBQfr55581evRoTZgwQZmZmUpPT5fdbldUVJRuuukmPf/888rPz3dL7UBVU936uvLspyT0dUDNVt36uAMHDqhDhw6aN2+e5s+frylTpigoKEjHjh0rcz0SfRyAKsQAqHRLliwx1f3HbceOHWbXrl1GkpkxY0apthk5cqQJDAys1GO9//77pn379qZp06aOtoKCAtO3b18THh7uaLtw4YJp06aN+ctf/lLmenJyckxwcLBp0KCB+fLLL69Y/tNPP5lWrVqZ//zP/yzzvivC1c5XSkqKkWQ6derk1F5YWGhiYmJMQECAGTRokMnMzCzzsSMiIkxERES5a0fNUhO+H6pTX3ctNReFvq54ksySJUvKXTtqBu7nKu9YxfVxQ4cONbt27TLGGHP8+HEzefJkI8lMnDixzPXQxxWvJvz9DVQz0YyMA1AqoaGh6tixY5m28fDwkIdH2buZ0h7rhx9+0DfffCOr1erUvnnzZm3ZskVTpkxxtHl6emr8+PFasGCBzp49W6Z6XnnlFe3cuVNPP/10kdMWbr75Zr3wwgtl3m9Fudr5CggIKLLdYrEoIiJC77//vtauXas777xTeXl5lVUmUC1Up76urPu5Gvo6oOarTn1ccnKyxowZo6CgIElS48aNNWfOHHl4eCgpKanM9dDHAahKeGYcUIVlZ2drxYoVOnDggLp27aqwsDA1aNDAsTwrK0vx8fHat2+fWrVqpcGDB6tVq1aO5SkpKVq2bJkee+wx7d27VytXrlTr1q01ZswYeXh4aOPGjY6h+Ndff70mT54sSdq0aZO++uorNWnSRA8//HCp6z158qSWLl2qQ4cO6fbbb5cxRhaLpYLOhrP8/Hw9//zz+vDDD/XSSy85LVu2bJkkqWvXrk7tt956q86ePav4+HhFRkYqIyNDCxcu1MSJE9W0adMij3Ps2DH993//t+rVq6cZM2YUW8/48eMVGxvr+FzVrk1JoqKi9Mknnyg+Pl47duxw63NSUDvR1xWvpL6utOjrLqKvg7vQxxWvpD6ubdu2Cg4Odmpr3ry5QkJC5OX1+z9j6eMuoo8DqhdGxgFV1P79+xUVFaWgoCC99NJLWrFihW6++WYdPHhQkrRr1y716dNH3t7emj59uk6fPq3OnTvrk08+kSTZ7XaFhIToiSee0BtvvKHXXntN27dv17hx4xwP4O3fv7+SkpL0zDPP6NZbb3Uc++6779Z7772nwYMHl7reAwcOaMiQIeratavmzJmjjIwMrVixotJu3ubMmaMnnnhC9evXv2LZTz/9JOniDdvlmjRpIunib2AlacWKFXr22WcVHR1d7HG++eYb5efnKzAwsMhjXeLj46OIiAhJVe/alEbPnj0lSV9++WWF7he4Gvq6kpXU15UWfd3v6OvgavRxJSupj7v++uuLPG5KSoqGDh3q+Ewf9zv6OKD6IIwDqqCCggKNGjVKI0aMUFBQkLy8vDRz5kxlZWVp7969ysvL04MPPqj77rtP999/vxo3bqynnnpK4eHhmjJlivbu3SubzaZJkyZJujhC7KOPPpLdbldwcLC++OILx7Hmz58vDw8PxcXFOdqOHDmigQMH6sYbbyx1zePHj1e/fv3Uq1cveXl5acqUKWXaviwSExPl5eWl3r17F7n8t99+k6enp3x8fJzaL7156+jRo5KkUaNGadGiRZowYUKxx/r+++8lSTfddFOpaquK16Y0Lt0gcvMGV6KvK9nV+rrSoq/7HX0dXIk+rmTl6eM2b94sLy8vPfnkk442+rjf0ccB1QdhHFAFxcfH69tvv9WwYcMcbcHBwcrKypLValVCQoL279/v+O3XJWFhYcrLy9OHH34oSapbt64kOT1/onPnzjpy5Ijjc2BgoIYMGaKPPvpIFy5ckCR99NFHmjp1aqnr3bBhg7766iv179/f0WaxWByviK9Ip0+f1oIFC/Tcc88Vu46/v3+R7ZfepNqsWTNJkp+fn0aNGlXib0gvTYMo7VtYq9q1Ka3s7GxJF88J4Cr0dcUrTV9XWvR1v6OvgyvRxxWvPH1cQUGBXnzxRcXGxjrd69HH/Y4+Dqg+COOAKmjXrl3y8/NT48aNndovjfTau3evpCtDpzvvvFOStG/fvmL37enpKWOMU9v06dN19OhRxcbGqrCwULt27dLtt99epnolOQ2/l1QpUxqefPJJhYaGKjY2VsuWLdOyZcv0448/6vz581q2bJk2bNigVq1aqaCgQLm5uU7bZmVlSbp4k1RaXbp0kST9+OOPpVq/ql2b0tq5c6ck6Y477qjwfQPFoa8rXmn6uopEXwdUPPq44pWnj5s5c6b+/Oc/q3v37mU+Hn0cgKqGFzgAVVBhYaHOnj2rjRs3Fvksieuuu06StG3bNsdNgSS1adNG3t7eatSoUZmON3ToUAUGBuq9995TnTp1nJ7DURqZmZmSpK+++srpobZSxd/Apaena+3atU5tZ86c0blz5zRjxgx16dJFd911l6SLzxRp166dY72MjAxJZQvjQkJC5O/vr4MHD+rnn3/WzTffXOL6Ve3alIYxRl9++aU8PT01aNCgCt8/UBz6uuKVpq8bMGBAhR2Pvg6oePRxxStrH/f++++re/fuCg8PL9fx6OMAVDWMjAOqoEtvAV20aJFT+4kTJ7R8+XLHb7s2b97stPz7779Xfn6+evXqVabjWSwWPfLII1q7dq3mzZun0aNHl6veih6pUZS4uDilpqY6/ffII4+ocePGSk1N1erVqzVp0iT5+vpq69atTtsmJyerW7du6tChQ6mPd/311+s//uM/VFBQoFmzZpW47jfffFPlrk1pPPnkk0pOTtarr76q2267rcL3DxSHvq54penrKhJ9HVDx6OOKV5Y+bvny5TLGaNy4cU77SExMLPXx6OMAVDWEcUAVFB4eru7du+uf//yn/vSnP2n9+vWaP3++Jk6cqHvvvVe33Xabxo8fr82bNzs9k2LLli1q37694xkUl37DmZeX51gnIyNDubm5VwyfnzhxourUqaN27doV+8yNU6dOSZLOnz9/Rb0dO3bUp59+6rhpSUtLU2JiolJTU7V7927HMzJKq7hjlUazZs30//7f/9Orr77q+DrPnz8vu92uDz/8UB4eF7u+5ORk9ejRQ5s2bSpxfzNmzNDIkSO1bNkyTZkyRTk5OU7LDx8+rKlTpyo7O7vKXRtJOnTokCRdUfehQ4c0ffp0vfHGG3rsscecHoYMuAJ93bX1daXdD30dfR3cgz7u2vu4devWae7cucrPz9eCBQu0YMEC/eMf/9C0adO0e/duSfRx9HFANWUAVLolS5aYsv64paammkGDBhmLxWIsFovp16+fSU1NdSzPyckx06dPN126dDH/+7//az744AMzbNgwc+TIEWOMMZs2bTKBgYFGkpk8ebI5evSoWbx4sQkICDCSzMsvv2zy8/Odjjlx4kSTnJxcZD3x8fEmKirKSDJNmjQxCxcuNEePHnUs/+WXX0xoaKiRZAIDA83o0aONzWYzffv2Ne+8847Jyckp9dd+tWP90dNPP22aNm3q1FZYWGj+8pe/GKvVat544w0ze/Zs88knnzit88UXXxiLxWIWLlxYqro+/fRT07p1a9O0aVMTHh5uJk6caDp06GBGjhxp9u/f71ivKl2b2NhY069fPyPJSDK9evUygwYNMsOGDTPDhw83Tz31lPn6669L9fUXJSIiwkRERJR7e9Qs5fl+oK+7tr6uNPuhr7v2vk6SWbJkSbm3R83A/Zxr+7jk5GTj5+fn+Lm+/L86deqYEydOGGPo47ifA6qlaIsxf4jsAVS46OhoRUVFXfEbstI4ffq0CgsLHc+u+KMzZ85oz549at26tVq2bHlNdZ47d0716tW7pn2kp6erXr168vPzU3Z2drFvNnWVgoICZWRkqGnTpkUuz8zMVEBAQJn2eerUKX3//ffy9vZWhw4dqs21qQyRkZGSpJiYGDdXgqrgWr4f6OsqF33dtbFYLFqyZIlGjhzp7lLgRtzPVV30cdeG+znA5WJ4gQNQxTVs2LDE5Q0aNFDv3r0r5FgVcXNw+RvDLr9xe/TRR6+67dSpU9WtW7drruFynp6exQZxksp84yZJjRo1cnqYb3Gq2rUBqjL6uspFXwe4F31c5aKPA1DdEMYBcIn+/ftfdZ3Lb/wAoDqirwNQk9HHAUDFIIwD4BKXhr8DQE1GXwegJqOPA4CKwdtUAQAAAAAAABchjAMAAAAAAABchDAOAAAAAAAAcBHCOAAAAAAAAMBFCOMAAAAAAAAAFyGMAwAAAAAAAFyEMA4AAAAAAABwEcI4AAAAAAAAwEUI4wAAAAAAAAAXIYwDAAAAAAAAXIQwDgAAAAAAAHARwjgAAAAAAADARQjjAAAAAAAAABchjAMAAAAAAABcxMvdBQC1icVicXcJQIWLiIhwdwmoQpYuXUpfB6BGo49DTcT9HOBaFmOMcXcRQE2XmpqqpKQkd5fhNmfPntX//M//6PDhw3r99dcVEBDg7pJQgVq1aqVevXq5uwxUAdu2bVNKSoq7y6gVtm3bptdff11Llixxdym1Ru/evdWyZUt3lwE3qu33czXVl19+qbfeeksjR47U/fff7+5y3Ib7OcClYgjjAFSqtLQ03XvvvTp+/Lji4+PVrVs3d5cEANVedHS0oqKixG0cAFy7jz76SNOmTdNDDz2k9957T97e3u4uCUDNFsM0VQCVZs+ePRo6dKgCAv4/e3ceH0WV7n/829kICQTZBCRh3wQJsiQkEDYVUEBkrmwCyh1EFFEZUBi8LsM4OHMdRxnUUQS54zbwg4AgjiiCECALBgOEHRQQCDthSwJJOsn5/eErPTRZ6EDS1Uk+79crf6S6qs7TVX366X761Kkgbd68WY0aNbI6JAAAAMDJuHHjFBwcrKFDhyolJUVLly7lSg4AZYobOAAoE+vXr1f37t3VvHlzxcbGUogDAACAx+rXr59iY2O1Z88eRUVFKSUlxeqQAFRgFOMAlLply5ZpwIABuu+++/TNN9/otttuszokAAAAoFihoaGKjY1VTk6OIiIilJycbHVIACooinEAStWcOXM0fPhwTZgwQUuWLJG/v7/VIQEAAAAuadKkieLi4tSiRQv17t1bMTExVocEoAKiGAegVBhjNH36dE2ZMkV/+ctfNGfOHHl58RYDAACA8qVmzZpavXq1BgwYoP79++vzzz+3OiQAFQw3cABwy7KysjR27FitWLFCCxcu1MiRI60OCQAAALhpVapU0eeff66WLVvqscce088//6yZM2daHRaACoJiHIBbcuHCBQ0ZMkQ7d+7U6tWr1atXL6tDAgAAAG6ZzWbTzJkzFRwcrIkTJ+rYsWOaO3eufH19rQ4NQDlHMQ7ATTt+/LgGDBigc+fOaf369erQoYPVIQEAAAClavz48apbt65GjRqllJQURUdHKygoyOqwAJRjTOgE4Kbs2rVLERERysvL0+bNmynEAQAAoMJ66KGHFBMTo+TkZPXo0UPHjx+3OiQA5RjFOAAltm7dOkVFRally5aKjY1VSEiI1SEBAAAAZSosLEwJCQnKzs5WVFSU9u7da3VIAMopinEASuTzzz/XAw88oL59+2rVqlWqUaOG1SEBAAAAbtG0aVPFxcUpJCRE3bt314YNG6wOCUA5RDEOgMvmzJmjsWPH6qmnntLixYvl7+9vdUgAAACAW9WqVUtr1qxR//79tIwOowAAIABJREFU1b9/fy1cuNDqkACUMxTjANxQbm6unnnmGU2ZMkVvvPGG5syZIy8v3j4AAABQOVWpUkULFy7UjBkzNGbMGM2cOdPqkACUI9xNFUCxsrKy9Nhjj+nLL7/UokWLNGLECKtDAgAAACxns9k0c+ZM1apVS1OnTtXx48f1wQcfyMeHr9kAise7BIAinT9/XkOGDNGuXbu0Zs0a9ejRw+qQAAAAAI/y3HPPqVGjRho9erSOHTum6OhoVa9e3eqwAHgwrjMDUKhffvlF3bt317FjxxQXF0chDgAAACjCkCFDtH79em3btk333nuvTp8+bXVIADwYxTgABezcuVNRUVHy9fXVpk2bdOedd1odEgAAAODRwsPDlZCQoMuXLysyMlL79u2zOiQAHopiHAAn33//vaKiotSmTRtt2rRJwcHBVocEAAAAlAvNmjVTfHy8GjZsqG7dumnjxo1WhwTAA1GMA+Dw6aef6oEHHtBDDz2kb775RjVq1LA6JAAAAKBcqVWrltauXat+/fqpX79+WrRokdUhAfAwFOMASJLmzJmj//7v/9bEiRP18ccfy9fX1+qQAAAAgHKpSpUqWrRokSZPnqzRo0dr5syZVocEwINwN1WgksvNzdWzzz6refPm6d1339WkSZOsDgkAAAAo92w2m9544w3dcccdmjp1qk6cOKH3339fPj58DQcqO94FgEosMzNTjz76qL766istWrRIw4YNszokAAAAoEKZPHmyGjVqpNGjR+vMmTNauHChAgICrA4LgIW4TBWopM6fP6/77rtP69at09q1aynEAQAAAGXkN7/5jdatW6f4+Hj16dNHZ86csTokABaiGAdUQocPH1a3bt10/PhxxcXFKSoqyuqQAAAAgAotIiJCCQkJunjxoiIjI7V//36rQwJgEYpxQCXz448/KjIyUlWqVFFsbKzatGljdUgAAABApdC8eXPFx8erQYMG6tatmzZt2mR1SAAsQDEOqETWrFmje++9V+3bt9emTZvUsGFDq0MCAAAAKpXatWtr7dq1uvfee9W3b18tXrzY6pAAuBnFOKCS+OSTTzRw4EANGTJEq1atUlBQkNUhAQAAAJWSv7+/Fi1apCeeeEKPPPKIZs6caXVIANyIu6kClcAbb7yhF198Uc8++6z+/ve/y2azWR0SAAAAUKl5e3vr3XffVYsWLTR16lRduHBBs2fPlpcXY2aAio5iHFCB5ebm6plnntH8+fP1j3/8QxMnTrQ6JAAAAADXmDx5soKDg/Xoo4/q6NGj+te//qWAgACrwwJQhii5AxVURkaGhgwZok8//VTLly+nEAcAAAB4qIcffljff/+9YmNjdc899+jMmTNWhwSgDFGMAyqg1NRU9evXT/Hx8fruu+/04IMPWh0SAAAAgGJERkYqISFB58+fV2RkpA4cOGB1SADKCMU4oII5dOiQunXrppMnTyo+Pl7du3e3OiQAAAAALmjRooU2btyoWrVqqVu3boqNjbU6JABlgGIcUIFs2bJFkZGRCgoKUkJCglq3bm11SACAW2S323XhwgWnv4yMDEkqsPzixYsWRwsAuFX169dXTEyMunXrpr59+2rJkiVWhwSglHEDB6Ac2bp1qzp16lToY999952GDh2qiIgILVu2TNWrV3dzdACAspCamqrg4GDl5uYWeKxWrVpO//fu3Vvr1693V2gAgDISGBio5cuX67nnntOoUaN0+vRpPfvss4Wue/jwYdWvX19Vq1Z1c5QAbhYj44ByYtOmTYqIiND3339f4LF//vOfGjRokB5++GF9/fXXFOIAoAKpX7++evbsKS+v4j+22Ww2PfLII26KCgBQ1ry9vfWPf/xDb731ln73u99p8uTJysvLc1onNTVVffv21VtvvWVRlABuBsU4oBwwxui5555TTk6OBg8erOTkZMdjb7zxhsaNG6epU6fq//7v/+Tr62thpACAsvDoo4/KZrMVu46Xl5cefvhhN0UEAHCXyZMna/HixZo3b56GDRumq1evSpIyMzM1cOBAHTp0SH/+85918uRJiyMF4CqKcUA5sHDhQiUnJ8sYo+zsbPXt21eHDh3Sk08+qZdeeklz587V//7v/97wixoAoHx6+OGH5e3tXeTj3t7euv/++1W7dm03RgUAcJehQ4fq+++/18aNG3XPPffo9OnTGjVqlJKSkmSMUU5Ojl588UWrwwTgIpsxxlgdBICiZWZmqnnz5jp16pRjWLqvr6/q1KmjS5cuacmSJRo4cKDFUQIAytpDDz2kVatWKScnp8BjXl5e+te//qWRI0daEBkAwF327NmjAQMGqH79+tqyZYvTZas2m01btmxR586dLYwQgAuiGRkHeLi///3vOn36tFOitdvtOnfunFq0aKE+ffpYGB0AwF3GjBlT6E0cJMnPz0+DBg1yc0QAAHdr27atJk2apB9++KHA/HHe3t6aPHmyRZEBKAlGxgEe7OzZs2ratKkyMjIKfdzHx0f333+/VqxYUezlSwCA8i8zM1N16tQpkBN8fHw0bNgwLVy40KLIAADu8tVXX2nIkCEFCnHXWr58uYYMGeLGqACUECPjAE/2hz/8QdnZ2UU+npOTo1WrVmnSpElujAoAYAV/f3/913/9V4Eb9eTk5Gj06NEWRQUAcJctW7Zo+PDhKm48jZeXl5577jllZWW5MTIAJUUxDvBQ+/bt07x582S324tdzxijDz/8UO+9956bIgMAWGXUqFEF8kJQUJD69u1rUUQAAHc4ePCgHnjgAWVlZRVbjMvLy9OJEyf0/vvvuzE6ACVFMQ7wUC+88IK8vIruoj4+PpKk9u3b66OPPtK4cePcFRoAwCL33XefatWq5fjf19dXI0eOlJ+fn4VRAQDKWkhIiD744AP17NlTNput2Pf93Nxc/eEPf1BqaqobIwRQEhTjAA8UExOjr7/+usDoB5vNJm9vb/n6+mrIkCFas2aNkpOT9fjjjysgIMCiaAEA7uLj46ORI0c6LlW12+0aNWqUxVEBAMqan5+fhg0bppiYGB04cEBTpkxRrVq1HN8PrpeZmamZM2e6P1AALuEGDoCHycvLU6dOnbR7927l5ORI+vXLV05Ojpo0aaKnnnpK48ePV+3atS2OFABghdjYWPXo0UOSVK9ePZ04caLYkdQAgIopOztbX375pd5//31t2LBBPj4+Tj/me3t7Kzk5We3atbMwSgCF4AYOgKf517/+peTkZOXk5MjHx0fe3t4aPHiwvv/+ex06dEi///3vKcQBQCXWvXt33XHHHZKkRx99lEIcAFRS+aPl1q9frz179uiZZ55RUFCQvLy85O3trby8PL3wwgtWhwmgEAVGxiUkJOjtt9+2Kh6gUsvNzdU333yjzMxM+fv7q3nz5mratKn8/f2tDg0o1tSpUxUZGVkm+x42bFiZ7Bcoz3bu3Kn9+/fr3nvvVc2aNa0OB/AokZGRmjp1apns++2331ZCQkKZ7BsoDbm5uUpJSdHBgwd1/vx5SVKPHj1Ur149iyMDKq/o6OgCiwr8lHrs2DEtXbrUPREBcPLTTz/ptttuU7du3TRw4EDdeeedFOLg8ZYuXapjx46V6f5TUlLKbP9AedSoUSNVr16dQhxwnc2bN5dpsSwhIUGbN28us/0Dt8rb21uNGzfWPffco379+qlFixbau3dvsXdgBVA2UlJSiqyv+RS1USGVOwBl7OzZs6pbt67VYQAlYrPZyryNKVOmaPjw4WXeDlCeLFmyhH4BXMcdo6kjIiL4roRy5cqVKzLGKDAw0OpQgEplyZIlGjFiRKGPFVmMA+B+FOIAAK6iEAcAcEVAQIDVIQC4DjP+AgAAAAAAAG5CMQ4AAAAAAABwE4pxAAAAAAAAgJtQjAMAAAAAAADchGIcAAAAAAAA4CYU4wAAAAAAAAA3oRgHAAAAAAAAuAnFOAAAAAAAAMBNKMYBAAAAAAAAbkIxDgAAAAAAAHATinEAAAAAAACAm1CMAwAAAAAAANyEYhwAAAAAAADgJj7uaCQ7O1ubNm3Sv//9b/Xt21cDBgxwabv09HR9//332r59u/7whz+4tW04K+o4Hjp0SLNmzdJrr72m4ODgMmv/1KlT2rdvn3r37l3seunp6Vq/fr1iY2P1xhtvlGlbqampmjdvnl588UWn5VlZWdqwYYO2b9+uqKgode3aVd7e3jcVS77jx49r69at2r59u2w2m1q0aKEuXbqoZs2a+uGHHzRgwACP62fr1q3T6dOnJUk2m03Dhg0r9jhs2rRJKSkpjv8feughBQQE3FQ819q4caOOHz/utMzf31/BwcFq1aqVatSoccttXMsT+0phx8DX11d169bVHXfcoZYtW5ZZPJ7I0/oKSs4T+1lhPCEnlXQ/riAn3TxyEjmpMJ7WX1ByntjXCuMJeSktLU0LFy7U4cOH1aJFC40aNeqW31/JSzePvGRhXjLXWbx4sSlk8S1JSkoyEyZMMJLM/PnzXd7un//8p6lTp45p3bq129uGs6KOY3R0tJFkVq1aVSbtnjlzxjz//POmatWq5rnnnrvh+tHR0aZJkyamUaNGZd7WkCFDTL169ZyWnT592jRt2tTMnz/fnD171kybNs0MHDjQ5OTklDgeY4zJzs4206ZNM76+vmby5Mnmyy+/NLGxsebdd981DRs2NDabzUydOtUY43n97OrVq2bBggVGkpFkFi9eXOT26enppmbNmkaS6dixo9m1a9dNx3K91NRUM336dCPJNGjQwCxYsMDMnDnT9OvXzwQEBJhJkyaZzMzMUmvPE/vKhQsXzJ/+9Ccjyfj5+Zm5c+ea999/3zz//POmY8eOpkmTJuall14y2dnZN9X2jc7vrSrt/XtaX0HJeWI/K4zVOelm9lMcctKtIyeVfU4aOnSoGTp0aGk8Dbft39P6C0rOE/taYazOS/v27TP169c3LVu2NH5+fkaSad68uTl58mSJ4zGGvFQayEtlm5eKqa8tcUsxzhhjkpOTb+pN/v7777+lF/6ttA1nRR3Hs2fPllmbiYmJjnZd/RIxfPhw06xZszJta968eaZly5ZOCSY3N9dERUWZwYMHO5bl5OSYxo0bm9///vcljicjI8OEh4eboKAg88MPPxR4/Pz586ZNmzZm4sSJjmWe1s8yMjKMj4+PkWS6dOlS5Lb/+Mc/zO23324kmRdffPGW4ijM3r17jSTTs2dPp+WvvfaakWQee+yxUm3PE/vKsWPHjCRz5513Oi3Py8sz0dHRJigoyPTt29dcvny5xG2Xt2KcMZ7XV1ByntjPCmNVTrqVmAtDTio95KSyzUnlsRhnjOf1F5ScJ/a1wliZlx544AGTnJxsjPm1ODJ+/HgjyYwbN67E8ZCXSg95qezyUnHFOLfNGefj8+sVsTabrUTbeXt7l3ib0mobzoo6jnXq1CmzNsPCwtSmTZsSbePl5SUvr5K/tF1t68CBA9q2bZsGDRrktHzjxo2KjY3VE0884Vjm7e2tsWPH6r333lNGRkaJ4nn99deVmJio//mf/1F4eHiBx2vWrKk5c+boypUrjmWe1s8CAgLUpk0btW3bVj/++KPWr19fYDtjjD788EONHz9eklS9evVbiqMwQUFBhS6fNGmSvLy8tGTJEmVnZ5dae57YV4o6BjabTUOHDtW8efO0Zs0a9ejRo1SPhafytL6CkvPEflYYq3JSSfdzI+Sk0kNOIicVxtP6C0rOE/taYazKS0lJSRo9erRCQ0MlSXXr1tVrr70mLy8vxcfHlzge8lLpIS9Zk5dKbc649PR0ffbZZzp69Khatmyp8PBw3XnnnTecKystLU2rVq3S3r17FRISon79+ikkJKTQdePj47V69WqFhobq4YcfdnrswIED2rx5s3bs2KHu3bvrN7/5zS0/p6tXr+rLL7/U4MGDdebMGa1atUp33HGHHnzwQXl7e+v06dNauXKlvLy8NGzYsAInsKiYdu7cqaSkJEm/dux+/fpp69atOn36tHx9fTV8+HD5+vq6FGNKSopWrlypiRMnasOGDVq9erUaNmyoxx9/XFWrVnWs58pxLsm5yJeXl6cNGzaoWrVqCgsLkyQdO3ZMX3zxhZ599lnt2bNHX375pRo1aqTRo0c7vfHf7GvmeufPn9fSpUv1yy+/qEuXLjLGlNmHCbvdrpdfflkLFiwoMGfAF198IUlq37690/K77rpLGRkZWrVqlYYNG6Zz585p/vz5GjdunOrVq1doOydOnNDf/vY3+fv763e/+12R8fTr10+33377DeO2sp95eXnp+eef129/+1u9+eab6tOnj9Pj33zzjcLCwoo8FsW1e6t9yd/fX15eXsrLy3Msq8h9pTgjRozQp59+qlWrVikxMVFRUVGltm8rkJPISZU9J7mKnEROIie5B3mJvFTZ81KTJk3UqVMnp2UNGjRQ586dHcUZibxEXqpEeakEw+iKdP78edOqVSuzceNGk56ebn7zm98YSSYsLMz87ne/M8YYs3v3biPJfPTRR47ttm/fbtq3b2+WLVtmzpw5Y/72t7+ZatWqmU8++cSxzsCBA03Tpk3NoEGDzMCBA82dd95pJJkxY8Y41pk9e7bp3bu3ycvLM4cPHzZNmjQx77//vuPxwtq+kZiYGNOyZUsjybz11ltmwoQJZvr06SYgIMA8/PDDZv78+Wb06NFm5MiRxmazmQcffNBp+xvF9PHHHzs9j2+//db06tXLnDt3zuUYP//8c1OzZk1TtWpV89RTT5lx48aZAQMGOI59/jXNrhxnV9a5/jju3r3bDB061EgyH3zwgTHGmJUrV5q6desaSWb27Nnmt7/9rRk0aJCRZP785z879uXKayZfVlZWkcNJ9+3bZ8LCwkx8fLyx2+3mww8/NFWqVDGtWrVy+Ti62pYxxrz88ssmLi7OGGPMlClTnIZeP/DAA0aSycrKctomJibGSDKzZs0yxhgzf/58I8m88847Rcbx5ZdfGkklHg7tif0sNDTUZGVlmYYNGxpJZseOHU6P9+3b1+zevdvMmTOnwOvElXZd6UvHjx8vdOj1F198YSSZe+65x+VjVV77yqVLlwoden2t/KHo15+DG5GHXaZKTiInkZNc3w85iZxkTMXKSZ54mSp5ibxEXipa/fr1zWuvveb4n7xEXjKm4uSlMp8z7sUXXzSNGzd2/J+UlOQ4aPmuP+BZWVmmTZs25tVXX3Xa16hRo4yfn5/ZvXu3MebXF76fn5/Zt2+fMebXa3YfeughI/1ncr8WLVqYSZMmOfYxZMgQM2DAgCLbdtXbb79tJJno6GjHshkzZhhJZtmyZY5lL730kqlSpYrJzc11LLtRTMYYM2bMGOPv728OHDhgBg0aZE6dOlWi+PL3YbPZnCZxfOWVV4wkM3fuXJeOs6vnorDjuGPHDqdOc+0xWrt2rWNZp06dTOfOnR3/u/KayVdcp+natauZNm2a4/+8vDzTrFmzMkkwMTExZubMmY7/r08wnTp1Mt7e3gW2S0xMNJIcr4f09HSzcOHCYq83//Of/2wkmfvvv7/Qx9euXWuefvppM378eDN+/Hjz6quvmrS0NI/sZ6GhocYYY958800jOc85sHPnTvPAAw8YY0yRCaY0+lJ+gunSpYs5fPiwiYmJMW+++aYJCAgwHTp0MCdPnqzwfcWVBJOfcPPPias8rRhHTiInkZNc3w85iZyUr6LkJE8sxpGXyEvkpcJt2LDBBAcHm7S0NMcy8hJ5KV9FyEtlPmfcwYMHdfbsWce1sx06dFBgYKCOHTtW5Dbffvut9u3bp4iICKfl/fv3V3Z2thYsWOBY1q5dO7Vu3VrSr9fsTpw4UZL09ddfS5JiYmI0a9YsSdKePXt07Ngx/fTTT7f8vPJv43vtZYf5cXTo0MGxrE2bNsrKytKJEyccy1yJac6cObrtttsUGRlZ7DDc4gQGBsrHx0ft2rVzLJsxY4Z8fHy0ceNGl45zSc7F9apUqVJgWf6Q72uvyW7btq2OHj3q+P9mXjPXW7dunX744Qenobw2m01hYWGlPvT64sWLeu+99/TSSy8VuU61atUKXZ6bmytJql+/vqRfz9kjjzxS7PX++cf12iHB17r33ns1bdo0ffTRR/rkk080ZcqUQtv3pH42YcIE1ahRQ4sWLXLclnvOnDl6/vnni92uNPvS8ePH9Ze//EXR0dHKycnRqlWrtH37dtWvX79C9xVXpaenS/r1NVqekZPISdeqrDnJVeQkclI+clLZIS+Rl65FXvpVbm6uXn31Va1cudIpZ5CXyEv5KnpeKpViXJ8+fXTlyhXFxsZKki5cuKDs7Gz17du3yG327NkjqWABo0ePHpKkvXv3FrltRESEvLy8HG/oDRs2VGJiop577jnt3btXzZs3L7Jj3ip/f/8Cy/Kvs752gn5XYqpVq5ZmzZql1NRUx4ktDQEBAQoODtbZs2ddOs63ci5c5e3tLWOM4/+bec1cLzk5WdKvc7JdqyzmQJgyZYrCwsK0cuVKffHFF/riiy/0008/KTMzU1988YXWrVunkJAQ5ebmKisry2nbtLQ0Sb++cbgqfz6F4t7AmzRpIi8vL7Vs2VK33XZboet4Uj8LCgrSk08+Kbvdrr///e86d+6cdu3apXvvvbfY7UqzL7Vs2VIffvih3nvvPc2YMUO9evVyPFaR+4qrtm7dKknq2rVrqe/bnchJ5KQbqQw5qTSRk/6DnEROuhnkJfLSjVTGvPTCCy9o6tSp6tixY4nbIy/9B3mp/OalUrmBw/jx4/Xzzz/rqaee0uuvv67169frL3/5i+6///4it6lVq5YkKSEhwXFyJKlx48by9fVVzZo1i9w2KChI1apVU7NmzSRJr7zyimNCzqpVq2rZsmWl8bRuiSsx5eXl6euvv1ZERIQmT56svn37OkZP3YqsrCydOnVK/fv3d+k438q5uFk385q53uXLlyVJP/zwQ4EJIUs7yZw9e1Zr1qxxWnbp0iVduXJFzz33nNq1a6eePXtK+nWiyRYtWjjWO3funKSSFeM6duyowMBAHTlyRIcPH1bTpk0LXc/Ly6vY5+pp/Wzy5Mn6+9//rnnz5slms+npp5++4Tbu6ksVua+4whijTZs2ydvbu0ySlzuRkwoiJxWvIuake+65p9TaIyf9BzmJnHQzyEsFkZeKV9Hz0rx589SxY0cNHjz4ptojL/0Hean85qVSGRnn4+OjBg0a6J///KdCQ0M1e/bsGw6nzK8mbty40Wn5rl27ZLfbFRkZWeS227Zt0+XLl/XAAw/o8OHDmjVrlsaMGeMYxlhWv/S4ytWYZs+erYceekgLFy5Udna2Y6jrrdq8ebMyMzM1aNAgl47zrZyLm3Uzr5nr5Q+JL+0RAIX597//rZSUFKe/iRMnqm7dukpJSdHq1av1+OOPq0qVKoqLi3PaNikpSXfffbdatWrlcns1atTQBx98oLy8PE2dOvWm47a6nxljnG4nfscdd2jMmDFKS0vTokWLNHLkyGK3L62+dO2vJ0WpyH3FFVOmTFFSUpLefPNNp0tLyiNykjNy0o1VxJxUmshJvyInkZNuFnnJGXnpxipyXlq+fLmMMXrsscec9rFhwwaX2yMv/Yq8VL7zUqkU4z744AMtXbpUdrtd2dnZOnr0qOPSvHyXLl2S9J/rbDt06KCxY8dq48aNTtf8xsbGqmXLlpowYYJjWXp6utOLKjo6WiNGjNC9997r2N+iRYt0+fJlbdq0SRs3btSFCxeUnp6utLS0Am27Kv85XHvZYf4+zp8/71iWP+Q6fz1XYtq1a5diYmI0duxYNW3aVK+88opWrFihzz//vEQxSlJOTo7TkM+lS5eqV69eGjRokEvH2dVzUdhxzH/O+aO/pP/8CpN/3Xb+41lZWY6O7sprJt+FCxckSZmZmU7LBw8erDZt2uizzz5zdPgTJ05ow4YNSklJ0Y4dO5STk+PSMbxRW66oX7++nnnmGb355puO55mZmamvvvpKCxYscNx+OSkpSeHh4YqJiSl2f48++qh+97vfacWKFXryySed3qglKTU1Vbm5uU63bPa0fnby5EkdP37c6Xi+8MILstlsevbZZ51upZ1/7I8cOeIU043adaUvXbx4UZL0yy+/FHm8K3Jfufa5X716tcDySZMm6Z133tGzzz6rKVOmFHmMygtyEjmJnOT6fshJ5KR85KSyQ14iL5GXfrV27Vq98cYbstvteu+99/Tee+9pzpw5evLJJ7Vjxw5J5CXyUiXKSyW420ORli9fbgIDA40kp7/77rvPnDx50vzwww+mf//+RpLp2LGj444jV69eNZMmTTLt2rUzH3/8sfnoo4/MwIEDzdGjRx37/u6770zHjh3NfffdZ2bOnGmefPJJ8/LLLxu73e5YZ9y4ccbHx8e0aNHCzJ071yxdutT4+fmZe+65x3zzzTeFtn0j8fHxpkOHDkaSGTt2rDl06JBZv3696dSpk5FkBg4caHbv3m3i4+NNRESEkWSGDx9uDhw4cMOYli5dapo0aWJeeOEFk5eXZ4wx5l//+peRZPz9/c38+fNdPvZPPvmk8fb2Ns8884yZNm2aGTlypHnwwQed7j7jynG+0TqFncPNmzc7bkF81113mX//+98mJibGNGvWzEgy48ePNydPnjSLFi0yQUFBRpKZOXOmsdvtN3zN5Fu1apUZMWKEkWRuv/12M3/+fKfHDx8+bMLCwowk06xZMzNq1Cjz4IMPmqioKPPBBx+Yq1evunwsb9TW9aZNm1bgDkF5eXnm97//vRk0aJB55513zIsvvmg+/fRTp3WWLVtmbDaby+d506ZNplu3biYkJMQ8/PDDZsaMGebRRx81ERERZsKECWbPnj3GmMLPkTHW9bPo6GjTs2dPI8n07dvXrFu3zrGvUaNGmQsXLhhjjMnIyDBvv/22CQ4ONpJMnTp1zCuvvGIyMjJu2K4rfek32pZHAAAgAElEQVTbb781ffv2dbzGJkyYYBITEws91hW1r6xcudL07t3bsW1kZKTp27evGThwoHnooYfM888/b7Zs2eLS67Ew8rC7qZKTyEnkJNf3Q04iJ1W0nOSJd1MlL5GXyEu/3uWysOeUf15TU1ONMeQlY8hLFSkvFXc3VZsxzmMSlyxZohEjRrg0VDHfmjVrdPz4cUVFRenUqVO6cuWKMjIytHTpUrVv314zZswodvtLly5p9+7datSokYKDgwtd5+rVqzp37lyB693zpaWlOd1xJSsrq9A7criTO2J66qmn9H//93/Kzs7WsWPHVKNGDQUFBRW6rivH2ZV1SsOtvmaud/bsWQUEBCgwMFDp6elF3tnUXXJzc3Xu3Lki71Rz+fLlIs9TUex2u3766SdlZWXpzjvvLHSC3OKU537m7nYrcl8pCzabTYsXL9bw4cM9Yv/kpMKRk4pW0XPSjZCTSoac5Nk5adiwYZJ+HbXiKfsnLxWOvFQ08hJ5qSTIS56bl4qpr0XfcjEuKSlJgwcP1tGjR52GgEq/DndcsmSJ0/BOT+DKRIgTJkzQ3Xff7YZoCudqjHPnznUkmPLCna+Z8nCugaKUl/dXTyrGlZdjdq3y8D5FTiInAeXl/dXTinHl5bhdqzy8V5GXyEtAeXh/La4Yd8t3U92xY4dOnjypjz76SPfdd58aN26sX375RYmJidqxY4defPHFW22i1PXp0+eG69StW9cNkRTN1RivXLminJyccvELRz53vmbKw7kGilIe31+tVh6PWXl4nyInlY7ycK6BopTH91dPUB6PW3l4ryIvlY7ycK6BopTH91cnJbimtVB5eXnmrbfeMr179zZVqlQxgYGBJiIiwnz44YcmKyvrJq6qhas+//xzU69ePSPJPP3002bbtm1Wh+QSXjOAa8pLX5EHzRlXXo5ZRUROAiq28tJXPG3OuPJy3Coi8hJQsZWHvlLmc8bls9vtTnf8QNm6dOmS03mqUqWK45bG5QWvGcA1ntxXPOky1Wt58jGriMhJQOXhyX3F0y5TvZYnH7eKiLwEVB6e2lfK9DLVa3nik6/IatSoYXUIt4zXDOAa+krJcczci5wEVB70lZvDcXMv8hJQeZTHvuJldQAAAAAAAABAZUExDgAAAAAAAHATinEAAAAAAACAm1CMAwAAAAAAANyEYhwAAAAAAADgJhTjAAAAAAAAADehGAcAAAAAAAC4CcU4AAAAAAAAwE0oxgEAAAAAAABuQjEOAAAAAAAAcBOKcQAAAAAAAICbUIwDAAAAAAAA3MSnqAeGDRvmzjgAoMSMMdq1a5dq1aql2rVry9/f3+qQUEZmz56t6Ohoq8MAAHi4zZs3KyIioszb4LuS+xljlJaWptTUVElS06ZNLY4IAIqXkpJS5GMFinEhISEaOnRomQYEAKUhMzNTp06d0oEDB2SMUWBgoGrXrq1atWqpTp06qlGjhmw2m9VhVnhDhw5VSEhIme4fgLOzZ89q79696tmzp9WhAB4lIiJCkZGRZbb/stw3nNntdp0/f16pqalKTU3V+fPnZbfb5ePjo4YNG1KMA+DxgoODi/wuYzPGGDfHAwClKj09Xdu3b1dcXJxiY2OVkJCg1NRUBQQEqGPHjurcubOioqLUu3dv1a1b1+pwAeCWLVmyRCNGjBAf4wBUFCdOnHB8louLi9O2bduUl5enBg0aOD7Lde/eXeHh4fLz87M6XAC4FdEU4wBUSIcOHVJsbKySkpIKfKDL/zAXFRWljh07ysuL6TMBlC8U4wCUZxkZGdq2bZvjc1pMTIzOnj0rHx8fdejQQd27d1fnzp3Vq1cvNW7c2OpwAaC0UYwDUDlcvnxZiYmJjgJdbGysLl68qGrVqqlDhw6OAl23bt1Uu3Ztq8MFgGJRjANQnpw4ccJReIuNjdWWLVuUnZ1dYNRbly5dmAMYQGVAMQ5A5ZSbm6t9+/Y5fTDcu3evjDFq1qyZ4xdZRs8B8EQU4wB4qpycHCUnJzt+AN24caOOHDkiHx8ftWrVylF469y5s9q1a2d1uABgBYpxAJDv9OnTSkxMdBTo4uLidPXqVQUFBSk8PNzxwbFHjx667bbbrA4XQCVGMQ6Apzh58qR+/PFHx4+bSUlJyszMVI0aNRQWFuaYGqRbt24KCAiwOlwA8AQU4wCgKDk5Odq/f7/TZMKHDh2St7e3Wrdu7XRZRdu2bblzKwC3oRgHwArXfzZKSkrSnj17+GwEACVDMQ4ASuL6OU/yf/2tV6+ewsLCnD6EVq1a1epwAVRQFOMAuMOlS5e0ZcsWx4+S8fHxunLliqpXr67Q0FCnm2LVrFnT6nABoLygGAcAt8Jut2vHjh2OwtyGDRt09OjRAvOiREVFqVmzZlaHC6CCoBgHoLQxny4AuA3FOAAobSdOnHAaOccdwwCUNopxAG5VWlqakpOTnabjuHDhQoE7zUdGRqpOnTpWhwsAFQnFOAAoaxkZGdq2bZvjl+b169fr3Llz8vX1VWhoqOOX5t69e6tRo0ZWhwugHKAYB6CkDh065PihMC4uTtu2bVNeXp4aNGjgdIfTrl27ytfX1+pwAaAioxgHAFZw9QNxeHi4/Pz8rA4XgIehGAegOOnp6dq+fbtj1NvmzZsL/BAYFRWlXr166fbbb7c6XACobCjGAYAnuP5Skfj4eJ0/f16BgYG6++67HZe39unTh0tFAFCMA+Dk+ikyEhMTZbfbC0yRERYWpipVqlgdLgBUdhTjAMATMYkygOJQjAMqr2tvHhUXF6cNGzbozJkz8vHxUYcOHRyfEXr06KGmTZtaHS4AoCCKcQBQXly+fFmJiYmOX703bdqkS5cuqXr16goNDXX86t29e3fVqlXL6nABlCGKcUDlceLECacf53788UdlZWWpfv366tKli9PIt6pVq1odLgDgxijGAUB5lT967trLUvbs2SNvb2+1bt3a6cN527ZtZbPZrA4ZQCmhGAdUTDk5Odq/f78jt8fGxurw4cOO3H7tvLLkdgAotyjGAUBFcurUKW3ZssXpF/TMzEzVqFFDYWFhjg/wPXv2VI0aNawOF8BNohgHVAzX5+24uDhdvXpVQUFBCg8Pd7rk9LbbbrM6XABA6aAYBwAVWU5OjpKTk50ubf3ll18K/YW9Xbt2VocLwEUU44Dyp7AR7dfPB8uIdgCoFCjGAUBl4+rcM1FRUfL397c6XACFoBgHeL7r53qNjY3VxYsXmesVAEAxDgAquytXrmjr1q2OAl1Rd2Xr2bOnmjRpYnW4AEQxDvBEhw4dctzhlLugAwCKQTEOAFDQiRMnnC6jSUxMlN1uV4MGDZxuDBEWFqYqVapYHS5Q6VCMA6yVlpam5ORkR66Mj4/X+fPnFRgYqLvvvtuRK3v37q26detaHS4AwLNQjAMA3Fh6erq2b9/u+NKRkJCg1NRUBQQEqGPHjo4vHb169dLtt99udbhAhUcxDnCva3+kiouL07Zt25SXl6cGDRo4zb8aHh4uPz8/q8MFAHg2inEAgJuTfzlO/uWtRX0x6dq1q3x9fa0OF6hQKMYBZScjI0Pbtm1z5LeYmBidPXtWvr6+Cg0NdeS3Xr16qXHjxlaHCwAofyjGAQBKR1pamn744QenAt2FCxdUrVo1dejQwVGg69atm2rXrm11uEC5RjEOKD3XT82wZcsWZWdnF5iaoUuXLtzYCABQGijGAQDKRm5urvbt2+d051YmswZKB8U44ObY7Xbt2LHDUXjbuHGjjhw5Ih8fH7Vq1cppZHe7du2sDhcAUDFRjAMAuM/p06eVmJjoKNDFxcXp6tWrCgoKUnh4uFOBrmbNmlaHC3gsinGAa06ePKkff/zRaeRbZmam6tWrp7CwMKeRb1WrVrU6XABA5UAxDgBgnZycHO3fv9/pS9KePXvk7e2t1q1bO31Jatu2rWw2m9UhAx6BYhxQEDkFAFBOUIwDAHgWRjEAN0YxDmC0NQCg3KIYBwDwbMzvAxREMQ6VDfOQAgAqEIpxAIDyhzvfobKjGIeKjjt0AwAqMIpxAIDyLyMjQ9u2bXN8YYuJidHZs2fl6+ur0NBQx4iJXr16qXHjxlaHC9wyinGoaA4dOuRUeNu2bZvy8vLUoEEDpxHQXbt2la+vr9XhAgBwKyjGAQAqpmtHzxX3xS48PFx+fn5WhwuUCMU4lGfp6enavn274z06ISFBqampCggIUMeOHR0jnHv16qXbb7/d6nABAChtFOMAAJVDWlqakpOTHV/+4uPjdf78eQUGBuruu+92fPnr3bu36tata3W4QLEoxqE8uX5qgcTERNnt9gJTC4SFhalKlSpWhwsAQFmjGAcAqLzyL4tiMnCUNxTj4KmuXLmirVu3Oi433bBhg86cOSMfHx916NDB8d7as2dPNWnSxOpwAQCwAsU4AADyXb58WYmJiY7RG7Gxsbp48aKqV6+u0NBQx+iN7t27q1atWlaHi0qMYhw8xYkTJ5zucPrjjz8qKytL9evXV5cuXZxGvlWtWtXqcAEA8AQU4wAAKEpubq727dvndHnV9aPn8r9ktm3bVjabzeqQUQGlpKRo7Nixys3NdSw7d+6c9u/fr+7duzut27p1a3344YfuDhGVRE5OjpKTkx3vh5s2bdIvv/wib29vtW7d2mk+znbt2lkdLgAAnopiHAAAJXHq1Clt2bLFMRIkLi5OV69eVVBQkMLDwx1fRHv06KHbbrvN6nBRQTRv3lyHDh264Xovv/yy/vSnP7khIlQG17/fxcbGKjMzUzVq1FBYWJjTJac1atSwOlwAAMoLinEAANyKnJwc7d+/3/FFNTY2VocPHy50pAij53Cz/vjHP+r111+X3W4vdr1du3YxIgk3pbCRwHv27HG8l117uSnvZQAA3BKKcQAAlDbmUEJp+/nnn9WyZcti12nbtq12797tpohQ3l0/R+amTZt06dIl5sgEAKDsUYwDAKCs2e127dixw3Hn1mvvLtiqVSvHl94ePXqoadOmVocLD9WhQwft3Lmz0Js2+Pr6atasWZo+fboFkcHT5Y96u/ZHAu4eDQCAZSjGAQBghRMnTjhdDpaYmCi73a4GDRo4jZwLCwtTlSpVSrXtixcvKigoiC/c5cxbb72lGTNmKCcnp8BjNptNhw4dUpMmTdwfGG7ahQsXVLNmzVLfb1pampKTkx3vMfHx8Tp//rwCAwN19913O95j+vTpozp16pR6+wAAoFgU4wAA8ATp6enavn2748vz5s2bde7cOfn6+io0NNRx59ZevXrp9ttvv6W2/vrXv2r58uWaN2+e2rdvX0rPAGXtxIkTCgkJUV5entNym82mrl27KiEhwaLIUFLGGH3++eeaOnWqEhMTb3lE7KFDhxyF/bi4OG3btk15eXlq0KCB07yV4eHh8vPzK6VnAQAAbhLFOAAAPJWrX7C7du0qX19fl/f70EMPaeXKlfL29tYLL7ygV199VQEBAWX4TFBaevToofj4eKeCnI+Pj9555x1NnDjRwsjgqgMHDuiJJ57Qpk2bJEmfffaZRo8e7fL2GRkZ2rZtm+N9Yf369QUK9507d1bv3r3VqFGjsnoaAADg5lGMAwCgvLj+0rO4uDhduHBB1apVU4cOHRwFusjIyGIvPatdu7bOnz8v6de5xurVq6d58+bpgQcecNdTwU2aN2+eJk6c6FSM8/b21okTJ255xCTKlt1u19tvv61XX31VxhjZ7Xb5+fnpiSee0HvvvVfkdtdf0r5lyxZlZ2cXuKS9S5cu8vf3d+MzAgAAN4liHAAA5dXNTMpe2F05vby8lJeXpwEDBmju3LkKCQmx6BnhRi5cuKDbb7/dMW+ct7e37rvvPn377bcWR4bibNq0SePHj9fBgweVm5vr9Nhdd92lnTt3SnK+2UtSUpI2bNigo0ePFrjZS1RUlJo1a2bFUwEAALeOYhwAABXJmTNntHnzZsXHxys+Pl4//vijrl69qpo1ayoyMlL+/v5asWJFgXnHpF9Hyfn5+en111/XM888I29vbwueAW5k4MCBWr16tXJzc+Xl5aVPPvlEY8aMsTosFOLChQuaPn26FixYIG9v70JvvuHl5aWnnnpKSUlJ2rp1q+x2u+rXr6+IiAh169ZNkZGRjHoDAKBioRgHAEBFZrfbtX37diUkJCghIUGrVq3S1atXZbfbi9zGy8tLd911lxYsWKAuXbq4MVq4YtGiRRo9erSMMfLz89PZs2cVFBRkdVi4TnR0tJ588kmlp6cX298kqWXLlurXr5+jAMeoNwAAKjSKcQAAVCZt27bV3r17b7iej4+P8vLyNGnSJL3++uuqXr26G6KDKzIyMlSnTh1lZmZq6NChio6OtjokXOPnn3/WE088oQ0bNkj69c6pxfHz89Mf/vAH/c///I87wgMAANaL9rE6AgAAUPaWLFmiq1evat++fS6tn3853bvvvqvPP/9cEyZMUKdOncoyRJRAp06dFB8fr6ZNm2rJkiVWhwP9Ogp1xYoVWr58uYwxNyzCXbtddHS0WrRooZCQEEVGRpZxpAAAwGqMjAMAoBKw2WxWhwDgBhjpCABApcDIOAAAKosRI0Zo8eLF8vHxcZpIPiAgQHfccYdatGihJk2aKCQkRCEhIWrcuLFCQkLUsGFD+fn5WRg5rme32/Xyyy/rjTfesDoUXCctLU1Hjx7VkSNHlJKSomPHjunIkSM6ePCgjhw5otOnTzv1P29vb+Xm5qp///4WRg0AANyJkXEAAFQCNptN48aNU/369QsU22rUqGF1eLgJV69eVdWqVa0OAyVkjNGpU6d09OhRHTt2zFGs27lzp2rVqsXIOAAAKj5GxgEAUFn0799fw4cPtzoMlBIKceWTzWZTgwYN1KBBA3Xt2tWxfNiwYRZGBQAA3MnL6gAAAAAAAACAyoJiHAAAAAAAAOAmFOMAAAAAAAAAN6EYBwAAAAAAALgJxTgAAAAAAADATSjGAQAAAAAAAG5CMQ4AAAAAAABwE4pxAAAAAAAAgJtQjAMAAAAAAADchGIcAAAAAAAA4CYU4wAAAAAAAAA3oRgHAAAAAAAAuImP1QEAAADgP1JTU/Xll1/q6NGjCg0NVb9+/VStWjWnddLS0rRw4UIdPnxYLVq00KhRoxQQEHBL7R47dkxbt27Vjh075OXlpZYtWyosLEw2m00pKSmKioq6pf0DAADgV4yMAwAA8BDbt29X79691bZtW02fPl0///yzunfvrpMnTzrW2b9/v1q1aqW33npLs2fP1hNPPKHQ0FCdOnXqptrMzs7WtGnT1KpVK8XFxalTp07q1q2bDh06pM6dO6tZs2ZKTEwsracIAABQ6VGMAwAA5dqnn35aIdrNy8vTf//3f2vAgAGKiIhQQECApk+fLn9/f40dO9ax3pQpU7R69WodOHBAKSkpGj9+vA4ePKiXXnqpxG1mZmYqMjJS8+fP15o1a/TXv/5VAwcOVJ8+fTRjxgxt2bJFwcHBunLlSmk+1VJRUc47AACofCjGAQCAcmvdunV68cUXK0S7mzdvVnJysjp27Oi0PDw8XGvWrFFSUpKSkpI0evRohYaGSpLq1q2r1157TV5eXoqPjy9xm7NmzdLWrVs1bdq0Qi9Dbd68uV555RVlZGTc3JMqIxXpvAMAgMrHe+bMmTOtDgIAAJStP/7xjxo2bJjatWvn8jbp6elasmSJoqOjde7cOQUHB8vf39/xeFpamlasWKGlS5fq4MGDqlu3rmrUqOF4/NixY/r4448VHh6u3bt3a/78+Tpy5Ijat28vm83mcjsHDhzQ119/rc8++0wZGRm68847JUnr16/XkCFDZLfbVatWLZ08eVKtW7eWJJ04cULR0dH66quvlJOTo2bNmpU4rtJu90bWrl2rL7/8Ug8//LDat2/vWH7u3DmtWLFCbdu2Vc+ePRUeHu4UZ/Xq1fX1118rMDBQjz/+uGObOXPmqFWrVgXmm8t36tQpDR06VP7+/oqOjlaVKlUKXa99+/ZKS0tT27ZtJXHeS/u854uOjpYkDR8+vMTbAgCAcmWPDAAAqPAkmcWLF7u8/t69e82AAQNMcnKysdvt5pFHHjG1a9c2Bw8eNMYYs337dtO+fXuzbNkyc+bMGfO3v/3NVKtWzXzyySfGGGNWrlxp6tataySZ2bNnm9/+9rdm0KBBRpL585//7HI7s2fPNr179zZ5eXnm8OHDpkmTJub99983xhizbds20717d1O3bl2zfv16s23bNmOMMevWrTNPPPGE2bp1q1myZImpVq2aefrpp0sUV2m364pFixYZSWbq1KlOy2NjYwtdfq369eub1157zfH//PnzjSTzzjvvFLnNqlWrjCRz1113uRwj5730z3u+oUOHmqFDh5Z4OwAAUO4soRgHAEAlUJJiXE5Ojrn77rvNvHnzHMuSkpKMn5+f+eqrr0xWVpZp06aNefXVV522GzVqlPHz8zO7d+82xhgzY8YMI8msXbvWsU6nTp1M586dXWrHGGNatGhhJk2a5Hh8yJAhZsCAAU7/h4SEOP5PS0szzZo1M+np6Y5ljz/+uJFkEhISXIqrrNq9kaNHjxo/Pz/TuXNnk5eX51j+9ddfF1tY27BhgwkODjZpaWmOZenp6WbhwoXm8uXLRbb317/+1UgyDz74oEvxcd7L5rznoxgHAEClscTHfaPwAABAebBq1Spt375dAwcOdCzr1KmT0tLS5Ofnp5UrV2rfvn2KiIhw2q5///5auHChFixYoLfeektVq1aVJLVp08axTtu2bbV69WqX2pGkmJgYBQYGSpL27NmjY8eO6fLly07tXnuJ4aJFi3T16lVNnz7dsezkyZNq3ry5fv75Z0VERNwwrrJq90ZCQkI0a9YsTZ8+Xb/97W81fPhw7d27V//v//0/SVKHDh0KbJObm6tXX31VK1eudLocNTAwUI888kix7fn4+Dj24Ypvv/2W834T7QIAAFyPYhwAAHCSnJyswMBA1a1b12l5fqFkz549klRgLrIePXpIkvbu3Vvkvr29vWWMcakdSWrYsKG+++47/fvf/1avXr3UvHlzJSUlOa1/bXFk9+7datCggf7xj3+49FwLi8ud7V5v2rRpCg8P13fffafY2FiNHDlSmzdv1k8//VTgxg6S9MILL2jq1KmFPnYj+fMH/vTTTy6tz3kvvXYBAEDlRjEOAAA4ycvLU0ZGhtavX69+/foVeLxWrVqSpISEBEchRpIaN24sX19f1axZs1TakaRXXnlFGzZs0OrVq1W1alUtW7aswDrXFke8vb21f/9+2e12+fr6uhSHJ7UrSb169VKvXr0kSYcPH9bKlSv15ptvqnr16k7rzZs3Tx07dtTgwYNvqp3OnTurWrVqOnTokA4ePKjmzZsXuz7nvezaBQAAlYuX1QEAAADPkn8nz4ULFzotT01N1fLly9W1a1dJ0saNG50e37Vrl+x2uyIjI0ulncOHD2vWrFkaM2aM4xLDvLw8p3VtNpvTZZYdOnRQRkaG5s6d67TexYsX9f7777sUl1XtXi87O1sjRoxQ69at9fTTTzs9tnz5chlj9Nhjjzkt37Bhg8v7r127tv74xz8qNzfX6TLLwmzbto3zXkbtAgCAyoeRcQAAwMngwYPVsWNHffLJJ/L399ewYcO0Y8cOxcTEaMmSJapSpYrGjh2rL774QkePHlWjRo0kSbGxsWrZsqUmTJggSY65trKzsx37PnfunLKysmSMuWE7Bw4ckPTrvFwjR45UcnKyNm7cqKysLKWnp8sYowYNGujUqVM6dOiQjDEaNGiQQkJC9MILLygzM1ODBg3Szp07tXTpUi1YsMCluNLT08uk3ZLIyMjQ008/raZNm+rdd991zO8mSWvXrtUbb7yhMWPG6L333pP067xve/bs0V133aVevXopKSlJEydO1F//+lf17t27yHaee+45/fDDD1qyZImeeOIJvfPOO45ClCQdOXJEr7/+uh599FH16NGD817G5x0AAFQSbr9nBAAAcDuV4G6qxhiTkpJi+vbta2w2m7HZbKZ3794mJSXF8fjVq1fNpEmTTLt27czHH39sPvroIzNw4EBz9OhRY4wxMTExplmzZkaSGT9+vDl58qRZtGiRCQoKMpLMzJkzjd1uv2E748aNMz4+PqZFixZm7ty5ZunSpcbPz8/cc889JjU11axfv974+PiY2267zXG30T179phWrVoZSUaSadeundm6dWuJ4irtdl117tw5s2DBAtOtWzfzxRdfFHg8KSnJBAYGOtq49s/f39+kpqYaY4xZtmyZsdlsZv78+S61+9lnn5lGjRqZevXqmcGDB5tx48aZVq1ameHDh5t9+/Zx3sv4vBvD3VQBAKhEltiMuWbWWgAAUCHZbDYtXrxYw4cPL9F2Fy9eVF5enmO+sOtdunRJu3fvVqNGjRQcHHzT8RXXTlpamtN8aVlZWapSpYpTDF5eXgXmVDty5IhsNptjBFdJWdHuihUrFBoaqmbNmt1UzNe6fPmygoKCSrTNhQsXtGvXLvn6+qpVq1acdze2O2zYMElSdHT0TW0PAADKjWiKcQAAVAI3W4xD6bh+zrfCTJgwQXfffbcbooEnohgHAEClEc2ccQAAAGWsT58+N1ynbt26bogEAAAAVqMYBwAAUMbyRz0BAAAAXlYHAAAAAAAAAFQWFOMAAAAAAAAAN6EYBwAAAAAAALgJxTgAAAAAAADATSjGAQAAAAAAAG5CMQ4AAAAAAABwE4pxAAAAAAAAgJtQjAMAAAAAAADchGIcAAAAAAAA4CYU4wAAAAAAAAA3oRgHAAAAAAAAuAnFOAAAAAAAAMBNKMYBAAAAAAAAbkIxDgAAAAAAAHATH6sDAAAA7pGQkGB1CACKkJKSouDgYKvDAAAAbmAzxhirgwAAAGXLZrNZHQKAGxg6dOj/Z+/Oo6qqF/ePPwcO4ACOkWk4XE1TyyGHxNFeu54AACAASURBVBGpgBRRK8ChMmevlqWWpY3Wt+GmVjcrb2neSktCnL045ICipZmaehWznFJSv4qpDCoc4PP7o6/nFzmBwtkceL/Wcq3Y+7M/+znsvVbHxz0oLi7O6hgAAKBoxXFlHAAApQD/9layzJkzR7169eK4AgAAuCGeGQcAAAAAAAC4CGUcAAAAAAAA4CKUcQAAAAAAAICLUMYBAAAAAAAALkIZBwAAAAAAALgIZRwAAAAAAADgIpRxAAAAAAAAgItQxgEAAAAAAAAuQhkHAAAAAAAAuAhlHAAAAAAAAOAilHEAAAAAAACAi1DGAQAAAAAAAC5CGQcAAAAAAAC4CGUcAAAAAAAA4CKUcQAAAAAAAICLUMYBAAAAAAAALkIZBwAAAAAAALgIZRwAAAAAAADgIpRxAAAAAAAAgItQxgEAAAAAAAAuQhkHAAAAAAAAuAhlHAAAAAAAAOAilHEAAAAAAACAi1DGAQAAAAAAAC5CGQcAAAAAAAC4CGUcAAAAAAAA4CKUcQAAAAAAAICLUMYBAAAAAAAALkIZBwAAAAAAALgIZRwAAAAAAADgIpRxAAAAAAAAgItQxgEAAAAAAAAuQhkHAAAAAAAAuIjd6gAAAAC4spMnT2rBggV5lm3ZskWSNG3atDzLfX191bdvX5dlAwAAQMHZjDHG6hAAAAC4vMzMTPn7+ysjI0Oenp6SJGOMjDHy8Pj/Nzk4HA7169dPX3zxhVVRAQAAcG1x3KYKAABQjPn4+CgqKkp2u10Oh0MOh0PZ2dnKyclx/uxwOCSJq+IAAADcAGUcAABAMde3b19lZWVddUylSpV07733uigRAAAArhdlHAAAQDEXHBwsf3//K6738vLSI488IrudxwEDAAAUd5RxAAAAxZyHh4f69u0rb2/vy653OBzq06ePi1MBAADgelDGAQAAuIE+ffpc8VbV6tWrq23bti5OBAAAgOtBGQcAAOAG2rRpo9q1a1+y3MvLS4899phsNpsFqQAAAFBQlHEAAABu4tFHH5WXl1eeZdyiCgAA4F4o4wAAANzEww8/LIfDkWfZbbfdpqZNm1qUCAAAAAVFGQcAAOAmGjZsqMaNGztvSfXy8tKAAQMsTgUAAICCoIwDAABwI/369ZOnp6ekP25RjY6OtjgRAAAACoIyDgAAwI307t1bOTk5kqSWLVvqtttuszgRAAAACoIyDgAAwI3Url1brVu3lvTHVXIAAABwLzZjjLE6BAAAKHmioqI0d+5cq2MA1yU2NpZbgAEAQFGIs1udAAAAlFyBgYEaPXq01TFKnNTUVE2dOlXjxo2zOkqJ1KtXL6sjAACAEowyDgAAFJmAgACuLioiQUFBql+/vtUxSiTKOAAAUJR4ZhwAAIAboogDAABwT5RxAAAAAAAAgItQxgEAAAAAAAAuQhkHAAAAAAAAuAhlHAAAAAAAAOAilHEAAAAAAACAi1DGAQAAAAAAAC5CGQcAAAAAAAC4CGUcAAAAAAAA4CKUcQAAAAAAAICLUMYBAAAAAAAALkIZBwAAAAAAALgIZRwAAAAAAADgIpRxAAAAAAAAgIvYrQ4AAABwJenp6UpISNCGDRv09ttvWx3HEjt27FBiYqK8vb0VHh6ugIAASVJmZqbWrVun7du3q0OHDmrTpo08PT0LNHdiYqJ+++23PMu8vLzk7++vGjVqqH79+oX2OQAAAPAHrowDAADF1vLly/Xkk0/q66+/tjqKy6WkpGjw4MEaP368evTooWHDhjmLuBMnTqhRo0Y6fPiwBg4cqIULF6pHjx7Kyckp0D6aNm2q/fv3q2/fvurfv79SU1N18uRJLVmyRL169dLf/vY3vfjii3I4HEXxEQEAAEolyjgAAFBsRUZG6u6775bd7p4X88+cOfO6tjt06JAaNWqkzMxMLV26VLVq1XKuy83N1UMPPaQmTZpo8ODBuummm/TWW29p165deuGFFwq0n0qVKql///6SpHr16mnYsGEaPny4Jk+erK1bt2rSpEn64IMPFB4errS0tOv6LFa73mMAAABQVCjjAABAsebh4SEPD/f7yrJmzRqNHz++wNtlZWUpOjpaVapU0ccff3zJ+sTERG3YsEFDhgxxLvP09NRjjz2mDz/8UBkZGQXaX4UKFS673GazKTIyUtOmTdPKlSvVsWNHZWVlFezDWOx6jwEAAEBRcs9/ZgYAACXW77//rrlz5+rQoUNq1aqVjDGy2WzO9adPn1ZMTIxGjBihZcuWaefOnXr66adlt9uVlpampUuXas+ePapZs6ZCQ0NVs2ZN57bJyclavHixhg8frnXr1mnFihW69dZbNWjQIJUtW9Y57mrzLFmyRPv375evr68GDx6stLQ0zZw5Uw6HQ9WrV1evXr2UkJCgnj17ymaz6ZNPPlGNGjUUERGRr8//wgsv6IcfftCnn36q8uXLX7J+/vz5kqQmTZrkWX7nnXcqIyNDS5cuVVRUlFJSUjR9+nQNHDhQ1apVy/8B+ItevXpp5syZWrp0qTZv3qwOHTqU+GMAAABQlNzvn5kBAECJtXfvXt1///1q0qSJXnvtNaWkpGjhwoXOMu6LL75QQECAnnrqKX344YcaP368xo0bp6SkJO3YsUPt27eXl5eXHn/8cZ05c0aNGzd23qb41VdfqWnTpnrmmWc0YsQIzZo1Szt37tTIkSMVFBTkfC7ateaJiIjQp59+qldffVWS5Ofnp379+umVV17R+++/L0mqXLmymjZtKh8fH91+++15yqhriYmJkd1u13//+1/dc8898vX1VadOnbRt2zZJ0r59+yRJ1atXz7PdzTffLEn6+eefJUkLFy7U888/rzlz5hT8QPxFYGCgJGn9+vWl4hgAAAAUKQMAAFAEIiMjTWRkZIG2adOmjRk7dqzz59zcXFO3bl3ToEED57KHH37YSDLz5883xhizZ88ek5mZaRo2bGhefvnlPPP17dvXeHt7m927dxtjjHnkkUeMzWYzu3btco556aWXjCTz8ccf53ueyMhIExAQkGdMixYtTNu2bZ0/9+zZ09SsWbNAnz85OdlIMs2bNzenTp0yxhizd+9eU716dePr62uSk5NNixYtjKen5yXbbt682Ugyjz/+uDHGmPT0dDN79myTmpp61X2ePXvWSDKNGjW64pj58+cbSaZLly7GmJJ9DIwxRpKJjY0t8HYAAAD5MIcr4wAAQLGwZs0aff/99woODnYus9lsat26dZ7bVGvUqCFJ6tGjhySpYcOGWr58uX766SfnFVwXhYWFKSsrSzNmzJAklS9fXna7XXfccYdzzLhx42S325WYmJjvefLrz7nz4+LVbz179lSVKlUkSQ0aNNC7776r9PR0TZ06Vb6+vpfd9uKbVG+55RZJf3zWPn36yM/Pr0AZLic9Pd05p1SyjwEAAEBRo4wDAADFwo4dOyT98eyzP/trmXLxZQ5/fqlDUlKSJF1SVHXs2FGStGfPnivut1y5cgoICNDJkydvaJ7LKWgRVLFiRUnSTTfdlGd527ZtJf1xG2/NmjWVk5OjzMzMPGMuvu20cePGBdpnflwsCdu0aSOpZB8DAACAokYZBwAAioXU1FRJ0vfff3/JumsVKhevItu4cWOe5bVr15aXl5cqV658xW0zMzN1/Phx1a1b94bmuZyCFkENGjSQJG3dujXP8lq1asnLy0t+fn5q1KiRJOnIkSN5xqSkpEgq/DLOGKP169fL09NTISEhVxxXUo4BAABAUaOMAwAAxcLFt4OuWbOmwNtevGIrMTExz/Jdu3bJ4XA4ryy7nE2bNunChQvq1q1bvuex2+26cOHCVTPZbDbnraP5dcsttygsLEybNm3Ks/yXX36Rw+FQ+/btNWjQIPn4+Ojbb7/NM2br1q1q3ry5s9ArLKNHj9bWrVs1adIkNWvW7IrjSsoxAAAAKGqUcQAAoFjo3r27GjZsqFmzZjmLmKNHj2rdunVKTk7Wzp07lZ2drYyMDEnSqVOnnNs2a9ZMjz32mBITE3X48GHn8g0bNqh+/foaOnSoc1l2dnaeWx3nzp2roKAgdevWLd/zhIaGKiUlRZ999pkyMjL02Wef6dSpUzpw4IBOnz4t6Y+3nR4/flwHDhzQ/v37nbmv5Z133tGRI0f03XffOZclJCSoUaNG6t+/v2655RY98cQTmjRpkowxkqQLFy5oyZIlmjFjhvPW0a1bt+ruu+/W2rVrr7q/Q4cOSZLOnz9/yfLHH39cU6ZM0ciRIzV69GjnupJ+DAAAAIqS3eoAAAAA0h9XOi1btkzR0dEKCgpS3bp1FRgYqFatWun06dP67rvvtH79ei1YsECSNGLECD399NO6++67JUkff/yxfH191bVrV40dO1bZ2dlaunSpVq9eLW9vb+d+PDw8NHXqVJUtW1ZHjhxRRkaGlixZ4lyfn3mioqI0bdo0DRw4UJMmTdIbb7yhli1bKiMjQ/PmzdPgwYOdY1q2bKnXXntNI0eOzNfv4Y477tC3336rMWPGqH379vLx8dHGjRu1evVq2e1/fHWbNGmS7Ha7unfvrtDQUB07dkwvvviiWrRo4Zzn119/1ZYtW7Rv3z517tz5svtasmSJ3n33XUl/lG/t2rWTr6+vvL29Zbfbddttt2nz5s1q1aqVc5sZM2aU+GMAAABQlGzm4j+pAgAAFKKoqChJUlxcXIG3PXnypMqVK6fy5csrPT39im8QvZyzZ89q9+7dqlWrlgICAvKs+/vf/65///vfysrK0pEjR1SxYkVVqFChwPP8Oae/v7+kP65OK1OmzCVzeHh4XPcbTY8ePaqyZcte8TlpOTk5SklJUbVq1S67PjU19Yqfryi5+zGw2WyKjY1VdHR0vrcBAADIpziujAMAAMXOxXJFuvStmtdSsWJFtWvX7prjatasecPz/DnnX0ugi3NcNGLEiGtmGjp0qJo3b+78uUaNGlcd7+npecUiTpIlRZxUfI8BAABAcUAZBwAASo1z584pOzu7wFfbFYbg4OBrjvlzsVRSWXkMAAAAigPKOAAAUCp89dVX+uabb2SM0XPPPachQ4bkuQqtqF28bbc0s/oYAAAAFAeUcQAAoFTo1q2bwsPDnT/7+PhYmKZ04hgAAABQxgEAgFKCZ4dZj2MAAAAgeVgdAAAAAAAAACgtKOMAAAAAAAAAF6GMAwAAAAAAAFyEMg4AAAAAAABwEco4AAAAAAAAwEUo4wAAAAAAAAAXoYwDAAAAAAAAXIQyDgAAAAAAAHARyjgAAAAAAADARSjjAAAAAAAAABehjAMAAAAAAABchDIOAAAAAAAAcBG71QEAAEDJNXfuXNlsNqtjAAAAAMWGzRhjrA4BAABKno0bN+rIkSNWx7CMw+HQxIkTlZycrH/+85/y8fGxOtI17dy5U2+++ab69++v+++/3+o4lmrXrp0CAgKsjgEAAEqeOK6MAwAARaJt27Zq27at1TEskZOToz59+ujXX3/V6tWr1bJlS6sj5Ut0dLRuuukmjRkzRu3bt9egQYOsjgQAAFDiUMYBAAAUImOMhg4dqvj4eC1fvtxtiriLRo0apZMnT2rYsGHy8/NTdHS01ZEAAABKFMo4AACAQvT000/ryy+/1MKFC9WxY0er41yXN954QxcuXNCjjz4qX19fde3a1epIAAAAJQZlHAAAQCEZP368pkyZopiYGHXp0sXqODdk8uTJOnv2rCIjI7V8+XJ16tTJ6kgAAAAlgofVAQAAAEqCN998U2+//bamTZumqKgoq+PcMJvNpk8++UQRERGKiIjQli1brI4EAABQIlDGAQAA3KCpU6fqhRde0DvvvKOBAwdaHafQeHp6atasWerQoYO6dOmipKQkqyMBAAC4Pco4AACAG/Dll19q5MiReuuttzR69Gir4xQ6b29vzZ07V40bN1ZISIgOHDhgdSQAAAC3RhkHAABwnRYuXKgBAwZo3LhxGjdunNVxikzZsmW1ZMkS1ahRQ8HBwTp8+LDVkQAAANyWzRhjrA4BAADgblatWqVu3bpp0KBB+uijj6yO4xIpKSkKCgpSdna2EhMTVa1aNasjAQAAuJs4rowDAAAooI0bN+qBBx5QVFSUPvjgA6vjuMxNN92klStXKjs7W2FhYTp9+rTVkQAAANwOZRwAAEAB7NixQ+Hh4brvvvv02WefycOjdH2dqlGjhhISEnT69GmFh4crPT3d6kgAAABupXR9ewQAALgBP//8s8LCwtSyZUt9/fXXstvtVkeyRK1atbRy5UodOHBADzzwgDIzM62OBAAA4DYo4wAAAPLh8OHDCgkJUd26dbVgwQL5+PhYHclSDRo00IoVK7R161b17t1b2dnZVkcCAABwC5RxAAAA13D06FEFBwercuXKio+Pl6+vr9WRioVmzZopPj5eq1at0sCBA5Wbm2t1JAAAgGKPMg4AAOAqUlJSFBISIrvdrhUrVqhy5cpWRypW2rZtqwULFmjOnDkaOXKk1XEAAACKvdL5oBMAAIB8SE1NVZcuXZSenq7169erWrVqVkcqlu677z59/fXXioqKUqVKlfTGG29YHQkAAKDYoowDAAC4jPPnzysiIkJHjx7V+vXrVatWLasjFWs9e/bUv//9b/Xv319+fn4aN26c1ZEAAACKJco4AACAv8jKylJkZKSSkpK0bt061a1b1+pIbuHRRx9VWlqaHn/8cZUpU0ajRo2yOhIAAECxQxkHAADwJzk5OXr00Ue1YcMGrV69Wo0bN7Y6klsZMWKEzpw5ozFjxqhChQoaOHCg1ZEAAACKFco4AACA/2OM0bBhw7RkyRItX75crVq1sjqSW3r++eeVlpamoUOHys/PT1FRUVZHAgAAKDYo4wAAAP7PM888o1mzZmnBggXq1KmT1XHc2ltvvaULFy7okUceka+vr7p06WJ1JAAAgGKBMg4AAEDSCy+8oPfff1+zZ89W165drY5TIrz77rtKTU1VZGSkli9fro4dO1odCQAAwHIeVgcAAACw2j//+U+99dZb+vjjjxUdHW11nBLDZrNp2rRpCg8PV0REhLZu3Wp1JAAAAMtRxgEAgFLts88+05gxYzR58mQNHjzY6jgljqenp7788ku1a9dOXbp0UVJSktWRAAAALEUZBwAASq2vvvpKgwcP1uuvv64xY8ZYHafE8vb21ty5c9WwYUOFhobq4MGDVkcCAACwjM0YY6wOAQAA4GqLFy/WQw89pCeeeELvvfee1XFKhbNnz+ree+/VmTNnlJiYqBo1algdCQAAwNXiKOMAAECps2bNGoWHh6tPnz6aMWOGbDab1ZFKjZMnT6pz587y8PDQ2rVrVbVqVasjAQAAuFIct6kCAIBSZdOmTerRo4ceeughffrppxRxLubv769vvvlGGRkZuu+++3TmzBmrIwEAALgUZRwAACg1du7cqfDwcN1zzz36/PPP5eHBVyEr3HrrrVq5cqVOnDih8PBwZWRkWB0JAADAZfgGCgAASoVffvlFYWFhat68uWJjY2W3262OVKrVq1dPK1as0N69e/XAAw8oMzPT6kgAAAAuQRkHAABKvCNHjigkJER16tTRokWLVKZMGasjQdKdd96pVatW6YcfflCfPn2UnZ1tdSQAAIAiRxkHAABKtBMnTigkJEQVK1ZUfHy8fH19rY6EP2nevLni4+P1zTffaNCgQcrNzbU6EgAAQJGijAMAACXWmTNnFBYWptzcXK1YsUJVqlSxOhIuo127dlqwYIFiY2P11FNPWR0HAACgSPGwFAAA4LaMMVd8G2paWppCQ0N16tQprV+/XrfccouL06EgQkJCFBMTo+joaFWuXFmvvfbaZcdd7ZgDAAC4A66MAwAAbus///mPnnjiCRlj8iw/f/68unfvrl9//VUrV65U7dq1LUqIgnjggQc0Y8YMvfHGG5o4ceIl63///Xd17dqVt68CAAC3xpVxAADAbU2ePFmJiYk6f/68pk2bJk9PTzkcDkVFRWn79u1KSEjQ7bffbnVMFEC/fv2UmpqqJ598UhUrVtSwYcMkScnJyQoODta+ffs0c+ZMDR8+3OKkAAAA18dm/vpPyQAAAG5g+/btuuuuuyRJHh4eevDBBzVr1iwNGDBA8fHxWr16tVq3bm1xSlyv//mf/9GECRM0a9YstWnTRp07d9b//u//Kjs7W3Xq1NG+ffvk4cFNHgAAwO3EUcYBAAC39PDDDysuLk4Oh0OSZLfbVbduXR05ckTLli1TUFCQxQlxo8aOHat//vOfqlixolJTU53H2mazadGiRYqIiLA4IQAAQIFRxgEAAPdz9OhR1a5dW9nZ2XmW2+12NWrUSBs2bFCFChUsSofCsmXLFgUHByszM9NZxEmSp6enAgMDtWHDBgvTAQAAXJc4ru0HAABu54MPPrjsGzWzs7P1008/KSgoSCkpKRYkQ2FZv369goKCdOHChTxFnCTl5OTo22+/1Q8//GBROgAAgOtHGQcAANxKRkaGpk6deklBc5HD4dDu3bvVsWNHHT9+3MXpUBiWLVumkJAQZWZmXnL140VeXl567733XJwMAADgxlHGAQAAt/L5558rIyPjqmMcDod++uknRUdHKycnx0XJUBh++eUXRUZGKisr66rHzuFwaM6cOUpOTnZhOgAAgBtHGQcAANxGbm6uJk2apNzc3CuOsdvt8vPz0yuvvKL4+Hh5enq6MCFuVP369ZWUlKRBgwbJw8NDXl5eVxzr4eGhDz/80IXpAAAAbhwvcAAAAG5jwYIFevDBBy+7zsvLS56ennrqqac0btw4VapUycXpUNj27NmjN954Q7Nnz5bdbr/srcm+vr46duyYfH19LUgIAABQYLzAAQAAuI+JEydecqWbl5eXfHx8NHz4cB06dEj/+Mc/KOJKiEaNGunLL7/Uzp071a1bN9lstkuulDt//rw+++wzixICAAAUHFfGAQAAt7Blyxa1bt3a+bOXl5eMMRowYIBeffVVVa9e3cJ0cIVNmzbp1Vdf1fLly+Xp6el8plxAQIAOHTrELckAAMAdcGUcAABwD5MmTXJeGeXp6al+/frpwIEDmjZtGkVcKREYGKhly5Zp9erVatmypaQ/nhuXnJysRYsWWZwOAAAgf7gyDgCAq4iKirI6AiSdO3dOy5YtkzFGtWrVUuPGjUvkM8Li4uKKZN6NGzfq3XffLZK5rXTs2DHt2rVLZ8+eVdWqVRUcHGx1JEhq27atxowZY3UMAACKqzi71QkAACjO5s6dq8DAQAUEBFgdpVTbv3+/atSooTvuuEMVKlSwOk6hS05O1qZNm4ps/iNHjmju3LmKjIwssn1YoXr16qpevbqSk5OVlJSk33//XVWqVLE6VqlWlOcxAAAlBWUcAADXMHr0aEVHR1sdo1Tbv3+/6tWrZ3WMIjNnzhz16tWryPdTVFfeFQe5ubk6fPiw6tSpY3WUUo2riQEAuDaeGQcAAIq9klzEoXB4eHhQxAEAALdAGQcAAAAAAAC4CGUcAAAAAAAA4CKUcQAAAAAAAICLUMYBAAAAAAAALkIZBwAAAAAAALgIZRwAAAAAAADgIpRxAAAAAAAAgItQxgEAAAAAAAAuQhkHAAAAAAAAuAhlHAAAAAAAAOAilHEAAAAAAACAi1DGAQAAAAAAAC5CGQcAAAAAAAC4iN3qAAAAlGTp6elKSEjQhg0b9Pbbb1sd57ocP35cP/30kzp37nzZ9fHx8UpNTXX+fOTIET3xxBMqV67cJWNPnTqladOmafz48QXKkJiYqN9++y3PMi8vL/n7+6tGjRqqX79+geZDwXEu53/M1XAuAwAAyjgAAIrQ8uXLNXbsWOXm5rpdgXHy5Em9/fbbmjp1qoYMGXLZAuOnn35SRESEjDHOZb17975iMTF48GBt3LixwGVc06ZNlZiYqJdeekne3t6aMmWKcnNztWnTJq1Zs0anT5/Www8/rFdeeUVeXl4Fmhv5w7lc8PP9cjiXAQAAZRwAAEUoMjJScXFx2rJli9VRCuzQoUPq16+f3nnnnSuOeffdd7VmzRrVq1fPuczf3/+yY6dPn67du3dfV5ZKlSqpf//+eumll1SvXj0NGzbMuc4Yo3nz5mnQoEHavHmz5s2bJz8/v+vaD66Mc7lg5/uVcC4DAACeGQcAQBHz8PCQh4f7/S+3devWatiw4RXXHz9+XDt37tRtt92mmjVrOv+UKVPmkrE///yzfvzxR3Xr1u2681SoUOGyy202myIjIzVt2jStXLlSHTt2VFZW1nXvB1dWms/lgpzv18K5DABA6caVcQAAFLLff/9dc+fO1aFDh9SqVSsZY2Sz2fKMOXr0qJYvX67k5GS1b99e9957r3PdkSNHNH/+fI0cOVJJSUlatGiRatWqpYcffthZhBhjtG7dOm3fvl2enp5q2LChQkJC8jV/Yfnggw/0/fffq2bNmvrb3/6ml19+WY899tgln9XhcOjFF1/UjBkz9Morr1wyT0pKiqZPn66BAweqWrVq152nV69emjlzppYuXarNmzerQ4cOkkrG79oqnMu2Ao3hXAYAAPnhfv+0CQBAMbZ3717df//9atKkiV577TWlpKRo4cKFef7CnpCQoAkTJuiuu+5So0aN1LNnTz3++OOSpCVLlqhly5YaNWqUpkyZonfffVebNm1Sv3798jyn68UXX9S+ffs0atQotW3bVi+++GK+5i9MQUFBGjt2rDp06KDk5GQNGDBAoaGhysnJyTPutdde06hRo654u93ChQv1/PPPa86cOTecKTAwUJK0fv16SSXnd20FzuW853J+xnAuAwCAfDEAAOCKJJnY2Nh8j2/Tpo0ZO3as8+fc3FxTt25d06BBA2OMMWlpaaZu3bomPT3dOWbQoEFGktm4caMxxphx48YZSWbVqlXOMS1atDAtW7Z0znnTTTeZhIQE5/rXX3893/MXRGZmppFknnzyyauO2759u2nYsKGRGN9uwQAAIABJREFUZN566y3n8rVr15oJEyY4fx49erSpVq1anm3T09PN7NmzTWpq6lX3cfbsWSPJNGrU6Ipj5s+fbySZLl26uNXvOjY21hTl17LrmZ9zOe+5nJ8xnMvGREZGmsjIyAJtAwBAKTOH21QBACgka9as0ffff5/nVkybzabWrVtr+/btkqSYmBidP39ezz77rHPMsWPHVK9ePe3bt0+BgYEqW7asJOV5xlXjxo21YsUK55y33367evXqpWnTpqlHjx565pln8j1/UWjWrJm2bt2q22+/XTExMRo3bpzOnDmjDz/8UDExMVfdtnz58urTp0+h5EhPT3fOWVJ/167AuZz3XM7vGM5lAACQH5RxAAAUkh07dkiS7rzzzjzL/3xb3+7du1W9enV99NFHBZrb09NTxhjnzx9++KGioqLUs2dP3Xvvvfrqq69UrVq1656/MJQrV049evTQv//9b0nS6NGj1bp1ay1evNg55pdfftGFCxc0f/58VapUSffcc0+hZti2bZskqU2bNiX6d13UOJfznsvXO+ZGcC4DAFBy8cw4AAAKSWpqqiTp+++/v2TdxRLD09NTe/fulcPhuKF9NW/eXNu2bdOIESO0du1atWjRQr///nuhzX+9GjZsqAYNGkiSTp48qSlTpujJJ590/lm7dq3S0tL05JNP5nmWVWEwxmj9+vXy9PRUSEhIif9dFyXO5bzn8o2MuR6cywAAlGyUcQAAFJImTZpI+uMWvytp1qyZMjIy9PHHH+dZfubMGU2dOjVf+8nMzNSsWbPk5+enjz76SPHx8Tp27Jjmz59fKPPfiAULFqhHjx6SpP/85z9KTk7O82f48OHy9/dXcnKy8/a5wjJ69Ght3bpVkyZNUrNmzUr877oocS7nPZdvZMz14FwGAKCEs/KJdQAAFHcqwAscHA6HadiwofH19TXr1q0zxhjz22+/merVqxtfX1+zY8cOk56ebmrWrGm8vb3NxIkTTVJSkomNjTVRUVHOh74//fTTRpI5cOCAc+7w8HDj5+dncnNzzfnz5027du1Mbm6uMeaPB7P7+/ubBQsWmAsXLlxz/oI4fvy4kWSGDh2aZ/nevXvNU089ZbZt2+ZctmvXLtOmTRuTlZV1xfnGjh17yQsctmzZYlq3bp3nwfKXs2PHDiPJ1KlTJ8/ygwcPmhEjRhibzWZGjhzpXJ6f30Vx+V0Xtxc4cC7nPZfze75zLvMCBwAA8mEOZRwAAFdRkDLOmD/+Mt26dWsjydStW9f07dvXREREmA4dOph//etf5vz58yYpKck0aNDASDKSzB133OH8S/7atWtN3bp1jSQzePBgc+zYMRMTE2MqVKhgJJkJEyaYtLQ0U716ddO7d28TFxdnJk+ebF5++WVnhqvNXxBLly41vXr1MpLMzTffbKZPn26OHTtmjDFm69atpmLFikaSCQ4ONs8995x5++23zblz56465+XKuHnz5hmbzWamT59+xe0WL15sOnfu7PxMbdu2NSEhISY8PNz06NHDPP300+aHH364ZDt3+V0XtzLOGM7lP5/L+T3fOZcp4wAAyIc5NmP+9FRXAACQh81mU2xsrKKjowu03cmTJ1WuXDmVL19e6enp8vX1vWTMr7/+KpvNplq1ahU4V3Z2tnJzc3X8+PErbn8j8+dHZmamDh8+rHLlyunWW2+9oblSU1NVoUKFQkp2qeL+u54zZ4569eqlovpadiPzcy7nf4zEuRwVFSVJiouLu67tAQAoBeJ4myoAAEXA39/f+d+XKy8kqXbt2tc9v93+x//Cr/YX5svNP2LEiGvOPXToUDVv3vya43x8fFS/fv1rjsuPoiwvJGt+1yUF53L+x0icywAA4Noo4wAAKEWCg4OvOebP5QtQXHEuAwAAd0UZBwBAKXLxFjLA3XEuAwAAd+VhdQAAAAAAAACgtKCMAwAAAAAAAFyEMg4AAAAAAABwEco4AAAAAAAAwEUo4wAAAAAAAAAXoYwDAAAAAAAAXIQyDgAAAAAAAHARyjgAAAAAAADARSjjAAAAAAAAABehjAMAAAAAAABchDIOAAAAAAAAcBHKOAAAAAAAAMBFKOMAAAAAAAAAF6GMAwAAAAAAAFzEbnUAAACKu/fee09xcXFWx4CknJwceXp6Wh2j0CUnJ7tkP1FRUS7Zj6tlZ2fLbudrbXGwadMmBQYGWh0DAIBijSvjAAC4isjISAUEBFgdA5J27typDRs2KCcnx+oohS4gIECRkZFFNn/NmjWLdH4rnT17VsuXL9fJkyetjgJJgYGBatu2rdUxAAAo1mzGGGN1CAAAgGv573//q86dO6tVq1ZavHixfHx8rI4Ei+3bt0+dOnVSw4YNFR8fr7Jly1odCQAA4FriuDIOAAC4hSZNmmjZsmXauHGj+vbtWyKvkEP+JScnKyQkRDVr1tSiRYso4gAAgNugjAMAAG7j7rvv1qJFi7R06VINHjxYXOBfOp08eVKhoaHy8/PT0qVL5efnZ3UkAACAfONJtwAAwK0EBwdr0aJF6t69uypUqKD333/f6khwobNnz+r++++Xw+HQ6tWrVbVqVasjAQAAFAhlHAAAcDuhoaGaPXu2oqOjVbVqVb388stWR4ILnDt3Tt26ddOJEye0fv16Va9e3epIAAAABUYZBwAA3NKDDz6oTz/9VAMHDlS5cuX0zDPPWB0JRSgrK0sPPvig9u7dq3Xr1qlOnTpWRwIAALgulHEAAMBt9e/fX6mpqRo1apQqVqyoIUOGWB0JRSAnJ0d9+/bVpk2btGbNGjVq1MjqSAAAANeNMg4AALi1J598UqdOndLw4cPl5+en3r17Wx0JhSg3N1f9+vXTsmXLtGLFCrVo0cLqSAAAADeEMg4AALi9V199VefOnVO/fv3k5+en8PBwqyOhEBhjNGLECM2dO1eLFy9Whw4drI4EAABwwyjjAABAiTBx4kSdPXtWUVFRWrp0qTp37mx1JNygcePG6dNPP1VsbKzCwsKsjgMAAFAoPKwOAAAAUBhsNpv+9a9/qUePHurevbt++OEHqyPhBrz22muaPHmyZs6cqYceesjqOAAAAIWGMg4AAJQYnp6emjlzpjp16qTQ0FBt377d6ki4Dh9++KEmTJigqVOnqm/fvlbHAQAAKFSUcQAAoETx8vJSXFycmjdvrrCwMO3du9fqSCiAmTNn6qmnntI//vEPDRs2zOo4AAAAhY4yDgAAlDhly5bV4sWLVbt2bYWEhOjXX3+1OhLyYcGCBRo0aJBefPFFPfvss1bHAQAAKBI2Y4yxOgQAAEBROHPmjIKDg5WRkaHExETdcsstVkfCFaxcuVIREREaMmSIPvjgA6vjAAAAFJU4yjgAAFCinThxQp06dZKPj48SEhJUpUoVqyPhL7777juFhobqoYce0meffSYPD27eAAAAJVYc33QAAECJdvPNN2vlypU6e/aswsPDlZ6ebnUk/Mn27dsVHh6u0NBQzZgxgyIOAACUeHzbAQAAJV7NmjW1cuVKHTp0SD169NCFCxesjgRJu3bt0n333afWrVsrJiZGdrvd6kgAAABFjjIOAACUCvXr19eKFSu0fft29erVS9nZ2VZHKtX279+vsLAw3X777VqwYIF8fHysjgQAAOASlHEAAKDUaNq0qeLj47VmzRr1799fubm5VkcqlX777TeFhITo5ptvVnx8vMqXL291JAAAAJfhXgAAAFCqBAYGatGiRQoPD5ePj48+/fRT2Ww2q2OVGidPnlRoaKjKly+vVatWqVKlSlZHAgAAcCnKOAAAUOrcc889io2N1UMPPaQKFSrovffeszpSqXD27Fl16dJFmZmZSkxMVNWqVa2OBAAA4HKUcQAAoFTq3r27Pv/8c/Xr10/+/v56/vnnrY5Uop07d04RERE6fvy41q9frxo1algdCQAAwBKUcQAAoNR6+OGHlZmZqcGDB6tMmTIaM2aM1ZFKpKysLEVGRmrPnj1at26d/va3v1kdCQAAwDKUcQAAoFQbOHCgUlNTNWbMGFWsWFGDBg2yOlKJkpOTo0ceeUTfffedVq9ercaNG1sdCQAAwFKUcQAAoNQbNWqUTp48qWHDhsnPz0/R0dFWRyoRjDEaOnSo4uPjtXz5crVs2dLqSAAAAJajjAMAAJD0xhtv6MKFC3r00Ufl6+urrl27Wh3J7T399NP68ssvtXDhQnXs2NHqOAAAAMUCZRwAAMD/mTx5ss6ePavIyEgtX75cnTp1sjqS2xo/frymTJmimJgYdenSxeo4AAAAxYaH1QEAAACKC5vNpk8++UQRERGKiIjQli1brI7klt588029/fbbmjZtmqKioqyOAwAAUKxQxgEAAPyJp6enZs2apQ4dOqhLly5KSkqyOpJbmTp1ql544QW98847GjhwoNVxAAAAih3KOAAAgL/w9vbW3Llz1bhxY4WEhOjAgQNWR3ILX375pUaOHKm33npLo0ePtjoOAABAsUQZBwAAcBlly5bVkiVLVKNGDQUHB+vw4cNWRyrWFi5cqAEDBmjcuHEaN26c1XEAAACKLZsxxlgdAgAAoLhKSUlRUFCQsrOzlZiYqGrVqlkdqdhZtWqVunXrpkGDBumjjz6yOg4AAEBxFseVcQAAAFdx0003aeXKlcrOzlZYWJhOnz5tdaRiZePGjXrggQcUFRWlDz74wOo4AAAAxR5lHAAAwDXUqFFDCQkJOn36tMLDw5Wenn7JmFOnTmnu3LkWpCt6n3zyiS53M8WOHTsUHh6u++67T5999pk8PPhqCQAAcC18YwIAAMiHWrVqaeXKlTpw4IAeeOABZWZmOtcdO3ZM7dq104gRI/IsLwlWr16tv//97xoxYoRyc3Ody3/++WeFhYWpZcuW+vrrr2W32y1MCQAA4D4o4wAAAPKpQYMGWrFihbZu3arevXsrOztbhw4dUmBgoA4ePKhTp04pJibG6piFatKkSfL09NS0adP0yCOPKDs7W4cPH1ZISIjq1q2rBQsWyMfHx+qYAAAAboMXOAAAABTQhg0bFBYWptDQUG3atEmnTp2Sw+GQh4eH6tevrz179shms1kd84bt3btXjRo1ct6iarfb1alTJx08eFCVK1fWmjVrVLFiRYtTAgAAuBVe4AAAAFBQHTp00KRJk7RixQqlpKTI4XBIknJzc7V3716tWrXK4oSFY/LkyXluP734Rtnz589r7ty5FHEAAADXgSvjAAAACuiHH37Qfffdp3Pnzik7OzvPOrvdruDgYH3zzTcWpSscJ0+eVEBAgLKysi5Z5+XlpTvvvFMrV65U1apVLUgHAADgtrgyDgAAoCASEhIUFBSkjIyMS4o46Y+rx1atWqWkpCQL0hWeqVOn5nlhw585HA7t2rVL7dq107Fjx1ycDAAAwL1RxgEAAOTTwoULFRYWpgsXLignJ+eK4+x2u959910XJitcFy5c0JQpUy5bNl7kcDj0yy+/KCgoSMnJyS5MBwAA4N4o4wAAAPKpefPm6tu3r2w2m7y9va84zuFwaObMmTpx4oQL0xWer776SmfOnLnqGE9PT1WsWFF///vfuVUVAACgACjjAAAA8qlOnTr6/PPPtW/fPvXr108eHh55XnDwV1OnTnVhusJhjNHkyZOvuN7Ly0vlypXTM888o0OHDmnMmDEqW7asCxMCAAC4N17gAAAAcJ12796tl19+WQsWLJDdbne+VfWiSpUq6ejRo25VVi1btkxdu3a9ZLmXl5c8PDw0atQoPffcc6pcubIF6QAAANweL3AAAAC4XnfccYfmzZunTZs26d5775WkPFfKpaWl6auvvrIq3nWZNGlSns/g5eUlu92uAQMG6NChQ/rHP/5BEQcAAHADuDIOAACgkCQmJuq5557Tpk2bZLfblZOTo9tuu0179+6VzWazOt41/fe//1WzZs1kjJGXl5eMMRo0aJBeeukl3XrrrVbHAwAAKAniKOMAACgF5syZY3WEUmX79u2KiYnRoUOHJEnjx49X8+bNrQ2VD//617+0du1a2Ww2dezYUVFRUbr55putjlVq1KxZU23btrU6BgAAKFqUcQAAlAbucFUWUNpFRkYqLi7O6hgAAKBoxV359V8AAKBEiY2NVXR0tNUxSp3c3FzFxsYqNDRUVatWtTrOFa1bt06VK1dW06ZNrY5SKkVFRVkdAQAAuAhlHAAAQBHy8PBQnz59rI5xTUFBQVZHAAAAKBV4myoAAAAAAADgIpRxAAAAAAAAgItQxgEAAAAAAAAuQhkHAAAAAAAAuAhlHAAAAAAAAOAilHEAAAAAAACAi1DGAQAAAAAAAC5CGQcAAAAAAAC4CGUcAAAAAAAA4CKUcQAAAAAAAICLUMYBAAAAAAAALkIZBwAAAAAAALgIZRwAAAAAAADgInarAwAAAOD/O3XqlBYtWqTDhw+radOmCg0Nla+vb54xZ86c0YwZM3T48GGFh4fr3nvvlaen5w3t98iRI9q2bZt27twpDw8P1a9fX61bt5bNZlNycrI6dOhwQ/MDAADgD1wZBwAAUExs375dnTt3VuPGjfXss89q3759at++vY4dO+Yc8/vvv6tVq1basWOHdu3apS5duqhdu3bXvc+srCyNHTtWDRo00LfffqsWLVqoXbt2OnDggFq2bKm6detq8+bNhfHxAAAAIMo4AADg5mbOnFki9pubm6v+/fura9euCgwMVLly5fTss8+qTJkyeuyxx5zj5syZo82bN2vmzJlavXq1JkyYoM2bN+vbb78t8D4vXLigtm3bavr06Vq5cqUmTpyo8PBwBQcHa9y4cfrhhx8UEBCgc+fOFeZHLRQl5bgDAIDShzIOAAC4rTVr1mj8+PElYr+bNm3Sjh07dNddd+VZfvfdd2vlypXaunWrsrKyFBYWpipVqjjX9+vXT5JUoUKFAu/z9ddf17Zt2zR27NjL3oZar149vfTSS8rIyCjw3EWpJB13AABQ+nhOmDBhgtUhAABA0Xr11VcVFRWlO+64I9/bpKena86cOYqLi1NKSooCAgJUpkwZ5/q0tDQtXLhQc+fO1f79++Xv76+KFSs61x85ckSff/657r77bu3evVvTp0/Xr7/+qiZNmshms+V7Pz///LPi4+M1a9YsZWRkqFGjRpKkhIQE9ezZUw6HQ1WqVNGxY8d0++23S5KOHj2quLg4LVmyRNnZ2apbt26BcxX2fq9l1apVWrRokR566CE1adLEuTwlJUULFy5U48aN1b59e1WuXDnPduvXr1daWppGjRqVZ5v3339fDRo0uOR5cxcdP35ckZGRKlOmjOLi4uTj43PZcU2aNFFaWpoaN24sieNe2Mf9ori4OElSdHR0gbcFAABuJUkGAACUeJJMbGxsvsfv2bPHdO3a1ezYscM4HA7Tp08fU7VqVbN//35jjDHbt283TZo0MfPmzTMnTpwwkydPNr6+vuaLL74wxhizePFi4+/vbySZ9957zwwYMMB069bNSDJvvvlmvvfz3nvvmc6dO5vc3Fxz8OBBU6dOHTN16lRjjDE//vijad++vfH39zcJCQnmxx9/NMYYs2bNGjNkyBCzbds2M2fOHOPr62tGjBhRoFyFvd/8iImJMZLMmDFj8izfsGHDZZfn5uaa2NhY07hxY3PkyJE866ZPn24kmSlTplxxf0uXLjWSzJ133pnvjBz3wj/uF0VGRprIyMgCbwcAANzOHMo4AABKgYKUcdnZ2aZ58+Zm2rRpzmVbt2413t7eZsmSJSYzM9M0bNjQvPzyy3m269u3r/H29ja7d+82xhgzbtw4I8msWrXKOaZFixamZcuW+dqPMcbcdttt5vHHH3eu79mzp+natWuen2vWrOn8OS0tzdStW9ekp6c7lw0aNMhIMhs3bsxXrqLa77UcPnzYeHt7m5YtW5rc3Fzn8vj4+EuKtfT0dDNkyBBTrlw5I8lUqlTJbN68Oc/62bNnm9TU1Cvub+LEiUaSiYiIyFc+jnvRHPeLKOMAACg15thddhEeAABwC0uXLtX27dsVHh7uXNaiRQulpaXJ29tbixcv1k8//aTAwMA824WFhWn27NmaMWOG3nnnHZUtW1aS1LBhQ+eYxo0ba8WKFfnajyStXbtW5cuXlyQlJSXpyJEjSk1NzbPfP99iGBMTo/Pnz+vZZ591Ljt27Jjq1aunffv2KTAw8Jq5imq/11KzZk29/vrrevbZZzVgwABFR0drz549+vrrryVJzZo1c44tX768pk2bpo8//lhTpkzRM888o+HDh2vLli3O9X369Lnq/uz2P74G5uTkXDObJC1fvpzjfh37BQAA+CvKOAAAkMeOHTtUvnx5+fv751l+sShJSkqSpEueRdaxY0dJ0p49e644t6enp4wx+dqPJN1666365ptv9J///EdBQUGqV6+etm7dmmf8n8uR3bt3q3r16vroo4/y9Vkvl8uV+/2rsWPH6u6779Y333yjDRs2qHfv3tq0aZN++eWXS17sIEkeHh4aNWqUvvvuO82bN0+ZmZlXfPbbX118fuAvv/ySr/Ec98LbLwAAKN0o4wAAQB65ubnKyMhQQkKCQkNDL1l/8U2eGzdudBYxklS7dm15eXld8oKB692PJL300ktat26dVqxYobJly2revHmXjPlzOeLp6am9e/fK4XDIy8srXzmK034lKSgoSEFBQZKkgwcPavHixZo0aZL8/PyuuE1ISIgSEhLyXcRJUsuWLeXr66sDBw5o//79qlev3lXHc9yLbr8AAKB08bA6AAAAKF4uvslz9uzZeZafOnVKCxYsUJs2bSRJiYmJedbv2rVLDodDbdu2LZT9HDx4UK+//roeeeQR5y2Gubm5ecbabLY8t1k2a9ZMGRkZ+vjjj/OMO3PmjKZOnZqvXFbt96+ysrLUq1cv3X777RoxYsRVx+7atUsREREFmr9q1ap69dVXlZOTk+c2y8v58ccfOe5FtF8AAFD6cGUcAADIo3v37rrrrrv0xRdfqEyZMoqKitLOnTu1du1azZkzRz4+Pnrsscc0f/58HT58WLVq1ZIkbdiwQfXr19fQoUMlyfmsraysLOfcKSkpyszMlDHmmvv5+eefJf3xXK7evXtrx44d/6+9u4/Vuqz/AP654ZzjBERyEGE8TB5OB1FAiRDFBBlmA4UtnglUVFqQDhYUKyHWco1MtjCJhbaKFYMDiDmZfzRAbPGgoGgQlCseTsAGChwOIRzh+v3hvH+eAOEgfG8OvF7/wH19r+91fe7v/Q97c13XN1avXh3Hjh2LqqqqSClFixYtYu/evfGvf/0rUkoxYMCAaNWqVUyePDk++OCDGDBgQLzzzjuxePHieP7558+prqqqqosyb20cOXIkxo8fHzfccEM888wz+fPdjh49GrNmzYqBAwfGTTfdFBEfhVhvvvlmvPTSS/n7N2zYEN/+9rfjZz/7WfTu3fuM8zz++OOxbt26WLRoUTz66KMxe/bsfBAVEbFjx4548sknY/To0XHnnXf63S/y7w4AXCGyf2kEAJC1qMXbVFNKqaKiIvXr1y/lcrmUy+VS7969U0VFRf760aNH04QJE1KnTp3Sb3/72/Tcc8+l/v37p507d6aUUlq1alVq27Ztioj0yCOPpD179qQFCxakxo0bp4hIM2bMSNXV1WedZ+zYsamoqCi1b98+zZ07Ny1evDiVlJSku+++O7333ntp5cqVqaioKDVp0iT/ttEtW7ak0tLSFBEpIlKnTp3Sxo0ba1XXhZ73XO3fvz89//zz6fbbb09Lly495XpVVVW65ZZbUi6XS927d0/Tpk1Lv/jFL9Lhw4dr9FuyZEnK5XJp3rx55zTv/PnzU+vWrVPz5s3T/fffn8aOHZtKS0vT0KFD09atW/P9/O4X53dPydtUAeAKsiiX0idOrQUALku5XC4WLlwYQ4cOrdV9Bw8ejJMnT+bPC/tfhw4dis2bN0fr1q2jZcuW513fp81z+PDhGuel/e9LCg4dOhT16tU75Uy1HTt2RC6Xy6/gqq1CzLts2bLo3LlztG3b9lP7HTx4MEpKSqJBgwZn7FNZWRmNGzeu1fwHDhyIv/3tb1FcXBylpaV+9wznHTJkSERElJeXn9f9AECdUS6MA4ArwPmGcVwYZzvzLSJi3Lhx0bVr1wyq4VIkjAOAK0a5M+MAAC6yPn36nLVPs2bNMqgEAIBCE8YBAFxkH696AgCAeoUuAAAAAACuFMI4AAAAAMiIMA4AAAAAMiKMAwAAAICMCOMAAAAAICPCOAAAAADIiDAOAAAAADIijAMAAACAjAjjAAAAACAjwjgAAAAAyIgwDgAAAAAyIowDAAAAgIwI4wAAAAAgI8I4AAAAAMhIUaELAACysWbNmkKXAJxBRUVFtGzZstBlAAAZyKWUUqGLAAAurlwuV+gSgLMYPHhwlJeXF7oMAODiKrcyDgCuAP7v7fKyaNGiGDZsmN8VAKAOcmYcAAAAAGREGAcAAAAAGRHGAQAAAEBGhHEAAAAAkBFhHAAAAABkRBgHAAAAABkRxgEAAABARoRxAAAAAJARYRwAAAAAZEQYBwAAAAAZEcYBAAAAQEaEcQAAAACQEWEcAAAAAGREGAcAAAAAGRHGAQAAAEBGhHEAAAAAkBFhHAAAAABkRBgHAAAAABkRxgEAAABARoRxAAAAAJARYRwAAAAAZEQYBwAAAAAZEcYBAAAAQEaEcQAAAACQEWEcAAAAAGREGAcAAAAAGRHGAQAAAEBGhHEAAAAAkBFhHAAAAABkRBgHAAAAABkRxgEAAABARoRxAAAAAJARYRwAAAAAZKSo0AUAAHBm+/btixdeeKFG2xtvvBEREb/+9a9rtDdq1ChGjhyZWW0AANReLqWUCl0EAACnd+zYsWjWrFkcOXIk6tevHxERKaVIKUW9ev+/yaG6ujrGjBkTv/vd7wpVKgAAZ1dumyoAwCXsqquuiiFDhkRRUVFUV1eqisUTAAAMU0lEQVRHdXV1fPjhh3HixIn85+rq6ogIq+IAAOoAYRwAwCVu5MiRcfz48U/t06RJk+jbt29GFQEAcL6EcQAAl7g+ffpEs2bNzni9uLg4vvnNb0ZRkeOAAQAudcI4AIBLXL169WLkyJFRUlJy2uvV1dUxYsSIjKsCAOB8COMAAOqAESNGnHGraosWLaJnz54ZVwQAwPkQxgEA1AE9evSINm3anNJeXFwcDzzwQORyuQJUBQBAbQnjAADqiNGjR0dxcXGNNltUAQDqFmEcAEAdMWrUqKiurq7R1r59++jcuXOBKgIAoLaEcQAAdURZWVnceOON+S2pxcXF8dBDDxW4KgAAakMYBwBQh4wZMybq168fER9tUR06dGiBKwIAoDaEcQAAdcjw4cPjxIkTERHRrVu3aN++fYErAgCgNoRxAAB1SJs2baJ79+4R8dEqOQAA6pZcSikVuggA4Mo1ZMiQWLx4caHL4AqxcOFCW3sBgEIqLyp0BQAAt912W0yaNKnQZdQZlZWVMWfOnJg6dWqhS6lThg0bVugSAABCGAcAFFzLli2tVqqlu+66Kzp06FDoMuoUYRwAcClwZhwAQB0kiAMAqJuEcQAAAACQEWEcAAAAAGREGAcAAAAAGRHGAQAAAEBGhHEAAAAAkBFhHAAAAABkRBgHAAAAABkRxgEAAABARoRxAAAAAJARYRwAAAAAZEQYBwAAAAAZEcYBAAAAQEaEcQAAAACQkaJCFwAA8FlVVVXFypUr4y9/+UvMnDmz0OWcl71798bWrVujd+/ep73+8ssvR2VlZf7zrl274jvf+U40aNDglL6bNm2K1atXR0lJSfTv3z9atmx5TjWsXr06/vOf/9RoKy4ujmbNmsX1118fHTp0OPcvBADAaQnjAIA675VXXokpU6bEyZMn61wYt2/fvpg5c2bMmTMnHn300dOGcVu3bo377rsvUkr5tuHDh58SxO3fvz+mTp0au3fvjrlz50br1q1rVUvnzp1j9erVMW3atCgpKYnZs2fHyZMnY+3atbFixYo4cOBAjBo1Kn70ox9FcXHxeX1fAIArnTAOAKjzBg8eHOXl5fHGG28UupRa2759e4wZMyaefvrpM/aZNWtWrFixItq1a5dva9as2SnjdO/ePe69995Yvnz5edXSpEmTePDBB2PatGnRrl27+Na3vpW/llKKJUuWxMMPPxzr16+PJUuWxDXXXHNe8wAAXMmEcQDAZaFevXpRr17dOw63e/fucfz48TNe37t3b7z99tsxffr0M243PX78eAwdOjSuu+66mDt37meqp3Hjxqdtz+VyMXjw4Dhx4kQMHz487rzzzli/fn2UlJR8pvkAAK40wjgAoE56//33Y/HixbF9+/b48pe/HCmlyOVyNfrs3r07XnnllaioqIg77rgj+vbtm7+2a9euWLp0aTz22GOxZcuWePHFF6N169YxatSofKiXUopXX3013nrrrahfv36UlZVFv379zmn8C+WZZ56JdevWRatWreKGG26I6dOnxwMPPFDju/7whz+M119/PZ577rlo2LDhacfZv39/zJs3L8aOHRvNmzc/73qGDRsWv//972P58uWxfv366NWrV0RcHs8aACALde+/jwGAK962bdvi3nvvjZtvvjl+/OMfx/79+2PZsmU1AqqVK1fGjBkz4pZbbomOHTvGoEGDYsKECRER8dJLL0W3bt1i4sSJMXv27Jg1a1asXbs2xowZU+PMuSeeeCLefffdmDhxYvTs2TOeeOKJcxr/QrrrrrtiypQp0atXr6ioqIiHHnoo7rnnnjhx4kS+z4IFC6KoqCjeeeeduPvuu6NRo0bx1a9+NTZu3Jjvs2zZsvjBD34QixYt+sw13XbbbRER8dprr0XE5fOsAQAykQAACmjw4MFp8ODBtbqnR48eacqUKfnPJ0+eTG3btk2lpaUppZQOHz6c2rZtm6qqqvJ9Hn744RQRac2aNSmllKZOnZoiIv35z3/O97n11ltTt27d8mM2bdo0rVy5Mn/9Jz/5yTmPXxvHjh1LEZEef/zxT+331ltvpbKyshQR6ac//WlKKaWKiooUEalr167pvffeSymltG3bttSiRYvUqFGjVFFRkVJKqaqqKv3xj39MlZWVnzrHoUOHUkSkjh07nrHP0qVLU0Skr3/963XqWUdEWrhwYa3uAQC4wBZZGQcA1CkrVqyIdevWRZ8+ffJtuVwuunfvnl8Zt2DBgjh69Gh873vfiwkTJsSECRNiz5490a5du3j33XcjIuLqq6+OiIiysrL8ODfeeGPs3LkzP+aXvvSlGDZsWLz44osRETF58uRzHv9i6NKlS2zYsCFatmwZCxYsiIjIr34bNGhQXHfddRERUVpaGrNmzYqqqqqYM2dOREQ0bNgwRowYcUFeulBVVZUf83J91gAAF4sz4wCAOmXTpk0REXHTTTfVaP/kFtXNmzdHixYt4tlnn63V2PXr14+UUv7zL3/5yxgyZEgMGjQo+vbtG3/4wx+iefPm5z3+hdCgQYMYOHBg/OY3v4mIiGuvvTYiIpo2bVqjX8+ePSPioy29F9rHAWCPHj0u62cNAHAxWBkHANQplZWVERGxbt26U659HMjVr18/tm3bFtXV1Z9prq5du8bGjRtj/PjxsWrVqrj11lvj/fffv2Djn6+ysrIoLS2NiMj/uWHDhhp9WrduHcXFxRdkJdwnpZTitddei/r160e/fv0u+2cNAHChCeMAgDrl5ptvjoiPtqueSZcuXeLIkSMxd+7cGu0HDx7Mb9s8m2PHjsX8+fPjmmuuiWeffTZefvnl2LNnTyxduvSCjP9ZvPDCCzFw4MCIiPjCF74QX/va12Lt2rU1+vzzn/+M6urquOOOOy7o3JMmTYoNGzbEU089FV26dLnsnzUAwIUmjAMA6pT7778/ysrKYv78+bF69eqIiNi9e3e8+uqrUVFREW+//XZ84xvfiFatWsXkyZPjqaeeir///e+xaNGiGDduXIwePToi/n+F3fHjx/Nj79+/P44dOxYppUgpxdy5c/NbKe+5555o2rRpNG3aNIYNG3bW8WvjwIEDERHxwQcf1Gj/xz/+ERMnTow333wz37Z58+Y4cuRIjbeNPv3007Fr167461//mm9buXJldOzYMR588MGI+Gjl3Fe+8pVYtWrVp9ayffv2iIg4evToKe0TJkyI2bNnx2OPPRaTJk2KiDinZ3EpPWsAgIIr2LsjAADS+b1N9d///nfq3r17iojUtm3bNHLkyHTfffelXr16pV/96lfp6NGjacuWLam0tDRFRIqI1KlTp7Rx48aUUkqrVq1Kbdu2TRGRHnnkkbRnz560YMGC1Lhx4xQRacaMGenw4cOpRYsWafjw4am8vDz9/Oc/T9OnT8/X8Gnj18by5cvTsGHDUkSkz3/+82nevHlpz549KaWUNmzYkK699toUEalPnz7p+9//fpo5c2b673//e8o4mzZtSn379k3Tp09PTz75ZBowYEDavXt3/vqSJUtSLpdL8+bNO2Mtf/rTn1Lv3r3z36lnz56pX79+qX///mngwIHpu9/9bnr99ddPua+uPOvwNlUAoPAW5VL6xMm5AAAZGzJkSERElJeX1/reffv2RYMGDaJhw4ZRVVUVjRo1OqXPjh07IpfLRevWrWs9/ocffhgnT56MvXv3nvH+zzL+uTh27Fjs3LkzGjRoEF/84hfP2n/37t1x9dVXx+c+97lTrlVWVkbjxo0vRpkRcek/61wuFwsXLoyhQ4ee1/0AABdAubepAgB1VrNmzfJ/P10QFxHRpk2b8x6/qOijfyp9WvhzuvHHjx9/1rHHjRsXXbt2PWu/q666Kjp06HDWfh+7/vrrz3jtYgZxEYV51gAAdY0wDgDgAuvTp89Z+3wySAQA4MohjAMAuMA+3noLAAD/y9tUAQAAACAjwjgAAAAAyIgwDgAAAAAyIowDAAAAgIwI4wAAAAAgI8I4AAAAAMiIMA4AAAAAMiKMAwAAAICMCOMAAAAAICPCOAAAAADIiDAOAAAAADIijAMAAACAjAjjAAAAACAjwjgAAAAAyEhRoQsAAFi8eHHkcrlClwEAABddLqWUCl0EAHDlWrNmTezatavQZXCFuP3226Nly5aFLgMAuHKVC+MAAAAAIBvlzowDAAAAgIwI4wAAAAAgI8I4AAAAAMhIUUSUF7oIAAAAALgCrP0/op41WnUzL80AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3dc5ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_117\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_62 (Embedding)        (None, 100, 100)     661800      input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 94, 12)       8412        embedding_62[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 92, 40)       36040       embedding_62[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, 94, 37)       25937       embedding_62[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_140 (Globa (None, 12)           0           conv1d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_141 (Globa (None, 40)           0           conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_142 (Globa (None, 37)           0           conv1d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 89)           0           global_max_pooling1d_140[0][0]   \n",
      "                                                                 global_max_pooling1d_141[0][0]   \n",
      "                                                                 global_max_pooling1d_142[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 89)           0           concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_154 (Dense)               (None, 10)           900         dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_155 (Dense)               (None, 4)            360         dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 14)           0           dense_154[0][0]                  \n",
      "                                                                 dense_155[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 8)            120         concatenate_93[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 733,569\n",
      "Trainable params: 733,569\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9917af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger      0.442     0.279     0.342       775\n",
      "anticipation      0.445     0.226     0.300       633\n",
      "     disgust      0.431     0.163     0.237       460\n",
      "        fear      0.368     0.148     0.211       500\n",
      "         joy      0.624     0.404     0.490       592\n",
      "     sadness      0.437     0.254     0.322       464\n",
      "    surprise      0.409     0.071     0.121       505\n",
      "       trust      0.420     0.149     0.220       564\n",
      "\n",
      "   micro avg      0.463     0.219     0.298      4493\n",
      "   macro avg      0.447     0.212     0.280      4493\n",
      "weighted avg      0.450     0.219     0.288      4493\n",
      " samples avg      0.265     0.236     0.241      4493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charagon/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_pred_bool, digits = 3, target_names = emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d26ab072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.1814033086138049\n",
      "hamming loss   0.16575156873930405\n",
      "hamming score  0.22553717436775053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "\n",
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    http://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        #print('\\nset_true: {0}'.format(set_true))\n",
    "        #print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "print('accuracy_score', accuracy_score(y_pred_bool, test_labels))\n",
    "print('hamming loss  ', hamming_loss(y_pred_bool, test_labels))\n",
    "print('hamming score ', hamming_score(test_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ce41b",
   "metadata": {},
   "source": [
    "## Train an RNN (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d6318af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_47 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 704,560\n",
      "Trainable params: 704,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.4464 - accuracy: 0.2048 - val_loss: 0.4372 - val_accuracy: 0.1808\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.4374 - accuracy: 0.2150 - val_loss: 0.4368 - val_accuracy: 0.2102\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4373 - accuracy: 0.2166 - val_loss: 0.4372 - val_accuracy: 0.1808\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.4373 - accuracy: 0.2112 - val_loss: 0.4368 - val_accuracy: 0.2102\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.4372 - accuracy: 0.2187 - val_loss: 0.4367 - val_accuracy: 0.1808\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.4371 - accuracy: 0.2118 - val_loss: 0.4361 - val_accuracy: 0.2102\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4371 - accuracy: 0.2174 - val_loss: 0.4363 - val_accuracy: 0.2102\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4372 - accuracy: 0.2181 - val_loss: 0.4367 - val_accuracy: 0.2102\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.4371 - accuracy: 0.2150 - val_loss: 0.4372 - val_accuracy: 0.2102\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.4372 - accuracy: 0.2166 - val_loss: 0.4362 - val_accuracy: 0.1808\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.4382 - accuracy: 0.1649\n",
      "F1 score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# LSTM model parameters\n",
    "epochs = 10\n",
    "embed_dim = 100\n",
    "dropout_rate = 0.7\n",
    "num_classes = 8\n",
    "\n",
    "# Input is a special \"layer\".  It defines a placeholder that will be overwritten by the training data.\n",
    "# In our case, we are accepting a list of wordids (padded out to max_len).\n",
    "wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "# Embed the wordids.\n",
    "# Recall, this is just a mathematically equivalent operation to a linear layer and a one-hot\n",
    "h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "# Add LSTM\n",
    "h = keras.layers.LSTM(64)(h)\n",
    "\n",
    "# Dropout can help with overfitting (improve generalization) by randomly 0-ing different subsets of values\n",
    "# in the vector.\n",
    "# See https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf for details.\n",
    "h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # From information theory notebooks.\n",
    "              metrics=['accuracy'])        # What metric to output as we train.\n",
    "model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "model.evaluate(test_padded, test_labels)\n",
    "\n",
    "# Get F1 score\n",
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc5b36",
   "metadata": {},
   "source": [
    "### Bidirection LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4d09d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_48 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.4438 - accuracy: 0.2129 - val_loss: 0.4282 - val_accuracy: 0.2667\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 19s 59ms/step - loss: 0.4083 - accuracy: 0.3162 - val_loss: 0.3948 - val_accuracy: 0.3451\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 20s 61ms/step - loss: 0.3787 - accuracy: 0.3837 - val_loss: 0.3866 - val_accuracy: 0.3620\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 21s 64ms/step - loss: 0.3558 - accuracy: 0.4384 - val_loss: 0.3793 - val_accuracy: 0.3748\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 20s 61ms/step - loss: 0.3371 - accuracy: 0.4875 - val_loss: 0.3829 - val_accuracy: 0.3842\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 20s 60ms/step - loss: 0.3194 - accuracy: 0.5197 - val_loss: 0.3891 - val_accuracy: 0.3811\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 20s 60ms/step - loss: 0.3060 - accuracy: 0.5424 - val_loss: 0.3887 - val_accuracy: 0.3848\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 21s 63ms/step - loss: 0.2947 - accuracy: 0.5672 - val_loss: 0.3957 - val_accuracy: 0.3856\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 20s 61ms/step - loss: 0.2832 - accuracy: 0.5871 - val_loss: 0.4009 - val_accuracy: 0.3745\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 21s 64ms/step - loss: 0.2759 - accuracy: 0.5945 - val_loss: 0.4153 - val_accuracy: 0.3779\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.4191 - accuracy: 0.3697\n",
      "F1 score:  0.35835080363382243\n"
     ]
    }
   ],
   "source": [
    "# LSTM model parameters\n",
    "epochs = 10\n",
    "embed_dim = 100\n",
    "dropout_rate = 0.7\n",
    "num_classes = 8\n",
    "\n",
    "# Input is a special \"layer\".  It defines a placeholder that will be overwritten by the training data.\n",
    "# In our case, we are accepting a list of wordids (padded out to max_len).\n",
    "wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "# Embed the wordids.\n",
    "# Recall, this is just a mathematically equivalent operation to a linear layer and a one-hot\n",
    "h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "# Add a bidirectional LSTMs\n",
    "h = keras.layers.Bidirectional(keras.layers.LSTM(64))(h)\n",
    "\n",
    "# Dropout can help with overfitting (improve generalization) by randomly 0-ing different subsets of values\n",
    "# in the vector.\n",
    "# See https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf for details.\n",
    "h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # From information theory notebooks.\n",
    "              metrics=['accuracy'])        # What metric to output as we train.\n",
    "model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "model.evaluate(test_padded, test_labels)\n",
    "\n",
    "# Get F1 score\n",
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a6a43ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_49 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 100, 128)          84480     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 846,128\n",
      "Trainable params: 846,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 42s 129ms/step - loss: 0.4419 - accuracy: 0.2108 - val_loss: 0.4275 - val_accuracy: 0.2567\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 47s 144ms/step - loss: 0.4137 - accuracy: 0.2976 - val_loss: 0.3984 - val_accuracy: 0.3323\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 37s 112ms/step - loss: 0.3870 - accuracy: 0.3640 - val_loss: 0.3923 - val_accuracy: 0.3354\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 36s 109ms/step - loss: 0.3670 - accuracy: 0.4034 - val_loss: 0.3858 - val_accuracy: 0.3537\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 37s 112ms/step - loss: 0.3477 - accuracy: 0.4492 - val_loss: 0.3821 - val_accuracy: 0.3654\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 40s 122ms/step - loss: 0.3312 - accuracy: 0.4942 - val_loss: 0.3846 - val_accuracy: 0.3765\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 48s 145ms/step - loss: 0.3163 - accuracy: 0.5210 - val_loss: 0.3893 - val_accuracy: 0.3742\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 39s 119ms/step - loss: 0.3042 - accuracy: 0.5410 - val_loss: 0.3942 - val_accuracy: 0.3662\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 38s 114ms/step - loss: 0.2921 - accuracy: 0.5677 - val_loss: 0.3968 - val_accuracy: 0.3665\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 40s 123ms/step - loss: 0.2823 - accuracy: 0.5842 - val_loss: 0.4034 - val_accuracy: 0.3756\n",
      "110/110 [==============================] - 3s 26ms/step - loss: 0.4063 - accuracy: 0.3691\n",
      "F1 score:  0.3563687543983111\n"
     ]
    }
   ],
   "source": [
    "# LSTM model parameters\n",
    "epochs = 10\n",
    "embed_dim = 100\n",
    "dropout_rate = 0.7\n",
    "num_classes = 8\n",
    "\n",
    "# Input is a special \"layer\".  It defines a placeholder that will be overwritten by the training data.\n",
    "# In our case, we are accepting a list of wordids (padded out to max_len).\n",
    "wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "# Embed the wordids.\n",
    "# Recall, this is just a mathematically equivalent operation to a linear layer and a one-hot\n",
    "h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "# Add 2 bidirectional LSTMs\n",
    "h = keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True))(h)\n",
    "h = keras.layers.Bidirectional(keras.layers.LSTM(64))(h)\n",
    "\n",
    "# Dropout can help with overfitting (improve generalization) by randomly 0-ing different subsets of values\n",
    "# in the vector.\n",
    "# See https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf for details.\n",
    "h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # From information theory notebooks.\n",
    "              metrics=['accuracy'])        # What metric to output as we train.\n",
    "model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "model.evaluate(test_padded, test_labels)\n",
    "\n",
    "# Get F1 score\n",
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f8f32",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameter using Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c6efa909",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_129\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_67 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_68 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "329/329 [==============================] - 24s 73ms/step - loss: 0.4440 - accuracy: 0.2097 - val_loss: 0.4297 - val_accuracy: 0.2125\n",
      "Epoch 2/16\n",
      "329/329 [==============================] - 28s 86ms/step - loss: 0.4100 - accuracy: 0.3109 - val_loss: 0.3981 - val_accuracy: 0.3363\n",
      "Epoch 3/16\n",
      "329/329 [==============================] - 32s 99ms/step - loss: 0.3787 - accuracy: 0.3869 - val_loss: 0.3883 - val_accuracy: 0.3597\n",
      "Epoch 4/16\n",
      "329/329 [==============================] - 23s 70ms/step - loss: 0.3584 - accuracy: 0.4341 - val_loss: 0.3817 - val_accuracy: 0.3754\n",
      "Epoch 5/16\n",
      "329/329 [==============================] - 28s 86ms/step - loss: 0.3390 - accuracy: 0.4830 - val_loss: 0.3844 - val_accuracy: 0.3739\n",
      "Epoch 6/16\n",
      "329/329 [==============================] - 27s 83ms/step - loss: 0.3246 - accuracy: 0.5133 - val_loss: 0.3867 - val_accuracy: 0.3771\n",
      "Epoch 7/16\n",
      "329/329 [==============================] - 25s 75ms/step - loss: 0.3106 - accuracy: 0.5399 - val_loss: 0.3840 - val_accuracy: 0.3825\n",
      "Epoch 8/16\n",
      "329/329 [==============================] - 24s 73ms/step - loss: 0.2977 - accuracy: 0.5681 - val_loss: 0.3933 - val_accuracy: 0.3833\n",
      "Epoch 9/16\n",
      "329/329 [==============================] - 24s 74ms/step - loss: 0.2869 - accuracy: 0.5844 - val_loss: 0.4005 - val_accuracy: 0.3765\n",
      "Epoch 10/16\n",
      "329/329 [==============================] - 27s 81ms/step - loss: 0.2783 - accuracy: 0.5990 - val_loss: 0.4018 - val_accuracy: 0.3811\n",
      "Epoch 11/16\n",
      "329/329 [==============================] - 26s 80ms/step - loss: 0.2702 - accuracy: 0.6144 - val_loss: 0.4110 - val_accuracy: 0.3813\n",
      "Epoch 12/16\n",
      "329/329 [==============================] - 25s 76ms/step - loss: 0.2627 - accuracy: 0.6222 - val_loss: 0.4108 - val_accuracy: 0.3819\n",
      "Epoch 13/16\n",
      "329/329 [==============================] - 26s 78ms/step - loss: 0.2561 - accuracy: 0.6302 - val_loss: 0.4198 - val_accuracy: 0.3702\n",
      "Epoch 14/16\n",
      "329/329 [==============================] - 25s 77ms/step - loss: 0.2505 - accuracy: 0.6332 - val_loss: 0.4231 - val_accuracy: 0.3808\n",
      "Epoch 15/16\n",
      "329/329 [==============================] - 26s 78ms/step - loss: 0.2455 - accuracy: 0.6442 - val_loss: 0.4303 - val_accuracy: 0.3756\n",
      "Epoch 16/16\n",
      "329/329 [==============================] - 24s 74ms/step - loss: 0.2404 - accuracy: 0.6496 - val_loss: 0.4306 - val_accuracy: 0.3728\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.4343 - accuracy: 0.3665\n",
      "F1 score:  0.35380767092829346\n",
      "Model: \"functional_131\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_69 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/24\n",
      "329/329 [==============================] - 20s 59ms/step - loss: 0.4428 - accuracy: 0.2123 - val_loss: 0.4271 - val_accuracy: 0.2493\n",
      "Epoch 2/24\n",
      "329/329 [==============================] - 18s 55ms/step - loss: 0.4100 - accuracy: 0.3179 - val_loss: 0.3980 - val_accuracy: 0.3232\n",
      "Epoch 3/24\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.3816 - accuracy: 0.3774 - val_loss: 0.3858 - val_accuracy: 0.3677\n",
      "Epoch 4/24\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.3607 - accuracy: 0.4374 - val_loss: 0.3831 - val_accuracy: 0.3665\n",
      "Epoch 5/24\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.3415 - accuracy: 0.4721 - val_loss: 0.3851 - val_accuracy: 0.3808\n",
      "Epoch 6/24\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.3269 - accuracy: 0.5082 - val_loss: 0.3848 - val_accuracy: 0.3711\n",
      "Epoch 7/24\n",
      "329/329 [==============================] - 20s 59ms/step - loss: 0.3118 - accuracy: 0.5373 - val_loss: 0.3903 - val_accuracy: 0.3782\n",
      "Epoch 8/24\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.2999 - accuracy: 0.5629 - val_loss: 0.3934 - val_accuracy: 0.3791\n",
      "Epoch 9/24\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.2894 - accuracy: 0.5743 - val_loss: 0.3951 - val_accuracy: 0.3748\n",
      "Epoch 10/24\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.2809 - accuracy: 0.5922 - val_loss: 0.4007 - val_accuracy: 0.3799\n",
      "Epoch 11/24\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.2704 - accuracy: 0.6023 - val_loss: 0.4072 - val_accuracy: 0.3765\n",
      "Epoch 12/24\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.2652 - accuracy: 0.6132 - val_loss: 0.4106 - val_accuracy: 0.3702\n",
      "Epoch 13/24\n",
      "329/329 [==============================] - 21s 65ms/step - loss: 0.2602 - accuracy: 0.6250 - val_loss: 0.4172 - val_accuracy: 0.3734\n",
      "Epoch 14/24\n",
      "329/329 [==============================] - 21s 65ms/step - loss: 0.2534 - accuracy: 0.6346 - val_loss: 0.4255 - val_accuracy: 0.3774\n",
      "Epoch 15/24\n",
      "329/329 [==============================] - 21s 64ms/step - loss: 0.2467 - accuracy: 0.6380 - val_loss: 0.4349 - val_accuracy: 0.3697\n",
      "Epoch 16/24\n",
      "329/329 [==============================] - 21s 63ms/step - loss: 0.2419 - accuracy: 0.6459 - val_loss: 0.4367 - val_accuracy: 0.3702\n",
      "Epoch 17/24\n",
      "329/329 [==============================] - 20s 61ms/step - loss: 0.2400 - accuracy: 0.6503 - val_loss: 0.4306 - val_accuracy: 0.3659\n",
      "Epoch 18/24\n",
      "329/329 [==============================] - 20s 60ms/step - loss: 0.2332 - accuracy: 0.6575 - val_loss: 0.4488 - val_accuracy: 0.3736\n",
      "Epoch 19/24\n",
      "329/329 [==============================] - 24s 71ms/step - loss: 0.2321 - accuracy: 0.6582 - val_loss: 0.4538 - val_accuracy: 0.3702\n",
      "Epoch 20/24\n",
      "329/329 [==============================] - 22s 66ms/step - loss: 0.2284 - accuracy: 0.6604 - val_loss: 0.4533 - val_accuracy: 0.3719\n",
      "Epoch 21/24\n",
      "329/329 [==============================] - 20s 60ms/step - loss: 0.2276 - accuracy: 0.6636 - val_loss: 0.4509 - val_accuracy: 0.3731\n",
      "Epoch 22/24\n",
      "329/329 [==============================] - 22s 67ms/step - loss: 0.2209 - accuracy: 0.6681 - val_loss: 0.4704 - val_accuracy: 0.3722\n",
      "Epoch 23/24\n",
      "329/329 [==============================] - 29s 89ms/step - loss: 0.2198 - accuracy: 0.6708 - val_loss: 0.4726 - val_accuracy: 0.3671\n",
      "Epoch 24/24\n",
      "329/329 [==============================] - 23s 70ms/step - loss: 0.2166 - accuracy: 0.6725 - val_loss: 0.4699 - val_accuracy: 0.3699\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.4710 - accuracy: 0.3565\n",
      "F1 score:  0.35587568360677607\n",
      "Model: \"functional_133\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_70 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_18 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 23s 69ms/step - loss: 0.4436 - accuracy: 0.2180 - val_loss: 0.4275 - val_accuracy: 0.2658\n",
      "Epoch 2/5\n",
      "329/329 [==============================] - 25s 77ms/step - loss: 0.4118 - accuracy: 0.3053 - val_loss: 0.3980 - val_accuracy: 0.3371\n",
      "Epoch 3/5\n",
      "329/329 [==============================] - 35s 107ms/step - loss: 0.3815 - accuracy: 0.3819 - val_loss: 0.3888 - val_accuracy: 0.3525\n",
      "Epoch 4/5\n",
      "329/329 [==============================] - 22s 67ms/step - loss: 0.3603 - accuracy: 0.4302 - val_loss: 0.3792 - val_accuracy: 0.3776\n",
      "Epoch 5/5\n",
      "329/329 [==============================] - 21s 64ms/step - loss: 0.3413 - accuracy: 0.4797 - val_loss: 0.3807 - val_accuracy: 0.3728\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.3831 - accuracy: 0.3736\n",
      "F1 score:  0.2738361106339117\n",
      "Model: \"functional_135\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_70 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_71 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_19 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 21s 65ms/step - loss: 0.4453 - accuracy: 0.2097 - val_loss: 0.4316 - val_accuracy: 0.2259\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 33s 101ms/step - loss: 0.4135 - accuracy: 0.3041 - val_loss: 0.3981 - val_accuracy: 0.3369\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 29s 88ms/step - loss: 0.3842 - accuracy: 0.3697 - val_loss: 0.3864 - val_accuracy: 0.3505\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 21s 64ms/step - loss: 0.3606 - accuracy: 0.4267 - val_loss: 0.3839 - val_accuracy: 0.3742\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 19s 56ms/step - loss: 0.3418 - accuracy: 0.4681 - val_loss: 0.3837 - val_accuracy: 0.3659\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.3266 - accuracy: 0.5080 - val_loss: 0.3825 - val_accuracy: 0.3722\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.3110 - accuracy: 0.5365 - val_loss: 0.3837 - val_accuracy: 0.3851\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 20s 62ms/step - loss: 0.2993 - accuracy: 0.5637 - val_loss: 0.3892 - val_accuracy: 0.3742\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 21s 64ms/step - loss: 0.2899 - accuracy: 0.5769 - val_loss: 0.4005 - val_accuracy: 0.3705\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 20s 60ms/step - loss: 0.2799 - accuracy: 0.5950 - val_loss: 0.4055 - val_accuracy: 0.3725\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.4085 - accuracy: 0.3682\n",
      "F1 score:  0.3534605525491313\n",
      "Model: \"functional_137\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_71 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_72 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_20 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "329/329 [==============================] - 22s 66ms/step - loss: 0.4439 - accuracy: 0.2083 - val_loss: 0.4259 - val_accuracy: 0.2867\n",
      "Epoch 2/12\n",
      "329/329 [==============================] - 24s 73ms/step - loss: 0.4059 - accuracy: 0.3200 - val_loss: 0.3958 - val_accuracy: 0.3346\n",
      "Epoch 3/12\n",
      "329/329 [==============================] - 22s 67ms/step - loss: 0.3767 - accuracy: 0.3923 - val_loss: 0.3856 - val_accuracy: 0.3600\n",
      "Epoch 4/12\n",
      "329/329 [==============================] - 21s 63ms/step - loss: 0.3545 - accuracy: 0.4430 - val_loss: 0.3834 - val_accuracy: 0.3819\n",
      "Epoch 5/12\n",
      "329/329 [==============================] - 23s 70ms/step - loss: 0.3350 - accuracy: 0.4875 - val_loss: 0.3828 - val_accuracy: 0.3734\n",
      "Epoch 6/12\n",
      "329/329 [==============================] - 20s 62ms/step - loss: 0.3183 - accuracy: 0.5218 - val_loss: 0.3847 - val_accuracy: 0.3831\n",
      "Epoch 7/12\n",
      "329/329 [==============================] - 20s 60ms/step - loss: 0.3038 - accuracy: 0.5488 - val_loss: 0.3891 - val_accuracy: 0.3816\n",
      "Epoch 8/12\n",
      "329/329 [==============================] - 19s 58ms/step - loss: 0.2923 - accuracy: 0.5730 - val_loss: 0.3927 - val_accuracy: 0.3853\n",
      "Epoch 9/12\n",
      "329/329 [==============================] - 21s 63ms/step - loss: 0.2806 - accuracy: 0.5926 - val_loss: 0.4058 - val_accuracy: 0.3845\n",
      "Epoch 10/12\n",
      "329/329 [==============================] - 24s 72ms/step - loss: 0.2709 - accuracy: 0.6104 - val_loss: 0.4055 - val_accuracy: 0.3825\n",
      "Epoch 11/12\n",
      "329/329 [==============================] - 24s 72ms/step - loss: 0.2641 - accuracy: 0.6132 - val_loss: 0.4139 - val_accuracy: 0.3822\n",
      "Epoch 12/12\n",
      "329/329 [==============================] - 23s 69ms/step - loss: 0.2587 - accuracy: 0.6245 - val_loss: 0.4132 - val_accuracy: 0.3828\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.4179 - accuracy: 0.3668\n",
      "F1 score:  0.3459256042842669\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    # LSTM model parameters\n",
    "    epochs = rn.randint(5, 25)\n",
    "    embed_dim = 100\n",
    "    dropout_rate = 0.7\n",
    "    num_classes = 8\n",
    "\n",
    "    # Input is a special \"layer\".  It defines a placeholder that will be overwritten by the training data.\n",
    "    # In our case, we are accepting a list of wordids (padded out to max_len).\n",
    "    wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "    # Embed the wordids.\n",
    "    # Recall, this is just a mathematically equivalent operation to a linear layer and a one-hot\n",
    "    h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "    # Add 2 bidirectional LSTMs\n",
    "    h = keras.layers.Bidirectional(keras.layers.LSTM(64))(h)\n",
    "\n",
    "    prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "    # Dropout can help with overfitting (improve generalization) by randomly 0-ing different subsets of values\n",
    "    # in the vector.\n",
    "    # See https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf for details.\n",
    "    h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "    \n",
    "    model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  # From information theory notebooks.\n",
    "                  metrics=['accuracy'])        # What metric to output as we train.\n",
    "    model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "    model.evaluate(test_padded, test_labels)\n",
    "\n",
    "    # Get F1 score\n",
    "    y_pred = model.predict(test_padded)\n",
    "    y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "    print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d8128742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_151\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_80 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.4589 - accuracy: 0.1769 - val_loss: 0.4287 - val_accuracy: 0.2944\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4209 - accuracy: 0.2957 - val_loss: 0.3986 - val_accuracy: 0.3531\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.3857 - accuracy: 0.3953 - val_loss: 0.3897 - val_accuracy: 0.3611\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 19s 58ms/step - loss: 0.3545 - accuracy: 0.4563 - val_loss: 0.3872 - val_accuracy: 0.3708\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 23s 70ms/step - loss: 0.3287 - accuracy: 0.5206 - val_loss: 0.3935 - val_accuracy: 0.3628\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 21s 64ms/step - loss: 0.3071 - accuracy: 0.5795 - val_loss: 0.3955 - val_accuracy: 0.3685\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 20s 62ms/step - loss: 0.2879 - accuracy: 0.6095 - val_loss: 0.4106 - val_accuracy: 0.3602\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.2724 - accuracy: 0.6305 - val_loss: 0.4206 - val_accuracy: 0.3631\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.2591 - accuracy: 0.6571 - val_loss: 0.4440 - val_accuracy: 0.3622\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 18s 55ms/step - loss: 0.2468 - accuracy: 0.6668 - val_loss: 0.4514 - val_accuracy: 0.3648\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.4475 - accuracy: 0.3682\n",
      "F1 score:  0.33232628398791536\n"
     ]
    }
   ],
   "source": [
    "# LSTM model parameters\n",
    "epochs = 10\n",
    "embed_dim = 100\n",
    "dropout_rate = 0.7\n",
    "num_classes = 8\n",
    "\n",
    "# Input is a special \"layer\".  It defines a placeholder that will be overwritten by the training data.\n",
    "# In our case, we are accepting a list of wordids (padded out to max_len).\n",
    "wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "# Embed the wordids.\n",
    "# Recall, this is just a mathematically equivalent operation to a linear layer and a one-hot\n",
    "h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "# Add a bidirectional LSTMs\n",
    "h = keras.layers.Bidirectional(keras.layers.LSTM(64))(h)\n",
    "\n",
    "# h = keras.layers.Dense(dense_size, activation='relu')(h)\n",
    "\n",
    "# Dropout can help with overfitting (improve generalization) by randomly 0-ing different subsets of values\n",
    "# in the vector.\n",
    "# See https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf for details.\n",
    "h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # From information theory notebooks.\n",
    "              metrics=['accuracy'])        # What metric to output as we train.\n",
    "model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "model.evaluate(test_padded, test_labels)\n",
    "\n",
    "# Get F1 score\n",
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e36f6c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger      0.457     0.382     0.416       775\n",
      "anticipation      0.438     0.272     0.335       633\n",
      "     disgust      0.435     0.159     0.232       460\n",
      "        fear      0.446     0.150     0.225       500\n",
      "         joy      0.612     0.429     0.504       592\n",
      "     sadness      0.458     0.198     0.277       464\n",
      "    surprise      0.378     0.145     0.209       505\n",
      "       trust      0.440     0.213     0.287       564\n",
      "\n",
      "   micro avg      0.470     0.257     0.332      4493\n",
      "   macro avg      0.458     0.243     0.311      4493\n",
      "weighted avg      0.460     0.257     0.322      4493\n",
      " samples avg      0.307     0.278     0.282      4493\n",
      "\n",
      "hamming score  0.26286841604867844\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_pred_bool, digits = 3, target_names = emotions))\n",
    "print('hamming score ', hamming_score(test_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4ac2c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_153\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_80 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_81 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.4516 - accuracy: 0.1886 - val_loss: 0.4247 - val_accuracy: 0.2932\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.4050 - accuracy: 0.3305 - val_loss: 0.3911 - val_accuracy: 0.3591\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.3588 - accuracy: 0.4506 - val_loss: 0.3827 - val_accuracy: 0.3742\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.3211 - accuracy: 0.5322 - val_loss: 0.3909 - val_accuracy: 0.3699\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.2905 - accuracy: 0.5932 - val_loss: 0.3980 - val_accuracy: 0.3802\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 13s 41ms/step - loss: 0.2685 - accuracy: 0.6308 - val_loss: 0.4131 - val_accuracy: 0.3702\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.2501 - accuracy: 0.6582 - val_loss: 0.4396 - val_accuracy: 0.3654\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 22s 68ms/step - loss: 0.2361 - accuracy: 0.6722 - val_loss: 0.4486 - val_accuracy: 0.3651\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 24s 73ms/step - loss: 0.2250 - accuracy: 0.6822 - val_loss: 0.4638 - val_accuracy: 0.3617\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 21s 63ms/step - loss: 0.2138 - accuracy: 0.6981 - val_loss: 0.4766 - val_accuracy: 0.3537\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 0.4756 - accuracy: 0.3474\n",
      "F1 score:  0.33963305283487377\n"
     ]
    }
   ],
   "source": [
    "# LSTM model parameters\n",
    "epochs = 10\n",
    "embed_dim = 100\n",
    "dropout_rate = 0.5\n",
    "num_classes = 8\n",
    "\n",
    "# Input is a special \"layer\".  It defines a placeholder that will be overwritten by the training data.\n",
    "# In our case, we are accepting a list of wordids (padded out to max_len).\n",
    "wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "# Embed the wordids.\n",
    "# Recall, this is just a mathematically equivalent operation to a linear layer and a one-hot\n",
    "h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "# Add a bidirectional LSTMs\n",
    "h = keras.layers.Bidirectional(keras.layers.LSTM(64))(h)\n",
    "\n",
    "# h = keras.layers.Dense(dense_size, activation='relu')(h)\n",
    "\n",
    "# Dropout can help with overfitting (improve generalization) by randomly 0-ing different subsets of values\n",
    "# in the vector.\n",
    "# See https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf for details.\n",
    "h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # From information theory notebooks.\n",
    "              metrics=['accuracy'])        # What metric to output as we train.\n",
    "model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "model.evaluate(test_padded, test_labels)\n",
    "\n",
    "# Get F1 score\n",
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1261013a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger      0.498     0.290     0.367       775\n",
      "anticipation      0.400     0.321     0.356       633\n",
      "     disgust      0.364     0.146     0.208       460\n",
      "        fear      0.439     0.202     0.277       500\n",
      "         joy      0.538     0.473     0.504       592\n",
      "     sadness      0.413     0.267     0.325       464\n",
      "    surprise      0.367     0.200     0.259       505\n",
      "       trust      0.451     0.230     0.305       564\n",
      "\n",
      "   micro avg      0.447     0.274     0.340      4493\n",
      "   macro avg      0.434     0.266     0.325      4493\n",
      "weighted avg      0.440     0.274     0.333      4493\n",
      " samples avg      0.323     0.293     0.297      4493\n",
      "\n",
      "hamming score  0.27573683209735694\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_pred_bool, digits = 3, target_names = emotions))\n",
    "print('hamming score ', hamming_score(test_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "24a380c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_155\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_81 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_82 (Embedding)     (None, 100, 100)          661800    \n",
      "_________________________________________________________________\n",
      "bidirectional_30 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 747,312\n",
      "Trainable params: 747,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "329/329 [==============================] - 37s 112ms/step - loss: 0.4594 - accuracy: 0.1728 - val_loss: 0.4297 - val_accuracy: 0.2795\n",
      "Epoch 2/12\n",
      "329/329 [==============================] - 25s 77ms/step - loss: 0.4238 - accuracy: 0.2880 - val_loss: 0.3988 - val_accuracy: 0.3491\n",
      "Epoch 3/12\n",
      "329/329 [==============================] - 25s 75ms/step - loss: 0.3852 - accuracy: 0.4015 - val_loss: 0.3846 - val_accuracy: 0.3694\n",
      "Epoch 4/12\n",
      "329/329 [==============================] - 26s 80ms/step - loss: 0.3508 - accuracy: 0.4774 - val_loss: 0.3840 - val_accuracy: 0.3745\n",
      "Epoch 5/12\n",
      "329/329 [==============================] - 29s 87ms/step - loss: 0.3245 - accuracy: 0.5490 - val_loss: 0.3936 - val_accuracy: 0.3659\n",
      "Epoch 6/12\n",
      "329/329 [==============================] - 27s 83ms/step - loss: 0.2984 - accuracy: 0.5941 - val_loss: 0.4022 - val_accuracy: 0.3614\n",
      "Epoch 7/12\n",
      "329/329 [==============================] - 26s 79ms/step - loss: 0.2830 - accuracy: 0.6218 - val_loss: 0.4061 - val_accuracy: 0.3634\n",
      "Epoch 8/12\n",
      "329/329 [==============================] - 25s 76ms/step - loss: 0.2714 - accuracy: 0.6437 - val_loss: 0.4245 - val_accuracy: 0.3665\n",
      "Epoch 9/12\n",
      "329/329 [==============================] - 26s 79ms/step - loss: 0.2586 - accuracy: 0.6591 - val_loss: 0.4429 - val_accuracy: 0.3611\n",
      "Epoch 10/12\n",
      "329/329 [==============================] - 24s 73ms/step - loss: 0.2489 - accuracy: 0.6690 - val_loss: 0.4452 - val_accuracy: 0.3588\n",
      "Epoch 11/12\n",
      "329/329 [==============================] - 24s 72ms/step - loss: 0.2390 - accuracy: 0.6835 - val_loss: 0.4590 - val_accuracy: 0.3611\n",
      "Epoch 12/12\n",
      "329/329 [==============================] - 24s 73ms/step - loss: 0.2315 - accuracy: 0.6885 - val_loss: 0.4692 - val_accuracy: 0.3631\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.4638 - accuracy: 0.3591\n",
      "F1 score:  0.3158971361776739\n"
     ]
    }
   ],
   "source": [
    "# LSTM model parameters\n",
    "epochs = 12\n",
    "embed_dim = 100\n",
    "dropout_rate = 0.7\n",
    "num_classes = 8\n",
    "\n",
    "# Input is a special \"layer\".  It defines a placeholder that will be overwritten by the training data.\n",
    "# In our case, we are accepting a list of wordids (padded out to max_len).\n",
    "wordids = keras.layers.Input(shape=(max_len_touse,))\n",
    "\n",
    "# Embed the wordids.\n",
    "# Recall, this is just a mathematically equivalent operation to a linear layer and a one-hot\n",
    "h = keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim, input_length=max_len_touse)(wordids)\n",
    "\n",
    "# Add a bidirectional LSTMs\n",
    "h = keras.layers.Bidirectional(keras.layers.LSTM(64))(h)\n",
    "\n",
    "# h = keras.layers.Dense(dense_size, activation='relu')(h)\n",
    "\n",
    "# Dropout can help with overfitting (improve generalization) by randomly 0-ing different subsets of values\n",
    "# in the vector.\n",
    "# See https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf for details.\n",
    "h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
    "\n",
    "prediction = keras.layers.Dense(num_classes, activation='sigmoid')(h)\n",
    "\n",
    "model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # From information theory notebooks.\n",
    "              metrics=['accuracy'])        # What metric to output as we train.\n",
    "model.fit(train_padded, train_labels, epochs=epochs, validation_data=(dev_padded, dev_labels))\n",
    "model.evaluate(test_padded, test_labels)\n",
    "\n",
    "# Get F1 score\n",
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = (y_pred>0.5)*1  # because last layer was sigmoid\n",
    "print('F1 score: ', f1_score(test_labels, y_pred_bool, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "068c6c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger      0.533     0.285     0.371       775\n",
      "anticipation      0.427     0.284     0.341       633\n",
      "     disgust      0.424     0.193     0.266       460\n",
      "        fear      0.384     0.172     0.238       500\n",
      "         joy      0.574     0.389     0.463       592\n",
      "     sadness      0.422     0.235     0.302       464\n",
      "    surprise      0.354     0.123     0.182       505\n",
      "       trust      0.423     0.184     0.257       564\n",
      "\n",
      "   micro avg      0.460     0.241     0.316      4493\n",
      "   macro avg      0.442     0.233     0.303      4493\n",
      "weighted avg      0.450     0.241     0.311      4493\n",
      " samples avg      0.293     0.257     0.265      4493\n",
      "\n",
      "hamming score  0.24713348545350827\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_pred_bool, digits = 3, target_names = emotions))\n",
    "print('hamming score ', hamming_score(test_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33473071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
